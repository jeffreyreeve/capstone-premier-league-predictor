{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c15996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b87cd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TeamH</th>\n",
       "      <th>TeamA</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>IWA</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PSD</th>\n",
       "      <th>PSA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>P&gt;2.5</th>\n",
       "      <th>P&lt;2.5</th>\n",
       "      <th>Max&gt;2.5</th>\n",
       "      <th>Max&lt;2.5</th>\n",
       "      <th>Avg&gt;2.5</th>\n",
       "      <th>Avg&lt;2.5</th>\n",
       "      <th>AHh</th>\n",
       "      <th>B365AHH</th>\n",
       "      <th>B365AHA</th>\n",
       "      <th>PAHH</th>\n",
       "      <th>PAHA</th>\n",
       "      <th>MaxAHH</th>\n",
       "      <th>MaxAHA</th>\n",
       "      <th>AvgAHH</th>\n",
       "      <th>AvgAHA</th>\n",
       "      <th>B365CH</th>\n",
       "      <th>B365CD</th>\n",
       "      <th>B365CA</th>\n",
       "      <th>BWCH</th>\n",
       "      <th>BWCD</th>\n",
       "      <th>BWCA</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>WHCH</th>\n",
       "      <th>WHCD</th>\n",
       "      <th>WHCA</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>MaxCH</th>\n",
       "      <th>MaxCD</th>\n",
       "      <th>MaxCA</th>\n",
       "      <th>AvgCH</th>\n",
       "      <th>AvgCD</th>\n",
       "      <th>AvgCA</th>\n",
       "      <th>B365C&gt;2.5</th>\n",
       "      <th>B365C&lt;2.5</th>\n",
       "      <th>PC&gt;2.5</th>\n",
       "      <th>PC&lt;2.5</th>\n",
       "      <th>MaxC&gt;2.5</th>\n",
       "      <th>MaxC&lt;2.5</th>\n",
       "      <th>AvgC&gt;2.5</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>HStr</th>\n",
       "      <th>HSOH</th>\n",
       "      <th>HSOA</th>\n",
       "      <th>HSAH</th>\n",
       "      <th>HSAA</th>\n",
       "      <th>HSDH</th>\n",
       "      <th>HSDA</th>\n",
       "      <th>HO</th>\n",
       "      <th>HA</th>\n",
       "      <th>HM</th>\n",
       "      <th>HD</th>\n",
       "      <th>HDP</th>\n",
       "      <th>HIP</th>\n",
       "      <th>HSAAg</th>\n",
       "      <th>HATAAg</th>\n",
       "      <th>HGls</th>\n",
       "      <th>HAssts</th>\n",
       "      <th>HGlsPK</th>\n",
       "      <th>HxG</th>\n",
       "      <th>HNpxG</th>\n",
       "      <th>HxAG</th>\n",
       "      <th>HPoss</th>\n",
       "      <th>HPrg</th>\n",
       "      <th>HPrgP</th>\n",
       "      <th>HGKS%</th>\n",
       "      <th>HGKCS%</th>\n",
       "      <th>HSoT</th>\n",
       "      <th>Hg-xG</th>\n",
       "      <th>HCmp</th>\n",
       "      <th>HCmp%</th>\n",
       "      <th>HPrgDist</th>\n",
       "      <th>HXa</th>\n",
       "      <th>HKP</th>\n",
       "      <th>HPPA</th>\n",
       "      <th>HCrsPA</th>\n",
       "      <th>HTB</th>\n",
       "      <th>HCrs</th>\n",
       "      <th>HCK</th>\n",
       "      <th>HSCA</th>\n",
       "      <th>HGCA</th>\n",
       "      <th>HTkIW</th>\n",
       "      <th>HLost</th>\n",
       "      <th>HBlocks</th>\n",
       "      <th>HPass</th>\n",
       "      <th>HInt</th>\n",
       "      <th>HClr</th>\n",
       "      <th>HAttPen</th>\n",
       "      <th>HSucc%</th>\n",
       "      <th>HCPA</th>\n",
       "      <th>HDis</th>\n",
       "      <th>HPrgR</th>\n",
       "      <th>HOnG</th>\n",
       "      <th>HOnGA</th>\n",
       "      <th>HOnxG</th>\n",
       "      <th>HOnxGA</th>\n",
       "      <th>AStr</th>\n",
       "      <th>ASOH</th>\n",
       "      <th>ASOA</th>\n",
       "      <th>ASAH</th>\n",
       "      <th>ASAA</th>\n",
       "      <th>ASDH</th>\n",
       "      <th>ASDA</th>\n",
       "      <th>AO</th>\n",
       "      <th>AA</th>\n",
       "      <th>AM</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADP</th>\n",
       "      <th>AIP</th>\n",
       "      <th>ASAAg</th>\n",
       "      <th>ATAAg</th>\n",
       "      <th>AGls</th>\n",
       "      <th>AAssts</th>\n",
       "      <th>AGlsPK</th>\n",
       "      <th>AxG</th>\n",
       "      <th>ANpxG</th>\n",
       "      <th>AxAG</th>\n",
       "      <th>APoss</th>\n",
       "      <th>APrg</th>\n",
       "      <th>APrgP</th>\n",
       "      <th>AGKS%</th>\n",
       "      <th>AGKCS%</th>\n",
       "      <th>ASoT</th>\n",
       "      <th>Ag-xG</th>\n",
       "      <th>ACmp</th>\n",
       "      <th>ACmp%</th>\n",
       "      <th>APrgDist</th>\n",
       "      <th>AXa</th>\n",
       "      <th>AKP</th>\n",
       "      <th>APPA</th>\n",
       "      <th>ACrsPA</th>\n",
       "      <th>ATB</th>\n",
       "      <th>ACrs</th>\n",
       "      <th>ACK</th>\n",
       "      <th>ASCA</th>\n",
       "      <th>AGCA</th>\n",
       "      <th>ATkIW</th>\n",
       "      <th>ALost</th>\n",
       "      <th>ABlocks</th>\n",
       "      <th>APass</th>\n",
       "      <th>AInt</th>\n",
       "      <th>AClr</th>\n",
       "      <th>AAttPen</th>\n",
       "      <th>ASucc%</th>\n",
       "      <th>ACPA</th>\n",
       "      <th>ADis</th>\n",
       "      <th>APrgR</th>\n",
       "      <th>AOnG</th>\n",
       "      <th>AOnGA</th>\n",
       "      <th>AOnxG</th>\n",
       "      <th>AOnxGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/8/2022</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.89</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.88</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>5.01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3</td>\n",
       "      <td>1085</td>\n",
       "      <td>1100</td>\n",
       "      <td>1110</td>\n",
       "      <td>1110</td>\n",
       "      <td>1060</td>\n",
       "      <td>1090</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>45.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>71.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>348.8</td>\n",
       "      <td>77.2</td>\n",
       "      <td>2310.4</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.19</td>\n",
       "      <td>6.14</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.95</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.89</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.73</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.65</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>5.41</td>\n",
       "      <td>12.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4</td>\n",
       "      <td>1245</td>\n",
       "      <td>1285</td>\n",
       "      <td>1250</td>\n",
       "      <td>1250</td>\n",
       "      <td>1240</td>\n",
       "      <td>1320</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.39</td>\n",
       "      <td>59.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>54.2</td>\n",
       "      <td>70.6</td>\n",
       "      <td>35.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.27</td>\n",
       "      <td>482.8</td>\n",
       "      <td>83.1</td>\n",
       "      <td>2658.9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.01</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.24</td>\n",
       "      <td>17.8</td>\n",
       "      <td>5.81</td>\n",
       "      <td>27.6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>8.89</td>\n",
       "      <td>6.51</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.22</td>\n",
       "      <td>6.35</td>\n",
       "      <td>15.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.1</td>\n",
       "      <td>53.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Time           TeamH    TeamA  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0  5/8/2022  20:00  Crystal Palace  Arsenal     0     2   A     0     1   A   \n",
       "\n",
       "    Referee  B365H  B365D  B365A   BWH  BWD   BWA  IWH   IWD   IWA  PSH   PSD  \\\n",
       "0  A Taylor    4.2    3.6   1.85  4.33  3.5  1.87  4.3  3.55  1.85  4.5  3.65   \n",
       "\n",
       "    PSA  WHH  WHD   WHA  VCH  VCD   VCA  MaxH  MaxD  MaxA  AvgH  AvgD  AvgA  \\\n",
       "0  1.89  4.4  3.5  1.83  4.6  3.5  1.87   4.6  3.78  1.95  4.39  3.59  1.88   \n",
       "\n",
       "   B365>2.5  B365<2.5  P>2.5  P<2.5  Max>2.5  Max<2.5  Avg>2.5  Avg<2.5  AHh  \\\n",
       "0       2.1      1.72   2.14   1.78     2.19     1.91     2.09     1.76  0.5   \n",
       "\n",
       "   B365AHH  B365AHA  PAHH  PAHA  MaxAHH  MaxAHA  AvgAHH  AvgAHA  B365CH  \\\n",
       "0     2.04     1.89  2.03  1.89    2.06    1.91    2.01    1.87     4.5   \n",
       "\n",
       "   B365CD  B365CA  BWCH  BWCD  BWCA  IWCH  IWCD  IWCA  PSCH  PSCD  PSCA  WHCH  \\\n",
       "0     3.6     1.8   4.5   3.5  1.83   4.4  3.55  1.85  4.58  3.63  1.88   4.8   \n",
       "\n",
       "   WHCD  WHCA  VCCH  VCCD  VCCA  MaxCH  MaxCD  MaxCA  AvgCH  AvgCD  AvgCA  \\\n",
       "0   3.4  1.78  4.75   3.5  1.85   5.01    3.7   1.91   4.56   3.57   1.85   \n",
       "\n",
       "   B365C>2.5  B365C<2.5  PC>2.5  PC<2.5  MaxC>2.5  MaxC<2.5  AvgC>2.5  \\\n",
       "0        2.1       1.72    2.14    1.78      2.19      1.91      2.08   \n",
       "\n",
       "   AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  \\\n",
       "0      1.76   0.5      2.09      1.84   2.04   1.88     2.09     1.88   \n",
       "\n",
       "   AvgCAHH  AvgCAHA  HStr  HSOH  HSOA  HSAH  HSAA  HSDH  HSDA  HO  HA  HM  HD  \\\n",
       "0     2.03     1.85     3  1085  1100  1110  1110  1060  1090  76  77  75  76   \n",
       "\n",
       "   HDP  HIP  HSAAg  HATAAg  HGls  HAssts  HGlsPK   HxG  HNpxG  HxAG  HPoss  \\\n",
       "0    4    2   26.6    25.2   1.0    0.76    0.97  1.02   0.96  0.75   45.8   \n",
       "\n",
       "   HPrg  HPrgP  HGKS%  HGKCS%  HSoT  Hg-xG   HCmp  HCmp%  HPrgDist   HXa  \\\n",
       "0  14.2   32.2   71.8    24.3  3.51  -0.02  348.8   77.2    2310.4  0.61   \n",
       "\n",
       "    HKP  HPPA  HCrsPA   HTB  HCrs   HCK  HSCA  HGCA  HTkIW  HLost  HBlocks  \\\n",
       "0  8.19  6.14    1.27  0.95  15.4  4.89  19.4  1.76   11.2   6.73     12.3   \n",
       "\n",
       "   HPass  HInt  HClr  HAttPen  HSucc%  HCPA  HDis  HPrgR  HOnG  HOnGA  HOnxG  \\\n",
       "0   9.08  9.65  21.5     19.9    46.9  5.41  12.1   32.1  1.05    1.3   1.02   \n",
       "\n",
       "   HOnxGA  AStr  ASOH  ASOA  ASAH  ASAA  ASDH  ASDA  AO  AA  AM  AD  ADP  AIP  \\\n",
       "0    1.29     4  1245  1285  1250  1250  1240  1320  80  83  81  79    7    7   \n",
       "\n",
       "   ASAAg  ATAAg  AGls  AAssts  AGlsPK   AxG  ANpxG  AxAG  APoss  APrg  APrgP  \\\n",
       "0   24.1   23.0  2.14    1.62    2.05  1.87   1.79  1.39   59.5  21.7   54.2   \n",
       "\n",
       "   AGKS%  AGKCS%  ASoT  Ag-xG   ACmp  ACmp%  APrgDist   AXa   AKP   APPA  \\\n",
       "0   70.6    35.1  5.03   0.27  482.8   83.1    2658.9  1.21  11.7  12.01   \n",
       "\n",
       "   ACrsPA   ATB  ACrs   ACK  ASCA  AGCA  ATkIW  ALost  ABlocks  APass  AInt  \\\n",
       "0    1.65  2.24  17.8  5.81  27.6  3.81   8.89   6.51     9.49   7.22  6.35   \n",
       "\n",
       "   AClr  AAttPen  ASucc%  ACPA  ADis  APrgR  AOnG  AOnGA  AOnxG  AOnxGA  \n",
       "0  15.8     34.0    46.3  7.38  10.1   53.5  2.24   1.16   1.87    1.12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data = pd.read_csv('../data/final_data_corrected.csv')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b36307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA',\n",
    "          'PSH', 'PSD', 'PSA', 'WHH','WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'MaxH', 'MaxD', 'MaxA','AvgH', 'AvgD', 'AvgA', 'B365>2.5',\n",
    "          'B365<2.5', 'P>2.5', 'P<2.5', 'Max>2.5', 'Max<2.5', 'Avg>2.5', 'Avg<2.5', 'AHh', 'B365AHH','B365AHA', 'PAHH', 'PAHA', \n",
    "          'MaxAHH', 'MaxAHA', \"AvgAHH\", 'AvgAHA', 'B365CH', 'B365CD', 'B365CA', 'BWCH', 'BWCD', 'BWCA', 'IWCH', 'IWCD', 'IWCA',\n",
    "          'PSCH', 'PSCD', 'PSCA', 'WHCH', 'WHCD', 'WHCA', 'VCCH', 'VCCD', 'VCCA', 'MaxCH', 'MaxCD', 'MaxCA', 'AvgCH', 'AvgCD',\n",
    "          'AvgCA', 'B365C>2.5', 'B365C<2.5', 'PC>2.5', 'PC<2.5', 'MaxC>2.5', 'MaxC<2.5', 'AvgC>2.5', 'AvgC<2.5', 'AHCh', 'B365CAHH',\n",
    "          'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA', 'HStr', 'HSOH', 'HSOA', 'HSAH', 'HSAA', 'HSDH',\n",
    "          'HSDA', 'HO', 'HA', 'HM', 'HD', 'HDP', 'HIP', 'HSAAg', 'HATAAg', 'HGls', 'HAssts', 'HGlsPK', 'HxG', 'HNpxG', 'HxAG',\n",
    "          'HPoss', 'HPrg', 'HPrgP', 'HGKS%', 'HGKCS%', 'HSoT', 'Hg-xG', 'HCmp', 'HCmp%', 'HPrgDist', 'HXa', 'HKP', 'HPPA', 'HCrsPA',\n",
    "          'HTB', 'HCrs', 'HCK', 'HSCA', 'HGCA', 'HTkIW', 'HLost', 'HBlocks', 'HPass', 'HInt', 'HClr', 'HAttPen', 'HSucc%', 'HCPA',\n",
    "          'HDis', 'HPrgR', 'HOnG', 'HOnGA', 'HOnxG', 'HOnxGA', 'AStr', 'ASOH', 'ASOA', 'ASAH', 'ASAA', 'ASDH', 'ASDA', 'AO', 'AA',\n",
    "          'AM', 'AD', 'ADP', 'AIP', 'ASAAg', 'ATAAg', 'AGls', 'AAssts', 'AGlsPK', 'AxG', 'ANpxG', 'AxAG', 'APoss', 'APrg', 'APrgP',\n",
    "          'AGKS%', 'AGKCS%', 'ASoT', 'Ag-xG', 'ACmp', 'ACmp%', 'APrgDist', 'AXa', 'AKP', 'APPA', 'ACrsPA', 'ATB', 'ACrs', 'ACK',\n",
    "          'ASCA', 'AGCA', 'ATkIW', 'ALost', 'ABlocks', 'APass', 'AInt', 'AClr','AAttPen', 'ASucc%', 'ACPA', 'ADis', 'APrgR', 'AOnG',\n",
    "          'AOnGA', 'AOnxG', 'AOnxGA']].copy()\n",
    "y = data['FTHG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ea61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5df267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da7fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.55501860\n",
      "Iteration 2, loss = 1.10991950\n",
      "Iteration 3, loss = 1.08703787\n",
      "Iteration 4, loss = 0.97386319\n",
      "Iteration 5, loss = 0.85842134\n",
      "Iteration 6, loss = 0.83735577\n",
      "Iteration 7, loss = 0.84074040\n",
      "Iteration 8, loss = 0.82304228\n",
      "Iteration 9, loss = 0.79163291\n",
      "Iteration 10, loss = 0.77737367\n",
      "Iteration 11, loss = 0.77266966\n",
      "Iteration 12, loss = 0.75678876\n",
      "Iteration 13, loss = 0.73127536\n",
      "Iteration 14, loss = 0.71825727\n",
      "Iteration 15, loss = 0.71259149\n",
      "Iteration 16, loss = 0.70335758\n",
      "Iteration 17, loss = 0.69024372\n",
      "Iteration 18, loss = 0.68081203\n",
      "Iteration 19, loss = 0.67412651\n",
      "Iteration 20, loss = 0.66652008\n",
      "Iteration 21, loss = 0.65842355\n",
      "Iteration 22, loss = 0.65151867\n",
      "Iteration 23, loss = 0.64446249\n",
      "Iteration 24, loss = 0.63672880\n",
      "Iteration 25, loss = 0.63131505\n",
      "Iteration 26, loss = 0.62607228\n",
      "Iteration 27, loss = 0.62183740\n",
      "Iteration 28, loss = 0.61513694\n",
      "Iteration 29, loss = 0.61030370\n",
      "Iteration 30, loss = 0.60417365\n",
      "Iteration 31, loss = 0.59752075\n",
      "Iteration 32, loss = 0.59364246\n",
      "Iteration 33, loss = 0.58996910\n",
      "Iteration 34, loss = 0.58667154\n",
      "Iteration 35, loss = 0.58168975\n",
      "Iteration 36, loss = 0.57494722\n",
      "Iteration 37, loss = 0.57078541\n",
      "Iteration 38, loss = 0.56619589\n",
      "Iteration 39, loss = 0.56218638\n",
      "Iteration 40, loss = 0.55827323\n",
      "Iteration 41, loss = 0.55349816\n",
      "Iteration 42, loss = 0.55005956\n",
      "Iteration 43, loss = 0.54672653\n",
      "Iteration 44, loss = 0.54470644\n",
      "Iteration 45, loss = 0.53925435\n",
      "Iteration 46, loss = 0.53438224\n",
      "Iteration 47, loss = 0.53044194\n",
      "Iteration 48, loss = 0.52708000\n",
      "Iteration 49, loss = 0.52402333\n",
      "Iteration 50, loss = 0.51993320\n",
      "Iteration 51, loss = 0.51674780\n",
      "Iteration 52, loss = 0.51349994\n",
      "Iteration 53, loss = 0.51097513\n",
      "Iteration 54, loss = 0.50532823\n",
      "Iteration 55, loss = 0.50332300\n",
      "Iteration 56, loss = 0.49829105\n",
      "Iteration 57, loss = 0.49674482\n",
      "Iteration 58, loss = 0.49162912\n",
      "Iteration 59, loss = 0.48852492\n",
      "Iteration 60, loss = 0.48775209\n",
      "Iteration 61, loss = 0.48134047\n",
      "Iteration 62, loss = 0.47738022\n",
      "Iteration 63, loss = 0.47430431\n",
      "Iteration 64, loss = 0.47052122\n",
      "Iteration 65, loss = 0.46573026\n",
      "Iteration 66, loss = 0.46426696\n",
      "Iteration 67, loss = 0.46132536\n",
      "Iteration 68, loss = 0.45573596\n",
      "Iteration 69, loss = 0.45546886\n",
      "Iteration 70, loss = 0.44867574\n",
      "Iteration 71, loss = 0.44755560\n",
      "Iteration 72, loss = 0.44759937\n",
      "Iteration 73, loss = 0.44053743\n",
      "Iteration 74, loss = 0.43966368\n",
      "Iteration 75, loss = 0.43198977\n",
      "Iteration 76, loss = 0.42935326\n",
      "Iteration 77, loss = 0.42520137\n",
      "Iteration 78, loss = 0.42140447\n",
      "Iteration 79, loss = 0.41767552\n",
      "Iteration 80, loss = 0.41574065\n",
      "Iteration 81, loss = 0.41029380\n",
      "Iteration 82, loss = 0.40918108\n",
      "Iteration 83, loss = 0.40148391\n",
      "Iteration 84, loss = 0.39798879\n",
      "Iteration 85, loss = 0.39273861\n",
      "Iteration 86, loss = 0.38928264\n",
      "Iteration 87, loss = 0.38612031\n",
      "Iteration 88, loss = 0.38301395\n",
      "Iteration 89, loss = 0.38092598\n",
      "Iteration 90, loss = 0.37547232\n",
      "Iteration 91, loss = 0.37286109\n",
      "Iteration 92, loss = 0.36660576\n",
      "Iteration 93, loss = 0.36636266\n",
      "Iteration 94, loss = 0.36360856\n",
      "Iteration 95, loss = 0.35885783\n",
      "Iteration 96, loss = 0.35471348\n",
      "Iteration 97, loss = 0.34913225\n",
      "Iteration 98, loss = 0.35104341\n",
      "Iteration 99, loss = 0.34203355\n",
      "Iteration 100, loss = 0.34783411\n",
      "Iteration 101, loss = 0.33647318\n",
      "Iteration 102, loss = 0.33776349\n",
      "Iteration 103, loss = 0.33022825\n",
      "Iteration 104, loss = 0.32751555\n",
      "Iteration 105, loss = 0.32185754\n",
      "Iteration 106, loss = 0.31762301\n",
      "Iteration 107, loss = 0.31316711\n",
      "Iteration 108, loss = 0.31137352\n",
      "Iteration 109, loss = 0.30725030\n",
      "Iteration 110, loss = 0.30383414\n",
      "Iteration 111, loss = 0.29971575\n",
      "Iteration 112, loss = 0.29502611\n",
      "Iteration 113, loss = 0.29330219\n",
      "Iteration 114, loss = 0.28920151\n",
      "Iteration 115, loss = 0.28463197\n",
      "Iteration 116, loss = 0.27953482\n",
      "Iteration 117, loss = 0.27976426\n",
      "Iteration 118, loss = 0.27345674\n",
      "Iteration 119, loss = 0.27277104\n",
      "Iteration 120, loss = 0.26690409\n",
      "Iteration 121, loss = 0.27036017\n",
      "Iteration 122, loss = 0.26343539\n",
      "Iteration 123, loss = 0.26055348\n",
      "Iteration 124, loss = 0.25850203\n",
      "Iteration 125, loss = 0.25107288\n",
      "Iteration 126, loss = 0.25332046\n",
      "Iteration 127, loss = 0.24327777\n",
      "Iteration 128, loss = 0.24936446\n",
      "Iteration 129, loss = 0.23765219\n",
      "Iteration 130, loss = 0.24089924\n",
      "Iteration 131, loss = 0.23103955\n",
      "Iteration 132, loss = 0.23233619\n",
      "Iteration 133, loss = 0.22614899\n",
      "Iteration 134, loss = 0.22499516\n",
      "Iteration 135, loss = 0.22182870\n",
      "Iteration 136, loss = 0.21934050\n",
      "Iteration 137, loss = 0.21306584\n",
      "Iteration 138, loss = 0.21139056\n",
      "Iteration 139, loss = 0.20636856\n",
      "Iteration 140, loss = 0.20313667\n",
      "Iteration 141, loss = 0.19901507\n",
      "Iteration 142, loss = 0.19744383\n",
      "Iteration 143, loss = 0.19672753\n",
      "Iteration 144, loss = 0.19001659\n",
      "Iteration 145, loss = 0.19136882\n",
      "Iteration 146, loss = 0.18669614\n",
      "Iteration 147, loss = 0.18097777\n",
      "Iteration 148, loss = 0.18010148\n",
      "Iteration 149, loss = 0.17710539\n",
      "Iteration 150, loss = 0.17521363\n",
      "Iteration 151, loss = 0.17304365\n",
      "Iteration 152, loss = 0.17095793\n",
      "Iteration 153, loss = 0.16979394\n",
      "Iteration 154, loss = 0.16248736\n",
      "Iteration 155, loss = 0.16200691\n",
      "Iteration 156, loss = 0.15850963\n",
      "Iteration 157, loss = 0.15707970\n",
      "Iteration 158, loss = 0.15158584\n",
      "Iteration 159, loss = 0.15182233\n",
      "Iteration 160, loss = 0.14867493\n",
      "Iteration 161, loss = 0.14692657\n",
      "Iteration 162, loss = 0.14286971\n",
      "Iteration 163, loss = 0.13950427\n",
      "Iteration 164, loss = 0.13784946\n",
      "Iteration 165, loss = 0.13563954\n",
      "Iteration 166, loss = 0.13263186\n",
      "Iteration 167, loss = 0.13116731\n",
      "Iteration 168, loss = 0.12756198\n",
      "Iteration 169, loss = 0.12672599\n",
      "Iteration 170, loss = 0.12290594\n",
      "Iteration 171, loss = 0.12120707\n",
      "Iteration 172, loss = 0.11846148\n",
      "Iteration 173, loss = 0.11652857\n",
      "Iteration 174, loss = 0.11428207\n",
      "Iteration 175, loss = 0.11199156\n",
      "Iteration 176, loss = 0.10990227\n",
      "Iteration 177, loss = 0.10799080\n",
      "Iteration 178, loss = 0.10603096\n",
      "Iteration 179, loss = 0.10446733\n",
      "Iteration 180, loss = 0.10209749\n",
      "Iteration 181, loss = 0.10054326\n",
      "Iteration 182, loss = 0.09970820\n",
      "Iteration 183, loss = 0.09827516\n",
      "Iteration 184, loss = 0.09576983\n",
      "Iteration 185, loss = 0.09513194\n",
      "Iteration 186, loss = 0.09300710\n",
      "Iteration 187, loss = 0.09183063\n",
      "Iteration 188, loss = 0.08756177\n",
      "Iteration 189, loss = 0.08811057\n",
      "Iteration 190, loss = 0.08557047\n",
      "Iteration 191, loss = 0.08404599\n",
      "Iteration 192, loss = 0.08217237\n",
      "Iteration 193, loss = 0.08039624\n",
      "Iteration 194, loss = 0.07890056\n",
      "Iteration 195, loss = 0.07716896\n",
      "Iteration 196, loss = 0.07543644\n",
      "Iteration 197, loss = 0.07370277\n",
      "Iteration 198, loss = 0.07297688\n",
      "Iteration 199, loss = 0.07168782\n",
      "Iteration 200, loss = 0.06984539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;, &#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2dfc7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.1856871976136767\n",
      "MAE: 1.2273385466351703\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d073be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.92026696\n",
      "Iteration 2, loss = 1.19306063\n",
      "Iteration 3, loss = 0.97890825\n",
      "Iteration 4, loss = 1.05468223\n",
      "Iteration 5, loss = 0.95843178\n",
      "Iteration 6, loss = 0.86257679\n",
      "Iteration 7, loss = 0.86435572\n",
      "Iteration 8, loss = 0.86119256\n",
      "Iteration 9, loss = 0.82317402\n",
      "Iteration 10, loss = 0.77655330\n",
      "Iteration 11, loss = 0.75471162\n",
      "Iteration 12, loss = 0.76524652\n",
      "Iteration 13, loss = 0.74874709\n",
      "Iteration 14, loss = 0.72067883\n",
      "Iteration 15, loss = 0.72169393\n",
      "Iteration 16, loss = 0.71338234\n",
      "Iteration 17, loss = 0.69555628\n",
      "Iteration 18, loss = 0.68800359\n",
      "Iteration 19, loss = 0.68119524\n",
      "Iteration 20, loss = 0.67046083\n",
      "Iteration 21, loss = 0.65592256\n",
      "Iteration 22, loss = 0.65029180\n",
      "Iteration 23, loss = 0.64309096\n",
      "Iteration 24, loss = 0.63050888\n",
      "Iteration 25, loss = 0.62075955\n",
      "Iteration 26, loss = 0.60639186\n",
      "Iteration 27, loss = 0.59379699\n",
      "Iteration 28, loss = 0.58774981\n",
      "Iteration 29, loss = 0.57714948\n",
      "Iteration 30, loss = 0.55755457\n",
      "Iteration 31, loss = 0.54651378\n",
      "Iteration 32, loss = 0.53168559\n",
      "Iteration 33, loss = 0.52393630\n",
      "Iteration 34, loss = 0.50876541\n",
      "Iteration 35, loss = 0.49719330\n",
      "Iteration 36, loss = 0.48181139\n",
      "Iteration 37, loss = 0.47219611\n",
      "Iteration 38, loss = 0.45514002\n",
      "Iteration 39, loss = 0.43714978\n",
      "Iteration 40, loss = 0.42646664\n",
      "Iteration 41, loss = 0.40979248\n",
      "Iteration 42, loss = 0.39983669\n",
      "Iteration 43, loss = 0.38009078\n",
      "Iteration 44, loss = 0.37052011\n",
      "Iteration 45, loss = 0.35527131\n",
      "Iteration 46, loss = 0.33858511\n",
      "Iteration 47, loss = 0.32644980\n",
      "Iteration 48, loss = 0.31400681\n",
      "Iteration 49, loss = 0.29709420\n",
      "Iteration 50, loss = 0.27958252\n",
      "Iteration 51, loss = 0.27003789\n",
      "Iteration 52, loss = 0.25819171\n",
      "Iteration 53, loss = 0.23854591\n",
      "Iteration 54, loss = 0.23723391\n",
      "Iteration 55, loss = 0.23079173\n",
      "Iteration 56, loss = 0.20625999\n",
      "Iteration 57, loss = 0.21537587\n",
      "Iteration 58, loss = 0.18374147\n",
      "Iteration 59, loss = 0.17803550\n",
      "Iteration 60, loss = 0.16113412\n",
      "Iteration 61, loss = 0.15208985\n",
      "Iteration 62, loss = 0.14488376\n",
      "Iteration 63, loss = 0.13655784\n",
      "Iteration 64, loss = 0.12509246\n",
      "Iteration 65, loss = 0.11926407\n",
      "Iteration 66, loss = 0.11194230\n",
      "Iteration 67, loss = 0.11600336\n",
      "Iteration 68, loss = 0.11316241\n",
      "Iteration 69, loss = 0.09867339\n",
      "Iteration 70, loss = 0.09143393\n",
      "Iteration 71, loss = 0.08091021\n",
      "Iteration 72, loss = 0.08102430\n",
      "Iteration 73, loss = 0.09942818\n",
      "Iteration 74, loss = 0.10392545\n",
      "Iteration 75, loss = 0.08189899\n",
      "Iteration 76, loss = 0.08103586\n",
      "Iteration 77, loss = 0.08598917\n",
      "Iteration 78, loss = 0.08753501\n",
      "Iteration 79, loss = 0.06010657\n",
      "Iteration 80, loss = 0.05637430\n",
      "Iteration 81, loss = 0.05751231\n",
      "Iteration 82, loss = 0.04857419\n",
      "Iteration 83, loss = 0.03659318\n",
      "Iteration 84, loss = 0.03835678\n",
      "Iteration 85, loss = 0.04074500\n",
      "Iteration 86, loss = 0.03013519\n",
      "Iteration 87, loss = 0.03184284\n",
      "Iteration 88, loss = 0.02811997\n",
      "Iteration 89, loss = 0.02553582\n",
      "Iteration 90, loss = 0.02106968\n",
      "Iteration 91, loss = 0.01909675\n",
      "Iteration 92, loss = 0.01977097\n",
      "Iteration 93, loss = 0.01821180\n",
      "Iteration 94, loss = 0.01680216\n",
      "Iteration 95, loss = 0.01312452\n",
      "Iteration 96, loss = 0.01362358\n",
      "Iteration 97, loss = 0.01236223\n",
      "Iteration 98, loss = 0.01176281\n",
      "Iteration 99, loss = 0.01086546\n",
      "Iteration 100, loss = 0.00976365\n",
      "Iteration 101, loss = 0.00841924\n",
      "Iteration 102, loss = 0.00732029\n",
      "Iteration 103, loss = 0.00941467\n",
      "Iteration 104, loss = 0.00966934\n",
      "Iteration 105, loss = 0.00956492\n",
      "Iteration 106, loss = 0.00732832\n",
      "Iteration 107, loss = 0.00663256\n",
      "Iteration 108, loss = 0.00635661\n",
      "Iteration 109, loss = 0.00636937\n",
      "Iteration 110, loss = 0.00524684\n",
      "Iteration 111, loss = 0.00529117\n",
      "Iteration 112, loss = 0.00429694\n",
      "Iteration 113, loss = 0.00354418\n",
      "Iteration 114, loss = 0.00332256\n",
      "Iteration 115, loss = 0.00299234\n",
      "Iteration 116, loss = 0.00276852\n",
      "Iteration 117, loss = 0.00264205\n",
      "Iteration 118, loss = 0.00252535\n",
      "Iteration 119, loss = 0.00221576\n",
      "Iteration 120, loss = 0.00196955\n",
      "Iteration 121, loss = 0.00177205\n",
      "Iteration 122, loss = 0.00156677\n",
      "Iteration 123, loss = 0.00140271\n",
      "Iteration 124, loss = 0.00124060\n",
      "Iteration 125, loss = 0.00118990\n",
      "Iteration 126, loss = 0.00104645\n",
      "Iteration 127, loss = 0.00102464\n",
      "Iteration 128, loss = 0.00092987\n",
      "Iteration 129, loss = 0.00089835\n",
      "Iteration 130, loss = 0.00080023\n",
      "Iteration 131, loss = 0.00085650\n",
      "Iteration 132, loss = 0.00074626\n",
      "Iteration 133, loss = 0.00067707\n",
      "Iteration 134, loss = 0.00065148\n",
      "Iteration 135, loss = 0.00063501\n",
      "Iteration 136, loss = 0.00055330\n",
      "Iteration 137, loss = 0.00048928\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;, &#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2794e70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.2540046764413413\n",
      "MAE: 1.322588249198596\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd64f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 21.11634593\n",
      "Iteration 2, loss = 20.03869475\n",
      "Iteration 3, loss = 19.18168187\n",
      "Iteration 4, loss = 18.43343220\n",
      "Iteration 5, loss = 17.74633536\n",
      "Iteration 6, loss = 17.17991024\n",
      "Iteration 7, loss = 16.69533982\n",
      "Iteration 8, loss = 16.25761252\n",
      "Iteration 9, loss = 15.82434840\n",
      "Iteration 10, loss = 15.37713199\n",
      "Iteration 11, loss = 14.92504600\n",
      "Iteration 12, loss = 14.48449500\n",
      "Iteration 13, loss = 14.06008861\n",
      "Iteration 14, loss = 13.66075908\n",
      "Iteration 15, loss = 13.28043565\n",
      "Iteration 16, loss = 12.90944246\n",
      "Iteration 17, loss = 12.54408695\n",
      "Iteration 18, loss = 12.18400787\n",
      "Iteration 19, loss = 11.82822623\n",
      "Iteration 20, loss = 11.48822061\n",
      "Iteration 21, loss = 11.16090508\n",
      "Iteration 22, loss = 10.84200872\n",
      "Iteration 23, loss = 10.53586007\n",
      "Iteration 24, loss = 10.23649064\n",
      "Iteration 25, loss = 9.94514598\n",
      "Iteration 26, loss = 9.66380740\n",
      "Iteration 27, loss = 9.39138072\n",
      "Iteration 28, loss = 9.12947755\n",
      "Iteration 29, loss = 8.87398791\n",
      "Iteration 30, loss = 8.62533337\n",
      "Iteration 31, loss = 8.38382097\n",
      "Iteration 32, loss = 8.15096002\n",
      "Iteration 33, loss = 7.92403588\n",
      "Iteration 34, loss = 7.70599177\n",
      "Iteration 35, loss = 7.49356407\n",
      "Iteration 36, loss = 7.28746021\n",
      "Iteration 37, loss = 7.08952993\n",
      "Iteration 38, loss = 6.89716285\n",
      "Iteration 39, loss = 6.70981465\n",
      "Iteration 40, loss = 6.52779659\n",
      "Iteration 41, loss = 6.35341952\n",
      "Iteration 42, loss = 6.18550079\n",
      "Iteration 43, loss = 6.02175012\n",
      "Iteration 44, loss = 5.86132631\n",
      "Iteration 45, loss = 5.70478482\n",
      "Iteration 46, loss = 5.55548153\n",
      "Iteration 47, loss = 5.41672049\n",
      "Iteration 48, loss = 5.27900438\n",
      "Iteration 49, loss = 5.14078081\n",
      "Iteration 50, loss = 5.00592271\n",
      "Iteration 51, loss = 4.87803353\n",
      "Iteration 52, loss = 4.75735497\n",
      "Iteration 53, loss = 4.64030106\n",
      "Iteration 54, loss = 4.52452017\n",
      "Iteration 55, loss = 4.40942089\n",
      "Iteration 56, loss = 4.30038336\n",
      "Iteration 57, loss = 4.19705566\n",
      "Iteration 58, loss = 4.09666970\n",
      "Iteration 59, loss = 3.99797234\n",
      "Iteration 60, loss = 3.90180046\n",
      "Iteration 61, loss = 3.80796599\n",
      "Iteration 62, loss = 3.71948242\n",
      "Iteration 63, loss = 3.63297490\n",
      "Iteration 64, loss = 3.54922378\n",
      "Iteration 65, loss = 3.46730451\n",
      "Iteration 66, loss = 3.38919817\n",
      "Iteration 67, loss = 3.31205623\n",
      "Iteration 68, loss = 3.23871726\n",
      "Iteration 69, loss = 3.16701110\n",
      "Iteration 70, loss = 3.09833024\n",
      "Iteration 71, loss = 3.03168528\n",
      "Iteration 72, loss = 2.96757484\n",
      "Iteration 73, loss = 2.90449896\n",
      "Iteration 74, loss = 2.84294502\n",
      "Iteration 75, loss = 2.78541378\n",
      "Iteration 76, loss = 2.72799902\n",
      "Iteration 77, loss = 2.67275153\n",
      "Iteration 78, loss = 2.61831746\n",
      "Iteration 79, loss = 2.56892130\n",
      "Iteration 80, loss = 2.51993910\n",
      "Iteration 81, loss = 2.47078445\n",
      "Iteration 82, loss = 2.42295150\n",
      "Iteration 83, loss = 2.37631160\n",
      "Iteration 84, loss = 2.33209842\n",
      "Iteration 85, loss = 2.29131139\n",
      "Iteration 86, loss = 2.25144596\n",
      "Iteration 87, loss = 2.20978635\n",
      "Iteration 88, loss = 2.17058312\n",
      "Iteration 89, loss = 2.13128640\n",
      "Iteration 90, loss = 2.09511058\n",
      "Iteration 91, loss = 2.06057165\n",
      "Iteration 92, loss = 2.02667889\n",
      "Iteration 93, loss = 1.99333144\n",
      "Iteration 94, loss = 1.96077422\n",
      "Iteration 95, loss = 1.93102141\n",
      "Iteration 96, loss = 1.90049563\n",
      "Iteration 97, loss = 1.87075795\n",
      "Iteration 98, loss = 1.84274193\n",
      "Iteration 99, loss = 1.81656685\n",
      "Iteration 100, loss = 1.79029160\n",
      "Iteration 101, loss = 1.76343612\n",
      "Iteration 102, loss = 1.73988448\n",
      "Iteration 103, loss = 1.71626496\n",
      "Iteration 104, loss = 1.69242139\n",
      "Iteration 105, loss = 1.67036077\n",
      "Iteration 106, loss = 1.64670954\n",
      "Iteration 107, loss = 1.62581180\n",
      "Iteration 108, loss = 1.60476765\n",
      "Iteration 109, loss = 1.58470487\n",
      "Iteration 110, loss = 1.56843489\n",
      "Iteration 111, loss = 1.54937447\n",
      "Iteration 112, loss = 1.52869291\n",
      "Iteration 113, loss = 1.51119071\n",
      "Iteration 114, loss = 1.49444991\n",
      "Iteration 115, loss = 1.47837556\n",
      "Iteration 116, loss = 1.46209738\n",
      "Iteration 117, loss = 1.44695005\n",
      "Iteration 118, loss = 1.43161295\n",
      "Iteration 119, loss = 1.41705254\n",
      "Iteration 120, loss = 1.40309267\n",
      "Iteration 121, loss = 1.39218308\n",
      "Iteration 122, loss = 1.37729172\n",
      "Iteration 123, loss = 1.36301538\n",
      "Iteration 124, loss = 1.35257885\n",
      "Iteration 125, loss = 1.34015878\n",
      "Iteration 126, loss = 1.32709161\n",
      "Iteration 127, loss = 1.31592266\n",
      "Iteration 128, loss = 1.30528680\n",
      "Iteration 129, loss = 1.29489596\n",
      "Iteration 130, loss = 1.28516207\n",
      "Iteration 131, loss = 1.27424468\n",
      "Iteration 132, loss = 1.26501064\n",
      "Iteration 133, loss = 1.25515593\n",
      "Iteration 134, loss = 1.24654503\n",
      "Iteration 135, loss = 1.23912379\n",
      "Iteration 136, loss = 1.23067185\n",
      "Iteration 137, loss = 1.22085864\n",
      "Iteration 138, loss = 1.21318047\n",
      "Iteration 139, loss = 1.20651809\n",
      "Iteration 140, loss = 1.19857386\n",
      "Iteration 141, loss = 1.18941134\n",
      "Iteration 142, loss = 1.18458475\n",
      "Iteration 143, loss = 1.17897226\n",
      "Iteration 144, loss = 1.17216313\n",
      "Iteration 145, loss = 1.16388643\n",
      "Iteration 146, loss = 1.15676524\n",
      "Iteration 147, loss = 1.15074362\n",
      "Iteration 148, loss = 1.14660582\n",
      "Iteration 149, loss = 1.13985068\n",
      "Iteration 150, loss = 1.13497164\n",
      "Iteration 151, loss = 1.12886083\n",
      "Iteration 152, loss = 1.12544922\n",
      "Iteration 153, loss = 1.11896674\n",
      "Iteration 154, loss = 1.11457092\n",
      "Iteration 155, loss = 1.10942260\n",
      "Iteration 156, loss = 1.10494252\n",
      "Iteration 157, loss = 1.10008453\n",
      "Iteration 158, loss = 1.09585348\n",
      "Iteration 159, loss = 1.09202012\n",
      "Iteration 160, loss = 1.08808950\n",
      "Iteration 161, loss = 1.08530101\n",
      "Iteration 162, loss = 1.07991176\n",
      "Iteration 163, loss = 1.07670513\n",
      "Iteration 164, loss = 1.07523927\n",
      "Iteration 165, loss = 1.07182827\n",
      "Iteration 166, loss = 1.06989702\n",
      "Iteration 167, loss = 1.06567625\n",
      "Iteration 168, loss = 1.06086829\n",
      "Iteration 169, loss = 1.05766180\n",
      "Iteration 170, loss = 1.05582228\n",
      "Iteration 171, loss = 1.05298954\n",
      "Iteration 172, loss = 1.04834636\n",
      "Iteration 173, loss = 1.04559032\n",
      "Iteration 174, loss = 1.04780890\n",
      "Iteration 175, loss = 1.04425208\n",
      "Iteration 176, loss = 1.03833139\n",
      "Iteration 177, loss = 1.03862815\n",
      "Iteration 178, loss = 1.03653848\n",
      "Iteration 179, loss = 1.03228906\n",
      "Iteration 180, loss = 1.02784957\n",
      "Iteration 181, loss = 1.02829808\n",
      "Iteration 182, loss = 1.02923241\n",
      "Iteration 183, loss = 1.02578781\n",
      "Iteration 184, loss = 1.02109624\n",
      "Iteration 185, loss = 1.02104625\n",
      "Iteration 186, loss = 1.02171742\n",
      "Iteration 187, loss = 1.01839233\n",
      "Iteration 188, loss = 1.01385183\n",
      "Iteration 189, loss = 1.01261287\n",
      "Iteration 190, loss = 1.01117397\n",
      "Iteration 191, loss = 1.00957772\n",
      "Iteration 192, loss = 1.00734006\n",
      "Iteration 193, loss = 1.00545695\n",
      "Iteration 194, loss = 1.00475228\n",
      "Iteration 195, loss = 1.00309574\n",
      "Iteration 196, loss = 1.00142197\n",
      "Iteration 197, loss = 1.00023481\n",
      "Iteration 198, loss = 0.99949935\n",
      "Iteration 199, loss = 0.99848815\n",
      "Iteration 200, loss = 0.99710533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;, &#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a16b5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.12234909263092575\n",
      "MAE: 1.0702081310719975\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d52308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA',\n",
    "          'PSH', 'PSD', 'PSA', 'WHH','WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'MaxH', 'MaxD', 'MaxA','AvgH', 'AvgD', 'AvgA', 'B365>2.5',\n",
    "          'B365<2.5', 'P>2.5', 'P<2.5', 'Max>2.5', 'Max<2.5', 'Avg>2.5', 'Avg<2.5', 'AHh', 'B365AHH','B365AHA', 'PAHH', 'PAHA', \n",
    "          'MaxAHH', 'MaxAHA', \"AvgAHH\", 'AvgAHA', 'B365CH', 'B365CD', 'B365CA', 'BWCH', 'BWCD', 'BWCA', 'IWCH', 'IWCD', 'IWCA',\n",
    "          'PSCH', 'PSCD', 'PSCA', 'WHCH', 'WHCD', 'WHCA', 'VCCH', 'VCCD', 'VCCA', 'MaxCH', 'MaxCD', 'MaxCA', 'AvgCH', 'AvgCD',\n",
    "          'AvgCA', 'B365C>2.5', 'B365C<2.5', 'PC>2.5', 'PC<2.5', 'MaxC>2.5', 'MaxC<2.5', 'AvgC>2.5', 'AvgC<2.5', 'AHCh', 'B365CAHH',\n",
    "          'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA', 'HStr', 'HSOH', 'HSOA', 'HSAH', 'HSAA', 'HSDH',\n",
    "          'HSDA', 'HO', 'HA', 'HM', 'HD', 'HDP', 'HIP', 'HSAAg', 'HATAAg', 'HGls', 'HAssts', 'HGlsPK', 'HxG', 'HNpxG', 'HxAG',\n",
    "          'HPoss', 'HPrg', 'HPrgP', 'HGKS%', 'HGKCS%', 'HSoT', 'Hg-xG', 'HCmp', 'HCmp%', 'HPrgDist', 'HXa', 'HKP', 'HPPA', 'HCrsPA',\n",
    "          'HTB', 'HCrs', 'HCK', 'HSCA', 'HGCA', 'HTkIW', 'HLost', 'HBlocks', 'HPass', 'HInt', 'HClr', 'HAttPen', 'HSucc%', 'HCPA',\n",
    "          'HDis', 'HPrgR', 'HOnG', 'HOnGA', 'HOnxG', 'HOnxGA', 'AStr', 'ASOH', 'ASOA', 'ASAH', 'ASAA', 'ASDH', 'ASDA', 'AO', 'AA',\n",
    "          'AM', 'AD', 'ADP', 'AIP', 'ASAAg', 'ATAAg', 'AGls', 'AAssts', 'AGlsPK', 'AxG', 'ANpxG', 'AxAG', 'APoss', 'APrg', 'APrgP',\n",
    "          'AGKS%', 'AGKCS%', 'ASoT', 'Ag-xG', 'ACmp', 'ACmp%', 'APrgDist', 'AXa', 'AKP', 'APPA', 'ACrsPA', 'ATB', 'ACrs', 'ACK',\n",
    "          'ASCA', 'AGCA', 'ATkIW', 'ALost', 'ABlocks', 'APass', 'AInt', 'AClr','AAttPen', 'ASucc%', 'ACPA', 'ADis', 'APrgR', 'AOnG',\n",
    "          'AOnGA', 'AOnxG', 'AOnxGA']].copy()\n",
    "y = data['FTAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae93a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f4818d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa628f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.79532087\n",
      "Iteration 2, loss = 0.67694661\n",
      "Iteration 3, loss = 0.68276273\n",
      "Iteration 4, loss = 0.62063257\n",
      "Iteration 5, loss = 0.59702395\n",
      "Iteration 6, loss = 0.60791907\n",
      "Iteration 7, loss = 0.58978668\n",
      "Iteration 8, loss = 0.56453466\n",
      "Iteration 9, loss = 0.56241486\n",
      "Iteration 10, loss = 0.56118206\n",
      "Iteration 11, loss = 0.54378928\n",
      "Iteration 12, loss = 0.53009301\n",
      "Iteration 13, loss = 0.52902315\n",
      "Iteration 14, loss = 0.51753340\n",
      "Iteration 15, loss = 0.50774802\n",
      "Iteration 16, loss = 0.50231157\n",
      "Iteration 17, loss = 0.49475243\n",
      "Iteration 18, loss = 0.48370358\n",
      "Iteration 19, loss = 0.48100836\n",
      "Iteration 20, loss = 0.47410775\n",
      "Iteration 21, loss = 0.46269614\n",
      "Iteration 22, loss = 0.45931835\n",
      "Iteration 23, loss = 0.45842426\n",
      "Iteration 24, loss = 0.45035888\n",
      "Iteration 25, loss = 0.44586915\n",
      "Iteration 26, loss = 0.43821003\n",
      "Iteration 27, loss = 0.43489455\n",
      "Iteration 28, loss = 0.42909796\n",
      "Iteration 29, loss = 0.42448444\n",
      "Iteration 30, loss = 0.41825841\n",
      "Iteration 31, loss = 0.41397857\n",
      "Iteration 32, loss = 0.41020441\n",
      "Iteration 33, loss = 0.40688470\n",
      "Iteration 34, loss = 0.40303761\n",
      "Iteration 35, loss = 0.39688223\n",
      "Iteration 36, loss = 0.39750159\n",
      "Iteration 37, loss = 0.39282748\n",
      "Iteration 38, loss = 0.38511627\n",
      "Iteration 39, loss = 0.38319598\n",
      "Iteration 40, loss = 0.38088061\n",
      "Iteration 41, loss = 0.37833573\n",
      "Iteration 42, loss = 0.37160306\n",
      "Iteration 43, loss = 0.36641188\n",
      "Iteration 44, loss = 0.36358016\n",
      "Iteration 45, loss = 0.35952567\n",
      "Iteration 46, loss = 0.35527021\n",
      "Iteration 47, loss = 0.35201602\n",
      "Iteration 48, loss = 0.34906793\n",
      "Iteration 49, loss = 0.34437379\n",
      "Iteration 50, loss = 0.34344176\n",
      "Iteration 51, loss = 0.34050240\n",
      "Iteration 52, loss = 0.33489900\n",
      "Iteration 53, loss = 0.33392512\n",
      "Iteration 54, loss = 0.32810672\n",
      "Iteration 55, loss = 0.32555956\n",
      "Iteration 56, loss = 0.32004824\n",
      "Iteration 57, loss = 0.31964007\n",
      "Iteration 58, loss = 0.31183324\n",
      "Iteration 59, loss = 0.31860860\n",
      "Iteration 60, loss = 0.30505155\n",
      "Iteration 61, loss = 0.31531901\n",
      "Iteration 62, loss = 0.30135605\n",
      "Iteration 63, loss = 0.30310834\n",
      "Iteration 64, loss = 0.30105670\n",
      "Iteration 65, loss = 0.29276834\n",
      "Iteration 66, loss = 0.29040399\n",
      "Iteration 67, loss = 0.28270283\n",
      "Iteration 68, loss = 0.28991915\n",
      "Iteration 69, loss = 0.28141989\n",
      "Iteration 70, loss = 0.27558936\n",
      "Iteration 71, loss = 0.27014363\n",
      "Iteration 72, loss = 0.26789641\n",
      "Iteration 73, loss = 0.26293055\n",
      "Iteration 74, loss = 0.26193279\n",
      "Iteration 75, loss = 0.25560077\n",
      "Iteration 76, loss = 0.26185147\n",
      "Iteration 77, loss = 0.25801751\n",
      "Iteration 78, loss = 0.24859988\n",
      "Iteration 79, loss = 0.24875427\n",
      "Iteration 80, loss = 0.24179678\n",
      "Iteration 81, loss = 0.23845785\n",
      "Iteration 82, loss = 0.23481287\n",
      "Iteration 83, loss = 0.23141176\n",
      "Iteration 84, loss = 0.22834874\n",
      "Iteration 85, loss = 0.22428980\n",
      "Iteration 86, loss = 0.22168316\n",
      "Iteration 87, loss = 0.21759534\n",
      "Iteration 88, loss = 0.21577323\n",
      "Iteration 89, loss = 0.21027468\n",
      "Iteration 90, loss = 0.20799392\n",
      "Iteration 91, loss = 0.20435896\n",
      "Iteration 92, loss = 0.20685238\n",
      "Iteration 93, loss = 0.20055966\n",
      "Iteration 94, loss = 0.19952464\n",
      "Iteration 95, loss = 0.19157009\n",
      "Iteration 96, loss = 0.19113290\n",
      "Iteration 97, loss = 0.18524212\n",
      "Iteration 98, loss = 0.18902283\n",
      "Iteration 99, loss = 0.18110478\n",
      "Iteration 100, loss = 0.18338035\n",
      "Iteration 101, loss = 0.17603216\n",
      "Iteration 102, loss = 0.17382643\n",
      "Iteration 103, loss = 0.16902095\n",
      "Iteration 104, loss = 0.16623401\n",
      "Iteration 105, loss = 0.16352645\n",
      "Iteration 106, loss = 0.16162815\n",
      "Iteration 107, loss = 0.15794905\n",
      "Iteration 108, loss = 0.15475084\n",
      "Iteration 109, loss = 0.15236128\n",
      "Iteration 110, loss = 0.14947995\n",
      "Iteration 111, loss = 0.14923913\n",
      "Iteration 112, loss = 0.14398457\n",
      "Iteration 113, loss = 0.14473918\n",
      "Iteration 114, loss = 0.13973784\n",
      "Iteration 115, loss = 0.13594050\n",
      "Iteration 116, loss = 0.13606033\n",
      "Iteration 117, loss = 0.13326814\n",
      "Iteration 118, loss = 0.13009104\n",
      "Iteration 119, loss = 0.12705890\n",
      "Iteration 120, loss = 0.12421095\n",
      "Iteration 121, loss = 0.12305612\n",
      "Iteration 122, loss = 0.12043827\n",
      "Iteration 123, loss = 0.11720050\n",
      "Iteration 124, loss = 0.11464832\n",
      "Iteration 125, loss = 0.11376586\n",
      "Iteration 126, loss = 0.10991800\n",
      "Iteration 127, loss = 0.10898528\n",
      "Iteration 128, loss = 0.10525004\n",
      "Iteration 129, loss = 0.10379732\n",
      "Iteration 130, loss = 0.10077887\n",
      "Iteration 131, loss = 0.09975447\n",
      "Iteration 132, loss = 0.09677680\n",
      "Iteration 133, loss = 0.09590017\n",
      "Iteration 134, loss = 0.09741849\n",
      "Iteration 135, loss = 0.09620901\n",
      "Iteration 136, loss = 0.09178215\n",
      "Iteration 137, loss = 0.09120371\n",
      "Iteration 138, loss = 0.08640378\n",
      "Iteration 139, loss = 0.08643742\n",
      "Iteration 140, loss = 0.08338465\n",
      "Iteration 141, loss = 0.08066883\n",
      "Iteration 142, loss = 0.07902693\n",
      "Iteration 143, loss = 0.07695557\n",
      "Iteration 144, loss = 0.07596723\n",
      "Iteration 145, loss = 0.07298689\n",
      "Iteration 146, loss = 0.07287386\n",
      "Iteration 147, loss = 0.06969801\n",
      "Iteration 148, loss = 0.06986868\n",
      "Iteration 149, loss = 0.06702601\n",
      "Iteration 150, loss = 0.06525594\n",
      "Iteration 151, loss = 0.06415499\n",
      "Iteration 152, loss = 0.06169383\n",
      "Iteration 153, loss = 0.06073693\n",
      "Iteration 154, loss = 0.06092820\n",
      "Iteration 155, loss = 0.05833143\n",
      "Iteration 156, loss = 0.05794581\n",
      "Iteration 157, loss = 0.05762876\n",
      "Iteration 158, loss = 0.05430975\n",
      "Iteration 159, loss = 0.05409019\n",
      "Iteration 160, loss = 0.05429708\n",
      "Iteration 161, loss = 0.05168152\n",
      "Iteration 162, loss = 0.04986022\n",
      "Iteration 163, loss = 0.05053521\n",
      "Iteration 164, loss = 0.04756046\n",
      "Iteration 165, loss = 0.04624498\n",
      "Iteration 166, loss = 0.04661020\n",
      "Iteration 167, loss = 0.04426787\n",
      "Iteration 168, loss = 0.04323416\n",
      "Iteration 169, loss = 0.04256872\n",
      "Iteration 170, loss = 0.04068486\n",
      "Iteration 171, loss = 0.03924709\n",
      "Iteration 172, loss = 0.03909680\n",
      "Iteration 173, loss = 0.03721004\n",
      "Iteration 174, loss = 0.03609197\n",
      "Iteration 175, loss = 0.03560771\n",
      "Iteration 176, loss = 0.03462095\n",
      "Iteration 177, loss = 0.03420971\n",
      "Iteration 178, loss = 0.03292500\n",
      "Iteration 179, loss = 0.03197408\n",
      "Iteration 180, loss = 0.03163012\n",
      "Iteration 181, loss = 0.03030859\n",
      "Iteration 182, loss = 0.02980337\n",
      "Iteration 183, loss = 0.02878119\n",
      "Iteration 184, loss = 0.02791763\n",
      "Iteration 185, loss = 0.02747774\n",
      "Iteration 186, loss = 0.02645695\n",
      "Iteration 187, loss = 0.02581561\n",
      "Iteration 188, loss = 0.02519147\n",
      "Iteration 189, loss = 0.02484691\n",
      "Iteration 190, loss = 0.02400306\n",
      "Iteration 191, loss = 0.02357224\n",
      "Iteration 192, loss = 0.02295940\n",
      "Iteration 193, loss = 0.02191755\n",
      "Iteration 194, loss = 0.02196532\n",
      "Iteration 195, loss = 0.02232803\n",
      "Iteration 196, loss = 0.02076145\n",
      "Iteration 197, loss = 0.02090304\n",
      "Iteration 198, loss = 0.01981594\n",
      "Iteration 199, loss = 0.01935282\n",
      "Iteration 200, loss = 0.01842099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;, &#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817c4044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.41438990427303524\n",
      "MAE: 1.063311861160067\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b45b8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.50251752\n",
      "Iteration 2, loss = 0.87320438\n",
      "Iteration 3, loss = 0.67480837\n",
      "Iteration 4, loss = 0.77371345\n",
      "Iteration 5, loss = 0.73480775\n",
      "Iteration 6, loss = 0.63384601\n",
      "Iteration 7, loss = 0.61353001\n",
      "Iteration 8, loss = 0.64285819\n",
      "Iteration 9, loss = 0.64385076\n",
      "Iteration 10, loss = 0.61103829\n",
      "Iteration 11, loss = 0.58026444\n",
      "Iteration 12, loss = 0.58749650\n",
      "Iteration 13, loss = 0.57875891\n",
      "Iteration 14, loss = 0.56302188\n",
      "Iteration 15, loss = 0.55237829\n",
      "Iteration 16, loss = 0.54861994\n",
      "Iteration 17, loss = 0.54313786\n",
      "Iteration 18, loss = 0.53063929\n",
      "Iteration 19, loss = 0.52666625\n",
      "Iteration 20, loss = 0.52594878\n",
      "Iteration 21, loss = 0.51217679\n",
      "Iteration 22, loss = 0.50230111\n",
      "Iteration 23, loss = 0.50132813\n",
      "Iteration 24, loss = 0.49177235\n",
      "Iteration 25, loss = 0.47842165\n",
      "Iteration 26, loss = 0.47261221\n",
      "Iteration 27, loss = 0.46453254\n",
      "Iteration 28, loss = 0.45253421\n",
      "Iteration 29, loss = 0.44325927\n",
      "Iteration 30, loss = 0.43272415\n",
      "Iteration 31, loss = 0.42115395\n",
      "Iteration 32, loss = 0.41127356\n",
      "Iteration 33, loss = 0.40177291\n",
      "Iteration 34, loss = 0.39067987\n",
      "Iteration 35, loss = 0.38155588\n",
      "Iteration 36, loss = 0.37151980\n",
      "Iteration 37, loss = 0.36293436\n",
      "Iteration 38, loss = 0.35293623\n",
      "Iteration 39, loss = 0.33982011\n",
      "Iteration 40, loss = 0.33978793\n",
      "Iteration 41, loss = 0.32332904\n",
      "Iteration 42, loss = 0.31958026\n",
      "Iteration 43, loss = 0.30400499\n",
      "Iteration 44, loss = 0.29792486\n",
      "Iteration 45, loss = 0.27989497\n",
      "Iteration 46, loss = 0.28228844\n",
      "Iteration 47, loss = 0.25907054\n",
      "Iteration 48, loss = 0.24577919\n",
      "Iteration 49, loss = 0.23660318\n",
      "Iteration 50, loss = 0.22620308\n",
      "Iteration 51, loss = 0.21895535\n",
      "Iteration 52, loss = 0.20544328\n",
      "Iteration 53, loss = 0.19433973\n",
      "Iteration 54, loss = 0.18945393\n",
      "Iteration 55, loss = 0.16906861\n",
      "Iteration 56, loss = 0.17755418\n",
      "Iteration 57, loss = 0.15939043\n",
      "Iteration 58, loss = 0.14693846\n",
      "Iteration 59, loss = 0.13838222\n",
      "Iteration 60, loss = 0.12597264\n",
      "Iteration 61, loss = 0.11645361\n",
      "Iteration 62, loss = 0.10874420\n",
      "Iteration 63, loss = 0.10083609\n",
      "Iteration 64, loss = 0.09350174\n",
      "Iteration 65, loss = 0.08661816\n",
      "Iteration 66, loss = 0.08189892\n",
      "Iteration 67, loss = 0.07727025\n",
      "Iteration 68, loss = 0.06889984\n",
      "Iteration 69, loss = 0.06272932\n",
      "Iteration 70, loss = 0.05674691\n",
      "Iteration 71, loss = 0.05500945\n",
      "Iteration 72, loss = 0.05368857\n",
      "Iteration 73, loss = 0.05175503\n",
      "Iteration 74, loss = 0.05303359\n",
      "Iteration 75, loss = 0.04287167\n",
      "Iteration 76, loss = 0.03603444\n",
      "Iteration 77, loss = 0.03728228\n",
      "Iteration 78, loss = 0.03001962\n",
      "Iteration 79, loss = 0.03453352\n",
      "Iteration 80, loss = 0.02682783\n",
      "Iteration 81, loss = 0.03436747\n",
      "Iteration 82, loss = 0.02943962\n",
      "Iteration 83, loss = 0.02352086\n",
      "Iteration 84, loss = 0.01912130\n",
      "Iteration 85, loss = 0.02425801\n",
      "Iteration 86, loss = 0.02159374\n",
      "Iteration 87, loss = 0.02227217\n",
      "Iteration 88, loss = 0.02418683\n",
      "Iteration 89, loss = 0.02040565\n",
      "Iteration 90, loss = 0.02522090\n",
      "Iteration 91, loss = 0.02710610\n",
      "Iteration 92, loss = 0.02556304\n",
      "Iteration 93, loss = 0.02561210\n",
      "Iteration 94, loss = 0.02886745\n",
      "Iteration 95, loss = 0.02308052\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;, &#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c4e035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.4784722836486597\n",
      "MAE: 1.1146203473240428\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "679b49a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 19.31425227\n",
      "Iteration 2, loss = 18.58302387\n",
      "Iteration 3, loss = 17.98168921\n",
      "Iteration 4, loss = 17.46184320\n",
      "Iteration 5, loss = 16.95932791\n",
      "Iteration 6, loss = 16.45449064\n",
      "Iteration 7, loss = 15.95300323\n",
      "Iteration 8, loss = 15.46115426\n",
      "Iteration 9, loss = 14.98767249\n",
      "Iteration 10, loss = 14.52965294\n",
      "Iteration 11, loss = 14.08627177\n",
      "Iteration 12, loss = 13.65367965\n",
      "Iteration 13, loss = 13.23143220\n",
      "Iteration 14, loss = 12.81949517\n",
      "Iteration 15, loss = 12.41890764\n",
      "Iteration 16, loss = 12.03128483\n",
      "Iteration 17, loss = 11.65733951\n",
      "Iteration 18, loss = 11.29480395\n",
      "Iteration 19, loss = 10.94370207\n",
      "Iteration 20, loss = 10.60299672\n",
      "Iteration 21, loss = 10.27285674\n",
      "Iteration 22, loss = 9.95226875\n",
      "Iteration 23, loss = 9.64241116\n",
      "Iteration 24, loss = 9.34333622\n",
      "Iteration 25, loss = 9.05407950\n",
      "Iteration 26, loss = 8.77361028\n",
      "Iteration 27, loss = 8.50243842\n",
      "Iteration 28, loss = 8.24025051\n",
      "Iteration 29, loss = 7.98677443\n",
      "Iteration 30, loss = 7.74127087\n",
      "Iteration 31, loss = 7.50400830\n",
      "Iteration 32, loss = 7.27487959\n",
      "Iteration 33, loss = 7.05341353\n",
      "Iteration 34, loss = 6.83988685\n",
      "Iteration 35, loss = 6.63310452\n",
      "Iteration 36, loss = 6.43205124\n",
      "Iteration 37, loss = 6.23833894\n",
      "Iteration 38, loss = 6.05091638\n",
      "Iteration 39, loss = 5.87008126\n",
      "Iteration 40, loss = 5.69495490\n",
      "Iteration 41, loss = 5.52671590\n",
      "Iteration 42, loss = 5.36284390\n",
      "Iteration 43, loss = 5.20444491\n",
      "Iteration 44, loss = 5.05203583\n",
      "Iteration 45, loss = 4.90493854\n",
      "Iteration 46, loss = 4.76280263\n",
      "Iteration 47, loss = 4.62480754\n",
      "Iteration 48, loss = 4.49175847\n",
      "Iteration 49, loss = 4.36333349\n",
      "Iteration 50, loss = 4.23941098\n",
      "Iteration 51, loss = 4.11985366\n",
      "Iteration 52, loss = 4.00321366\n",
      "Iteration 53, loss = 3.89183608\n",
      "Iteration 54, loss = 3.78409480\n",
      "Iteration 55, loss = 3.67993288\n",
      "Iteration 56, loss = 3.57930893\n",
      "Iteration 57, loss = 3.48146392\n",
      "Iteration 58, loss = 3.38776259\n",
      "Iteration 59, loss = 3.29690794\n",
      "Iteration 60, loss = 3.20832756\n",
      "Iteration 61, loss = 3.12449464\n",
      "Iteration 62, loss = 3.04186649\n",
      "Iteration 63, loss = 2.96290599\n",
      "Iteration 64, loss = 2.88646604\n",
      "Iteration 65, loss = 2.81246010\n",
      "Iteration 66, loss = 2.74100145\n",
      "Iteration 67, loss = 2.67244457\n",
      "Iteration 68, loss = 2.60613512\n",
      "Iteration 69, loss = 2.54132790\n",
      "Iteration 70, loss = 2.47984721\n",
      "Iteration 71, loss = 2.41965251\n",
      "Iteration 72, loss = 2.36208561\n",
      "Iteration 73, loss = 2.30577250\n",
      "Iteration 74, loss = 2.25150100\n",
      "Iteration 75, loss = 2.19959872\n",
      "Iteration 76, loss = 2.14906708\n",
      "Iteration 77, loss = 2.10097021\n",
      "Iteration 78, loss = 2.05382313\n",
      "Iteration 79, loss = 2.00815103\n",
      "Iteration 80, loss = 1.96388435\n",
      "Iteration 81, loss = 1.92176390\n",
      "Iteration 82, loss = 1.88123427\n",
      "Iteration 83, loss = 1.84208086\n",
      "Iteration 84, loss = 1.80388236\n",
      "Iteration 85, loss = 1.76690319\n",
      "Iteration 86, loss = 1.73117330\n",
      "Iteration 87, loss = 1.69657780\n",
      "Iteration 88, loss = 1.66377125\n",
      "Iteration 89, loss = 1.63120681\n",
      "Iteration 90, loss = 1.60164919\n",
      "Iteration 91, loss = 1.57118352\n",
      "Iteration 92, loss = 1.54226067\n",
      "Iteration 93, loss = 1.51412498\n",
      "Iteration 94, loss = 1.48700205\n",
      "Iteration 95, loss = 1.46092084\n",
      "Iteration 96, loss = 1.43558031\n",
      "Iteration 97, loss = 1.41172676\n",
      "Iteration 98, loss = 1.38762630\n",
      "Iteration 99, loss = 1.36568898\n",
      "Iteration 100, loss = 1.34305369\n",
      "Iteration 101, loss = 1.32204464\n",
      "Iteration 102, loss = 1.30160014\n",
      "Iteration 103, loss = 1.28189896\n",
      "Iteration 104, loss = 1.26264560\n",
      "Iteration 105, loss = 1.24429880\n",
      "Iteration 106, loss = 1.22658629\n",
      "Iteration 107, loss = 1.20924150\n",
      "Iteration 108, loss = 1.19249028\n",
      "Iteration 109, loss = 1.17667503\n",
      "Iteration 110, loss = 1.16106642\n",
      "Iteration 111, loss = 1.14615505\n",
      "Iteration 112, loss = 1.13154845\n",
      "Iteration 113, loss = 1.11751551\n",
      "Iteration 114, loss = 1.10411664\n",
      "Iteration 115, loss = 1.09106226\n",
      "Iteration 116, loss = 1.07893366\n",
      "Iteration 117, loss = 1.06650100\n",
      "Iteration 118, loss = 1.05483445\n",
      "Iteration 119, loss = 1.04371286\n",
      "Iteration 120, loss = 1.03302402\n",
      "Iteration 121, loss = 1.02276821\n",
      "Iteration 122, loss = 1.01283101\n",
      "Iteration 123, loss = 1.00304197\n",
      "Iteration 124, loss = 0.99340679\n",
      "Iteration 125, loss = 0.98390427\n",
      "Iteration 126, loss = 0.97498673\n",
      "Iteration 127, loss = 0.96648763\n",
      "Iteration 128, loss = 0.95855317\n",
      "Iteration 129, loss = 0.95046653\n",
      "Iteration 130, loss = 0.94293845\n",
      "Iteration 131, loss = 0.93563577\n",
      "Iteration 132, loss = 0.92848608\n",
      "Iteration 133, loss = 0.92146437\n",
      "Iteration 134, loss = 0.91464925\n",
      "Iteration 135, loss = 0.90819755\n",
      "Iteration 136, loss = 0.90200339\n",
      "Iteration 137, loss = 0.89622667\n",
      "Iteration 138, loss = 0.89061927\n",
      "Iteration 139, loss = 0.88512607\n",
      "Iteration 140, loss = 0.87949450\n",
      "Iteration 141, loss = 0.87395208\n",
      "Iteration 142, loss = 0.86919496\n",
      "Iteration 143, loss = 0.86426350\n",
      "Iteration 144, loss = 0.85966991\n",
      "Iteration 145, loss = 0.85526180\n",
      "Iteration 146, loss = 0.85068693\n",
      "Iteration 147, loss = 0.84687166\n",
      "Iteration 148, loss = 0.84260834\n",
      "Iteration 149, loss = 0.83837677\n",
      "Iteration 150, loss = 0.83425440\n",
      "Iteration 151, loss = 0.83064604\n",
      "Iteration 152, loss = 0.82805762\n",
      "Iteration 153, loss = 0.82563212\n",
      "Iteration 154, loss = 0.82232820\n",
      "Iteration 155, loss = 0.81962116\n",
      "Iteration 156, loss = 0.81631857\n",
      "Iteration 157, loss = 0.81308383\n",
      "Iteration 158, loss = 0.80965766\n",
      "Iteration 159, loss = 0.80658698\n",
      "Iteration 160, loss = 0.80389223\n",
      "Iteration 161, loss = 0.80182981\n",
      "Iteration 162, loss = 0.79939307\n",
      "Iteration 163, loss = 0.79686569\n",
      "Iteration 164, loss = 0.79452564\n",
      "Iteration 165, loss = 0.79246951\n",
      "Iteration 166, loss = 0.79069345\n",
      "Iteration 167, loss = 0.78802500\n",
      "Iteration 168, loss = 0.78603162\n",
      "Iteration 169, loss = 0.78423095\n",
      "Iteration 170, loss = 0.78250096\n",
      "Iteration 171, loss = 0.78094684\n",
      "Iteration 172, loss = 0.77912926\n",
      "Iteration 173, loss = 0.77745135\n",
      "Iteration 174, loss = 0.77615698\n",
      "Iteration 175, loss = 0.77502235\n",
      "Iteration 176, loss = 0.77336442\n",
      "Iteration 177, loss = 0.77209968\n",
      "Iteration 178, loss = 0.77041317\n",
      "Iteration 179, loss = 0.76942612\n",
      "Iteration 180, loss = 0.76806718\n",
      "Iteration 181, loss = 0.76687016\n",
      "Iteration 182, loss = 0.76560965\n",
      "Iteration 183, loss = 0.76444308\n",
      "Iteration 184, loss = 0.76336426\n",
      "Iteration 185, loss = 0.76283264\n",
      "Iteration 186, loss = 0.76184882\n",
      "Iteration 187, loss = 0.76106964\n",
      "Iteration 188, loss = 0.75946802\n",
      "Iteration 189, loss = 0.75861522\n",
      "Iteration 190, loss = 0.75779081\n",
      "Iteration 191, loss = 0.75722586\n",
      "Iteration 192, loss = 0.75653548\n",
      "Iteration 193, loss = 0.75567473\n",
      "Iteration 194, loss = 0.75502752\n",
      "Iteration 195, loss = 0.75418289\n",
      "Iteration 196, loss = 0.75334460\n",
      "Iteration 197, loss = 0.75253392\n",
      "Iteration 198, loss = 0.75184183\n",
      "Iteration 199, loss = 0.75144816\n",
      "Iteration 200, loss = 0.75105074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;, &#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be1db04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.01749437903072537\n",
      "MAE: 0.9318830342065986\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc0adba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TeamH</th>\n",
       "      <th>TeamA</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HR</th>\n",
       "      <th>AR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>IWA</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PSD</th>\n",
       "      <th>PSA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>P&gt;2.5</th>\n",
       "      <th>P&lt;2.5</th>\n",
       "      <th>Max&gt;2.5</th>\n",
       "      <th>Max&lt;2.5</th>\n",
       "      <th>Avg&gt;2.5</th>\n",
       "      <th>Avg&lt;2.5</th>\n",
       "      <th>AHh</th>\n",
       "      <th>B365AHH</th>\n",
       "      <th>B365AHA</th>\n",
       "      <th>PAHH</th>\n",
       "      <th>PAHA</th>\n",
       "      <th>MaxAHH</th>\n",
       "      <th>MaxAHA</th>\n",
       "      <th>AvgAHH</th>\n",
       "      <th>AvgAHA</th>\n",
       "      <th>B365CH</th>\n",
       "      <th>B365CD</th>\n",
       "      <th>B365CA</th>\n",
       "      <th>BWCH</th>\n",
       "      <th>BWCD</th>\n",
       "      <th>BWCA</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>WHCH</th>\n",
       "      <th>WHCD</th>\n",
       "      <th>WHCA</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>MaxCH</th>\n",
       "      <th>MaxCD</th>\n",
       "      <th>MaxCA</th>\n",
       "      <th>AvgCH</th>\n",
       "      <th>AvgCD</th>\n",
       "      <th>AvgCA</th>\n",
       "      <th>B365C&gt;2.5</th>\n",
       "      <th>B365C&lt;2.5</th>\n",
       "      <th>PC&gt;2.5</th>\n",
       "      <th>PC&lt;2.5</th>\n",
       "      <th>MaxC&gt;2.5</th>\n",
       "      <th>MaxC&lt;2.5</th>\n",
       "      <th>AvgC&gt;2.5</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5/8/2022</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.89</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.88</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>5.01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Date   Time           TeamH    TeamA  FTHG  FTAG FTR  HTHG  \\\n",
       "0           0  5/8/2022  20:00  Crystal Palace  Arsenal     0     2   A     0   \n",
       "\n",
       "   HTAG HTR   Referee  HR  AR  B365H  B365D  B365A   BWH  BWD   BWA  IWH  \\\n",
       "0     1   A  A Taylor   0   0    4.2    3.6   1.85  4.33  3.5  1.87  4.3   \n",
       "\n",
       "    IWD   IWA  PSH   PSD   PSA  WHH  WHD   WHA  VCH  VCD   VCA  MaxH  MaxD  \\\n",
       "0  3.55  1.85  4.5  3.65  1.89  4.4  3.5  1.83  4.6  3.5  1.87   4.6  3.78   \n",
       "\n",
       "   MaxA  AvgH  AvgD  AvgA  B365>2.5  B365<2.5  P>2.5  P<2.5  Max>2.5  Max<2.5  \\\n",
       "0  1.95  4.39  3.59  1.88       2.1      1.72   2.14   1.78     2.19     1.91   \n",
       "\n",
       "   Avg>2.5  Avg<2.5  AHh  B365AHH  B365AHA  PAHH  PAHA  MaxAHH  MaxAHA  \\\n",
       "0     2.09     1.76  0.5     2.04     1.89  2.03  1.89    2.06    1.91   \n",
       "\n",
       "   AvgAHH  AvgAHA  B365CH  B365CD  B365CA  BWCH  BWCD  BWCA  IWCH  IWCD  IWCA  \\\n",
       "0    2.01    1.87     4.5     3.6     1.8   4.5   3.5  1.83   4.4  3.55  1.85   \n",
       "\n",
       "   PSCH  PSCD  PSCA  WHCH  WHCD  WHCA  VCCH  VCCD  VCCA  MaxCH  MaxCD  MaxCA  \\\n",
       "0  4.58  3.63  1.88   4.8   3.4  1.78  4.75   3.5  1.85   5.01    3.7   1.91   \n",
       "\n",
       "   AvgCH  AvgCD  AvgCA  B365C>2.5  B365C<2.5  PC>2.5  PC<2.5  MaxC>2.5  \\\n",
       "0   4.56   3.57   1.85        2.1       1.72    2.14    1.78      2.19   \n",
       "\n",
       "   MaxC<2.5  AvgC>2.5  AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  \\\n",
       "0      1.91      2.08      1.76   0.5      2.09      1.84   2.04   1.88   \n",
       "\n",
       "   MaxCAHH  MaxCAHA  AvgCAHH  AvgCAHA  \n",
       "0     2.09     1.88     2.03     1.85  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data1 = pd.read_csv('../data/data_betting.csv')\n",
    "data1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cf07508",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA',\n",
    "          'PSH', 'PSD', 'PSA', 'WHH','WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'MaxH', 'MaxD', 'MaxA','AvgH', 'AvgD', 'AvgA', 'B365>2.5',\n",
    "          'B365<2.5', 'P>2.5', 'P<2.5', 'Max>2.5', 'Max<2.5', 'Avg>2.5', 'Avg<2.5', 'AHh', 'B365AHH','B365AHA', 'PAHH', 'PAHA', \n",
    "          'MaxAHH', 'MaxAHA', \"AvgAHH\", 'AvgAHA', 'B365CH', 'B365CD', 'B365CA', 'BWCH', 'BWCD', 'BWCA', 'IWCH', 'IWCD', 'IWCA',\n",
    "          'PSCH', 'PSCD', 'PSCA', 'WHCH', 'WHCD', 'WHCA', 'VCCH', 'VCCD', 'VCCA', 'MaxCH', 'MaxCD', 'MaxCA', 'AvgCH', 'AvgCD',\n",
    "          'AvgCA', 'B365C>2.5', 'B365C<2.5', 'PC>2.5', 'PC<2.5', 'MaxC>2.5', 'MaxC<2.5', 'AvgC>2.5', 'AvgC<2.5', 'AHCh', 'B365CAHH',\n",
    "          'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA']].copy()\n",
    "y = data1['FTHG'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b413ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e53be3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f56269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.63774676\n",
      "Iteration 2, loss = 2.02666592\n",
      "Iteration 3, loss = 1.57818322\n",
      "Iteration 4, loss = 1.25187519\n",
      "Iteration 5, loss = 1.03485893\n",
      "Iteration 6, loss = 0.93122724\n",
      "Iteration 7, loss = 0.90677772\n",
      "Iteration 8, loss = 0.90720594\n",
      "Iteration 9, loss = 0.91288749\n",
      "Iteration 10, loss = 0.91445973\n",
      "Iteration 11, loss = 0.89584128\n",
      "Iteration 12, loss = 0.86206418\n",
      "Iteration 13, loss = 0.82214814\n",
      "Iteration 14, loss = 0.78765142\n",
      "Iteration 15, loss = 0.76192896\n",
      "Iteration 16, loss = 0.74283057\n",
      "Iteration 17, loss = 0.73318938\n",
      "Iteration 18, loss = 0.72747489\n",
      "Iteration 19, loss = 0.72237597\n",
      "Iteration 20, loss = 0.71647864\n",
      "Iteration 21, loss = 0.70954070\n",
      "Iteration 22, loss = 0.70155300\n",
      "Iteration 23, loss = 0.69278563\n",
      "Iteration 24, loss = 0.68734971\n",
      "Iteration 25, loss = 0.67936098\n",
      "Iteration 26, loss = 0.67555211\n",
      "Iteration 27, loss = 0.67049945\n",
      "Iteration 28, loss = 0.66621735\n",
      "Iteration 29, loss = 0.66194985\n",
      "Iteration 30, loss = 0.65749930\n",
      "Iteration 31, loss = 0.65325544\n",
      "Iteration 32, loss = 0.64868287\n",
      "Iteration 33, loss = 0.64322035\n",
      "Iteration 34, loss = 0.63812592\n",
      "Iteration 35, loss = 0.63221842\n",
      "Iteration 36, loss = 0.62704893\n",
      "Iteration 37, loss = 0.62326076\n",
      "Iteration 38, loss = 0.61896494\n",
      "Iteration 39, loss = 0.61553415\n",
      "Iteration 40, loss = 0.61233510\n",
      "Iteration 41, loss = 0.60761171\n",
      "Iteration 42, loss = 0.60355202\n",
      "Iteration 43, loss = 0.59923776\n",
      "Iteration 44, loss = 0.59525813\n",
      "Iteration 45, loss = 0.59126019\n",
      "Iteration 46, loss = 0.58726967\n",
      "Iteration 47, loss = 0.58358714\n",
      "Iteration 48, loss = 0.57939352\n",
      "Iteration 49, loss = 0.57610469\n",
      "Iteration 50, loss = 0.57231597\n",
      "Iteration 51, loss = 0.56859953\n",
      "Iteration 52, loss = 0.56465924\n",
      "Iteration 53, loss = 0.56149566\n",
      "Iteration 54, loss = 0.55808022\n",
      "Iteration 55, loss = 0.55461530\n",
      "Iteration 56, loss = 0.55147402\n",
      "Iteration 57, loss = 0.54842601\n",
      "Iteration 58, loss = 0.54528212\n",
      "Iteration 59, loss = 0.54169174\n",
      "Iteration 60, loss = 0.53868658\n",
      "Iteration 61, loss = 0.53495820\n",
      "Iteration 62, loss = 0.53195951\n",
      "Iteration 63, loss = 0.52869482\n",
      "Iteration 64, loss = 0.52540223\n",
      "Iteration 65, loss = 0.52245921\n",
      "Iteration 66, loss = 0.51984892\n",
      "Iteration 67, loss = 0.51669812\n",
      "Iteration 68, loss = 0.51393052\n",
      "Iteration 69, loss = 0.51024299\n",
      "Iteration 70, loss = 0.50772750\n",
      "Iteration 71, loss = 0.50396464\n",
      "Iteration 72, loss = 0.50089201\n",
      "Iteration 73, loss = 0.49786652\n",
      "Iteration 74, loss = 0.49452131\n",
      "Iteration 75, loss = 0.49150827\n",
      "Iteration 76, loss = 0.48817863\n",
      "Iteration 77, loss = 0.48522561\n",
      "Iteration 78, loss = 0.48177356\n",
      "Iteration 79, loss = 0.47893307\n",
      "Iteration 80, loss = 0.47700518\n",
      "Iteration 81, loss = 0.47381288\n",
      "Iteration 82, loss = 0.47022240\n",
      "Iteration 83, loss = 0.46712122\n",
      "Iteration 84, loss = 0.46367834\n",
      "Iteration 85, loss = 0.46063699\n",
      "Iteration 86, loss = 0.45727108\n",
      "Iteration 87, loss = 0.45403878\n",
      "Iteration 88, loss = 0.45099359\n",
      "Iteration 89, loss = 0.44841450\n",
      "Iteration 90, loss = 0.44530754\n",
      "Iteration 91, loss = 0.44201482\n",
      "Iteration 92, loss = 0.43871408\n",
      "Iteration 93, loss = 0.43594476\n",
      "Iteration 94, loss = 0.43333009\n",
      "Iteration 95, loss = 0.43014009\n",
      "Iteration 96, loss = 0.42708089\n",
      "Iteration 97, loss = 0.42354019\n",
      "Iteration 98, loss = 0.42056249\n",
      "Iteration 99, loss = 0.41777140\n",
      "Iteration 100, loss = 0.41448729\n",
      "Iteration 101, loss = 0.41167133\n",
      "Iteration 102, loss = 0.40873368\n",
      "Iteration 103, loss = 0.40520832\n",
      "Iteration 104, loss = 0.40248014\n",
      "Iteration 105, loss = 0.39927901\n",
      "Iteration 106, loss = 0.39674619\n",
      "Iteration 107, loss = 0.39326894\n",
      "Iteration 108, loss = 0.39018518\n",
      "Iteration 109, loss = 0.38669697\n",
      "Iteration 110, loss = 0.38321108\n",
      "Iteration 111, loss = 0.37994535\n",
      "Iteration 112, loss = 0.37703072\n",
      "Iteration 113, loss = 0.37362733\n",
      "Iteration 114, loss = 0.36978628\n",
      "Iteration 115, loss = 0.36857885\n",
      "Iteration 116, loss = 0.36401080\n",
      "Iteration 117, loss = 0.36034239\n",
      "Iteration 118, loss = 0.35860461\n",
      "Iteration 119, loss = 0.35538534\n",
      "Iteration 120, loss = 0.35221227\n",
      "Iteration 121, loss = 0.34818900\n",
      "Iteration 122, loss = 0.34543362\n",
      "Iteration 123, loss = 0.34163939\n",
      "Iteration 124, loss = 0.33946162\n",
      "Iteration 125, loss = 0.33732678\n",
      "Iteration 126, loss = 0.33236582\n",
      "Iteration 127, loss = 0.32967994\n",
      "Iteration 128, loss = 0.32851039\n",
      "Iteration 129, loss = 0.32454816\n",
      "Iteration 130, loss = 0.32130098\n",
      "Iteration 131, loss = 0.31716818\n",
      "Iteration 132, loss = 0.31385461\n",
      "Iteration 133, loss = 0.30986551\n",
      "Iteration 134, loss = 0.30687223\n",
      "Iteration 135, loss = 0.30400966\n",
      "Iteration 136, loss = 0.30119498\n",
      "Iteration 137, loss = 0.29763543\n",
      "Iteration 138, loss = 0.29380530\n",
      "Iteration 139, loss = 0.29063280\n",
      "Iteration 140, loss = 0.28796103\n",
      "Iteration 141, loss = 0.28372048\n",
      "Iteration 142, loss = 0.28083637\n",
      "Iteration 143, loss = 0.27790869\n",
      "Iteration 144, loss = 0.27481908\n",
      "Iteration 145, loss = 0.27172598\n",
      "Iteration 146, loss = 0.26871281\n",
      "Iteration 147, loss = 0.26559183\n",
      "Iteration 148, loss = 0.26165070\n",
      "Iteration 149, loss = 0.25907952\n",
      "Iteration 150, loss = 0.25582717\n",
      "Iteration 151, loss = 0.25228411\n",
      "Iteration 152, loss = 0.25028180\n",
      "Iteration 153, loss = 0.24703699\n",
      "Iteration 154, loss = 0.24349522\n",
      "Iteration 155, loss = 0.24012557\n",
      "Iteration 156, loss = 0.23685502\n",
      "Iteration 157, loss = 0.23395399\n",
      "Iteration 158, loss = 0.23097217\n",
      "Iteration 159, loss = 0.22749657\n",
      "Iteration 160, loss = 0.22461702\n",
      "Iteration 161, loss = 0.22156873\n",
      "Iteration 162, loss = 0.21854635\n",
      "Iteration 163, loss = 0.21498155\n",
      "Iteration 164, loss = 0.21265681\n",
      "Iteration 165, loss = 0.20938888\n",
      "Iteration 166, loss = 0.20678674\n",
      "Iteration 167, loss = 0.20411632\n",
      "Iteration 168, loss = 0.20108479\n",
      "Iteration 169, loss = 0.19775706\n",
      "Iteration 170, loss = 0.19472780\n",
      "Iteration 171, loss = 0.19213989\n",
      "Iteration 172, loss = 0.18950236\n",
      "Iteration 173, loss = 0.18641752\n",
      "Iteration 174, loss = 0.18389204\n",
      "Iteration 175, loss = 0.18123829\n",
      "Iteration 176, loss = 0.17875118\n",
      "Iteration 177, loss = 0.17594790\n",
      "Iteration 178, loss = 0.17332662\n",
      "Iteration 179, loss = 0.17097783\n",
      "Iteration 180, loss = 0.16828859\n",
      "Iteration 181, loss = 0.16522359\n",
      "Iteration 182, loss = 0.16270124\n",
      "Iteration 183, loss = 0.15979350\n",
      "Iteration 184, loss = 0.15756950\n",
      "Iteration 185, loss = 0.15563597\n",
      "Iteration 186, loss = 0.15296776\n",
      "Iteration 187, loss = 0.15014781\n",
      "Iteration 188, loss = 0.14792037\n",
      "Iteration 189, loss = 0.14571437\n",
      "Iteration 190, loss = 0.14298624\n",
      "Iteration 191, loss = 0.14082071\n",
      "Iteration 192, loss = 0.13809345\n",
      "Iteration 193, loss = 0.13622286\n",
      "Iteration 194, loss = 0.13373777\n",
      "Iteration 195, loss = 0.13177082\n",
      "Iteration 196, loss = 0.12928857\n",
      "Iteration 197, loss = 0.12700880\n",
      "Iteration 198, loss = 0.12526072\n",
      "Iteration 199, loss = 0.12291382\n",
      "Iteration 200, loss = 0.12127481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce8fb61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.2146162970043708\n",
      "MAE: 1.2188569471177622\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d16c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.82666208\n",
      "Iteration 2, loss = 1.36756118\n",
      "Iteration 3, loss = 1.07735303\n",
      "Iteration 4, loss = 0.93876164\n",
      "Iteration 5, loss = 0.93490384\n",
      "Iteration 6, loss = 0.94247276\n",
      "Iteration 7, loss = 0.91283649\n",
      "Iteration 8, loss = 0.85059866\n",
      "Iteration 9, loss = 0.80238055\n",
      "Iteration 10, loss = 0.77804352\n",
      "Iteration 11, loss = 0.76722171\n",
      "Iteration 12, loss = 0.75633999\n",
      "Iteration 13, loss = 0.73841150\n",
      "Iteration 14, loss = 0.72310298\n",
      "Iteration 15, loss = 0.71021713\n",
      "Iteration 16, loss = 0.71264659\n",
      "Iteration 17, loss = 0.70552359\n",
      "Iteration 18, loss = 0.69245686\n",
      "Iteration 19, loss = 0.68081027\n",
      "Iteration 20, loss = 0.67018947\n",
      "Iteration 21, loss = 0.66044341\n",
      "Iteration 22, loss = 0.65160388\n",
      "Iteration 23, loss = 0.63980495\n",
      "Iteration 24, loss = 0.62804648\n",
      "Iteration 25, loss = 0.62469891\n",
      "Iteration 26, loss = 0.61492151\n",
      "Iteration 27, loss = 0.59910482\n",
      "Iteration 28, loss = 0.58515943\n",
      "Iteration 29, loss = 0.57611016\n",
      "Iteration 30, loss = 0.56181507\n",
      "Iteration 31, loss = 0.54825608\n",
      "Iteration 32, loss = 0.53831198\n",
      "Iteration 33, loss = 0.52224224\n",
      "Iteration 34, loss = 0.51203088\n",
      "Iteration 35, loss = 0.50298108\n",
      "Iteration 36, loss = 0.48035819\n",
      "Iteration 37, loss = 0.46902147\n",
      "Iteration 38, loss = 0.45534089\n",
      "Iteration 39, loss = 0.43963931\n",
      "Iteration 40, loss = 0.42224057\n",
      "Iteration 41, loss = 0.40550330\n",
      "Iteration 42, loss = 0.39393190\n",
      "Iteration 43, loss = 0.37269494\n",
      "Iteration 44, loss = 0.35969429\n",
      "Iteration 45, loss = 0.34601964\n",
      "Iteration 46, loss = 0.33339662\n",
      "Iteration 47, loss = 0.31140534\n",
      "Iteration 48, loss = 0.29244447\n",
      "Iteration 49, loss = 0.27454086\n",
      "Iteration 50, loss = 0.25889798\n",
      "Iteration 51, loss = 0.24031862\n",
      "Iteration 52, loss = 0.22502812\n",
      "Iteration 53, loss = 0.20868550\n",
      "Iteration 54, loss = 0.18971879\n",
      "Iteration 55, loss = 0.17553790\n",
      "Iteration 56, loss = 0.15860408\n",
      "Iteration 57, loss = 0.14477853\n",
      "Iteration 58, loss = 0.13026848\n",
      "Iteration 59, loss = 0.12021676\n",
      "Iteration 60, loss = 0.10009050\n",
      "Iteration 61, loss = 0.09644373\n",
      "Iteration 62, loss = 0.07868209\n",
      "Iteration 63, loss = 0.06745326\n",
      "Iteration 64, loss = 0.06114150\n",
      "Iteration 65, loss = 0.04996845\n",
      "Iteration 66, loss = 0.04265329\n",
      "Iteration 67, loss = 0.03644863\n",
      "Iteration 68, loss = 0.03106563\n",
      "Iteration 69, loss = 0.02661730\n",
      "Iteration 70, loss = 0.02259593\n",
      "Iteration 71, loss = 0.01841693\n",
      "Iteration 72, loss = 0.01536594\n",
      "Iteration 73, loss = 0.01274796\n",
      "Iteration 74, loss = 0.01340267\n",
      "Iteration 75, loss = 0.00960616\n",
      "Iteration 76, loss = 0.00824577\n",
      "Iteration 77, loss = 0.00630428\n",
      "Iteration 78, loss = 0.00522461\n",
      "Iteration 79, loss = 0.00495560\n",
      "Iteration 80, loss = 0.00401996\n",
      "Iteration 81, loss = 0.00337459\n",
      "Iteration 82, loss = 0.00310280\n",
      "Iteration 83, loss = 0.00296066\n",
      "Iteration 84, loss = 0.00294119\n",
      "Iteration 85, loss = 0.00251744\n",
      "Iteration 86, loss = 0.00195501\n",
      "Iteration 87, loss = 0.00176940\n",
      "Iteration 88, loss = 0.00156359\n",
      "Iteration 89, loss = 0.00109699\n",
      "Iteration 90, loss = 0.00094667\n",
      "Iteration 91, loss = 0.00087120\n",
      "Iteration 92, loss = 0.00074385\n",
      "Iteration 93, loss = 0.00063866\n",
      "Iteration 94, loss = 0.00058254\n",
      "Iteration 95, loss = 0.00049975\n",
      "Iteration 96, loss = 0.00048220\n",
      "Iteration 97, loss = 0.00041965\n",
      "Iteration 98, loss = 0.00039681\n",
      "Iteration 99, loss = 0.00041153\n",
      "Iteration 100, loss = 0.00038688\n",
      "Iteration 101, loss = 0.00049706\n",
      "Iteration 102, loss = 0.00038138\n",
      "Iteration 103, loss = 0.00036812\n",
      "Iteration 104, loss = 0.00032230\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f499a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.31617201686345764\n",
      "MAE: 1.2953839280219352\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d566bcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 20.10761081\n",
      "Iteration 2, loss = 19.31178285\n",
      "Iteration 3, loss = 18.59745779\n",
      "Iteration 4, loss = 17.94584993\n",
      "Iteration 5, loss = 17.34101469\n",
      "Iteration 6, loss = 16.77592411\n",
      "Iteration 7, loss = 16.25607983\n",
      "Iteration 8, loss = 15.77983253\n",
      "Iteration 9, loss = 15.34912500\n",
      "Iteration 10, loss = 14.96068138\n",
      "Iteration 11, loss = 14.58926279\n",
      "Iteration 12, loss = 14.22749342\n",
      "Iteration 13, loss = 13.86179576\n",
      "Iteration 14, loss = 13.49236671\n",
      "Iteration 15, loss = 13.12938647\n",
      "Iteration 16, loss = 12.77628235\n",
      "Iteration 17, loss = 12.43569118\n",
      "Iteration 18, loss = 12.10977038\n",
      "Iteration 19, loss = 11.79581587\n",
      "Iteration 20, loss = 11.49062344\n",
      "Iteration 21, loss = 11.19301909\n",
      "Iteration 22, loss = 10.90163632\n",
      "Iteration 23, loss = 10.61406850\n",
      "Iteration 24, loss = 10.33479295\n",
      "Iteration 25, loss = 10.06201210\n",
      "Iteration 26, loss = 9.79789779\n",
      "Iteration 27, loss = 9.54179562\n",
      "Iteration 28, loss = 9.29206119\n",
      "Iteration 29, loss = 9.04987314\n",
      "Iteration 30, loss = 8.81458218\n",
      "Iteration 31, loss = 8.58474004\n",
      "Iteration 32, loss = 8.36157447\n",
      "Iteration 33, loss = 8.14464020\n",
      "Iteration 34, loss = 7.93395426\n",
      "Iteration 35, loss = 7.73061972\n",
      "Iteration 36, loss = 7.53242419\n",
      "Iteration 37, loss = 7.33919178\n",
      "Iteration 38, loss = 7.15048165\n",
      "Iteration 39, loss = 6.96634192\n",
      "Iteration 40, loss = 6.78783142\n",
      "Iteration 41, loss = 6.61514325\n",
      "Iteration 42, loss = 6.44698331\n",
      "Iteration 43, loss = 6.28312249\n",
      "Iteration 44, loss = 6.12443531\n",
      "Iteration 45, loss = 5.96986405\n",
      "Iteration 46, loss = 5.82033673\n",
      "Iteration 47, loss = 5.67496478\n",
      "Iteration 48, loss = 5.53353725\n",
      "Iteration 49, loss = 5.39650005\n",
      "Iteration 50, loss = 5.26252456\n",
      "Iteration 51, loss = 5.13266071\n",
      "Iteration 52, loss = 5.00673358\n",
      "Iteration 53, loss = 4.88459080\n",
      "Iteration 54, loss = 4.76606834\n",
      "Iteration 55, loss = 4.65063958\n",
      "Iteration 56, loss = 4.53874743\n",
      "Iteration 57, loss = 4.43001524\n",
      "Iteration 58, loss = 4.32476115\n",
      "Iteration 59, loss = 4.22247656\n",
      "Iteration 60, loss = 4.12284575\n",
      "Iteration 61, loss = 4.02738308\n",
      "Iteration 62, loss = 3.93254417\n",
      "Iteration 63, loss = 3.84202083\n",
      "Iteration 64, loss = 3.75417044\n",
      "Iteration 65, loss = 3.66877152\n",
      "Iteration 66, loss = 3.58530116\n",
      "Iteration 67, loss = 3.50474560\n",
      "Iteration 68, loss = 3.42663552\n",
      "Iteration 69, loss = 3.35095469\n",
      "Iteration 70, loss = 3.27698717\n",
      "Iteration 71, loss = 3.20569127\n",
      "Iteration 72, loss = 3.13635542\n",
      "Iteration 73, loss = 3.06920609\n",
      "Iteration 74, loss = 3.00393687\n",
      "Iteration 75, loss = 2.94055262\n",
      "Iteration 76, loss = 2.87932040\n",
      "Iteration 77, loss = 2.82002613\n",
      "Iteration 78, loss = 2.76212785\n",
      "Iteration 79, loss = 2.70603656\n",
      "Iteration 80, loss = 2.65161952\n",
      "Iteration 81, loss = 2.60037120\n",
      "Iteration 82, loss = 2.54965306\n",
      "Iteration 83, loss = 2.49983803\n",
      "Iteration 84, loss = 2.45134267\n",
      "Iteration 85, loss = 2.40533575\n",
      "Iteration 86, loss = 2.35988089\n",
      "Iteration 87, loss = 2.31618344\n",
      "Iteration 88, loss = 2.27382641\n",
      "Iteration 89, loss = 2.23309225\n",
      "Iteration 90, loss = 2.19364855\n",
      "Iteration 91, loss = 2.15501345\n",
      "Iteration 92, loss = 2.11933538\n",
      "Iteration 93, loss = 2.08212589\n",
      "Iteration 94, loss = 2.04724014\n",
      "Iteration 95, loss = 2.01416315\n",
      "Iteration 96, loss = 1.98023837\n",
      "Iteration 97, loss = 1.94843831\n",
      "Iteration 98, loss = 1.91787632\n",
      "Iteration 99, loss = 1.88853293\n",
      "Iteration 100, loss = 1.85902781\n",
      "Iteration 101, loss = 1.83118121\n",
      "Iteration 102, loss = 1.80417098\n",
      "Iteration 103, loss = 1.77806523\n",
      "Iteration 104, loss = 1.75299052\n",
      "Iteration 105, loss = 1.72862313\n",
      "Iteration 106, loss = 1.70477498\n",
      "Iteration 107, loss = 1.68316221\n",
      "Iteration 108, loss = 1.65986548\n",
      "Iteration 109, loss = 1.63795851\n",
      "Iteration 110, loss = 1.61716395\n",
      "Iteration 111, loss = 1.59704714\n",
      "Iteration 112, loss = 1.57761376\n",
      "Iteration 113, loss = 1.55873458\n",
      "Iteration 114, loss = 1.54052637\n",
      "Iteration 115, loss = 1.52326184\n",
      "Iteration 116, loss = 1.50609711\n",
      "Iteration 117, loss = 1.49013363\n",
      "Iteration 118, loss = 1.47412683\n",
      "Iteration 119, loss = 1.45807362\n",
      "Iteration 120, loss = 1.44307984\n",
      "Iteration 121, loss = 1.42883286\n",
      "Iteration 122, loss = 1.41482541\n",
      "Iteration 123, loss = 1.40148443\n",
      "Iteration 124, loss = 1.38819576\n",
      "Iteration 125, loss = 1.37546775\n",
      "Iteration 126, loss = 1.36322896\n",
      "Iteration 127, loss = 1.35126997\n",
      "Iteration 128, loss = 1.34011041\n",
      "Iteration 129, loss = 1.32924089\n",
      "Iteration 130, loss = 1.31910511\n",
      "Iteration 131, loss = 1.30796104\n",
      "Iteration 132, loss = 1.29778505\n",
      "Iteration 133, loss = 1.28820807\n",
      "Iteration 134, loss = 1.27909708\n",
      "Iteration 135, loss = 1.27041794\n",
      "Iteration 136, loss = 1.26219750\n",
      "Iteration 137, loss = 1.25429893\n",
      "Iteration 138, loss = 1.24640142\n",
      "Iteration 139, loss = 1.23907401\n",
      "Iteration 140, loss = 1.22994530\n",
      "Iteration 141, loss = 1.22275119\n",
      "Iteration 142, loss = 1.21556528\n",
      "Iteration 143, loss = 1.20848224\n",
      "Iteration 144, loss = 1.20130325\n",
      "Iteration 145, loss = 1.19464328\n",
      "Iteration 146, loss = 1.18811598\n",
      "Iteration 147, loss = 1.18221125\n",
      "Iteration 148, loss = 1.17674054\n",
      "Iteration 149, loss = 1.17111982\n",
      "Iteration 150, loss = 1.16614687\n",
      "Iteration 151, loss = 1.16039660\n",
      "Iteration 152, loss = 1.15538507\n",
      "Iteration 153, loss = 1.15023560\n",
      "Iteration 154, loss = 1.14545271\n",
      "Iteration 155, loss = 1.14164662\n",
      "Iteration 156, loss = 1.13659961\n",
      "Iteration 157, loss = 1.13207678\n",
      "Iteration 158, loss = 1.12824013\n",
      "Iteration 159, loss = 1.12454051\n",
      "Iteration 160, loss = 1.12099321\n",
      "Iteration 161, loss = 1.11748971\n",
      "Iteration 162, loss = 1.11359799\n",
      "Iteration 163, loss = 1.10948482\n",
      "Iteration 164, loss = 1.10623825\n",
      "Iteration 165, loss = 1.10304743\n",
      "Iteration 166, loss = 1.10088645\n",
      "Iteration 167, loss = 1.09660335\n",
      "Iteration 168, loss = 1.09417463\n",
      "Iteration 169, loss = 1.09125722\n",
      "Iteration 170, loss = 1.08823664\n",
      "Iteration 171, loss = 1.08526497\n",
      "Iteration 172, loss = 1.08257810\n",
      "Iteration 173, loss = 1.08067546\n",
      "Iteration 174, loss = 1.07887469\n",
      "Iteration 175, loss = 1.07681599\n",
      "Iteration 176, loss = 1.07435684\n",
      "Iteration 177, loss = 1.07254762\n",
      "Iteration 178, loss = 1.06938852\n",
      "Iteration 179, loss = 1.06749417\n",
      "Iteration 180, loss = 1.06546815\n",
      "Iteration 181, loss = 1.06369587\n",
      "Iteration 182, loss = 1.06225981\n",
      "Iteration 183, loss = 1.06036585\n",
      "Iteration 184, loss = 1.05842163\n",
      "Iteration 185, loss = 1.05739896\n",
      "Iteration 186, loss = 1.05540015\n",
      "Iteration 187, loss = 1.05338781\n",
      "Iteration 188, loss = 1.05200289\n",
      "Iteration 189, loss = 1.05073220\n",
      "Iteration 190, loss = 1.04868080\n",
      "Iteration 191, loss = 1.04752408\n",
      "Iteration 192, loss = 1.04640978\n",
      "Iteration 193, loss = 1.04576676\n",
      "Iteration 194, loss = 1.04369914\n",
      "Iteration 195, loss = 1.04317421\n",
      "Iteration 196, loss = 1.04160917\n",
      "Iteration 197, loss = 1.04043096\n",
      "Iteration 198, loss = 1.03931496\n",
      "Iteration 199, loss = 1.03849213\n",
      "Iteration 200, loss = 1.03792339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1019a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.05397520230519326\n",
      "MAE: 1.1218069927962886\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddf7cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data1[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA',\n",
    "          'PSH', 'PSD', 'PSA', 'WHH','WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'MaxH', 'MaxD', 'MaxA','AvgH', 'AvgD', 'AvgA', 'B365>2.5',\n",
    "          'B365<2.5', 'P>2.5', 'P<2.5', 'Max>2.5', 'Max<2.5', 'Avg>2.5', 'Avg<2.5', 'AHh', 'B365AHH','B365AHA', 'PAHH', 'PAHA', \n",
    "          'MaxAHH', 'MaxAHA', \"AvgAHH\", 'AvgAHA', 'B365CH', 'B365CD', 'B365CA', 'BWCH', 'BWCD', 'BWCA', 'IWCH', 'IWCD', 'IWCA',\n",
    "          'PSCH', 'PSCD', 'PSCA', 'WHCH', 'WHCD', 'WHCA', 'VCCH', 'VCCD', 'VCCA', 'MaxCH', 'MaxCD', 'MaxCA', 'AvgCH', 'AvgCD',\n",
    "          'AvgCA', 'B365C>2.5', 'B365C<2.5', 'PC>2.5', 'PC<2.5', 'MaxC>2.5', 'MaxC<2.5', 'AvgC>2.5', 'AvgC<2.5', 'AHCh', 'B365CAHH',\n",
    "          'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA']].copy()\n",
    "y = data1['FTAG'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a89be5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e60f9bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6d03ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.20849784\n",
      "Iteration 2, loss = 0.92910997\n",
      "Iteration 3, loss = 0.78157004\n",
      "Iteration 4, loss = 0.71406105\n",
      "Iteration 5, loss = 0.70927792\n",
      "Iteration 6, loss = 0.71069384\n",
      "Iteration 7, loss = 0.70283126\n",
      "Iteration 8, loss = 0.67643946\n",
      "Iteration 9, loss = 0.64303845\n",
      "Iteration 10, loss = 0.61313471\n",
      "Iteration 11, loss = 0.59860403\n",
      "Iteration 12, loss = 0.59207539\n",
      "Iteration 13, loss = 0.58822858\n",
      "Iteration 14, loss = 0.58373068\n",
      "Iteration 15, loss = 0.57485598\n",
      "Iteration 16, loss = 0.56518032\n",
      "Iteration 17, loss = 0.55465598\n",
      "Iteration 18, loss = 0.54557981\n",
      "Iteration 19, loss = 0.53896014\n",
      "Iteration 20, loss = 0.53267638\n",
      "Iteration 21, loss = 0.52652250\n",
      "Iteration 22, loss = 0.51983934\n",
      "Iteration 23, loss = 0.51334352\n",
      "Iteration 24, loss = 0.50737451\n",
      "Iteration 25, loss = 0.50164680\n",
      "Iteration 26, loss = 0.49593829\n",
      "Iteration 27, loss = 0.49039835\n",
      "Iteration 28, loss = 0.48426019\n",
      "Iteration 29, loss = 0.47828949\n",
      "Iteration 30, loss = 0.47355776\n",
      "Iteration 31, loss = 0.46839158\n",
      "Iteration 32, loss = 0.46299481\n",
      "Iteration 33, loss = 0.45680446\n",
      "Iteration 34, loss = 0.45215678\n",
      "Iteration 35, loss = 0.44723629\n",
      "Iteration 36, loss = 0.44293059\n",
      "Iteration 37, loss = 0.43790097\n",
      "Iteration 38, loss = 0.43308943\n",
      "Iteration 39, loss = 0.42843606\n",
      "Iteration 40, loss = 0.42391116\n",
      "Iteration 41, loss = 0.41954207\n",
      "Iteration 42, loss = 0.41528113\n",
      "Iteration 43, loss = 0.41093225\n",
      "Iteration 44, loss = 0.40703511\n",
      "Iteration 45, loss = 0.40264585\n",
      "Iteration 46, loss = 0.39833033\n",
      "Iteration 47, loss = 0.39468406\n",
      "Iteration 48, loss = 0.39112391\n",
      "Iteration 49, loss = 0.38717181\n",
      "Iteration 50, loss = 0.38312237\n",
      "Iteration 51, loss = 0.37937783\n",
      "Iteration 52, loss = 0.37548838\n",
      "Iteration 53, loss = 0.37191509\n",
      "Iteration 54, loss = 0.36889017\n",
      "Iteration 55, loss = 0.36495963\n",
      "Iteration 56, loss = 0.36197099\n",
      "Iteration 57, loss = 0.35792515\n",
      "Iteration 58, loss = 0.35392338\n",
      "Iteration 59, loss = 0.35016885\n",
      "Iteration 60, loss = 0.34647440\n",
      "Iteration 61, loss = 0.34265175\n",
      "Iteration 62, loss = 0.33936273\n",
      "Iteration 63, loss = 0.33640878\n",
      "Iteration 64, loss = 0.33291313\n",
      "Iteration 65, loss = 0.33009387\n",
      "Iteration 66, loss = 0.32617915\n",
      "Iteration 67, loss = 0.32201472\n",
      "Iteration 68, loss = 0.31957903\n",
      "Iteration 69, loss = 0.31718813\n",
      "Iteration 70, loss = 0.31315132\n",
      "Iteration 71, loss = 0.30910847\n",
      "Iteration 72, loss = 0.30560854\n",
      "Iteration 73, loss = 0.30220092\n",
      "Iteration 74, loss = 0.29853535\n",
      "Iteration 75, loss = 0.29519935\n",
      "Iteration 76, loss = 0.29196105\n",
      "Iteration 77, loss = 0.28829309\n",
      "Iteration 78, loss = 0.28433638\n",
      "Iteration 79, loss = 0.28060049\n",
      "Iteration 80, loss = 0.27714268\n",
      "Iteration 81, loss = 0.27393013\n",
      "Iteration 82, loss = 0.27022049\n",
      "Iteration 83, loss = 0.26713955\n",
      "Iteration 84, loss = 0.26362542\n",
      "Iteration 85, loss = 0.26036844\n",
      "Iteration 86, loss = 0.25683408\n",
      "Iteration 87, loss = 0.25411072\n",
      "Iteration 88, loss = 0.25057658\n",
      "Iteration 89, loss = 0.24677042\n",
      "Iteration 90, loss = 0.24439547\n",
      "Iteration 91, loss = 0.24079433\n",
      "Iteration 92, loss = 0.23730952\n",
      "Iteration 93, loss = 0.23402974\n",
      "Iteration 94, loss = 0.23096990\n",
      "Iteration 95, loss = 0.22782026\n",
      "Iteration 96, loss = 0.22439201\n",
      "Iteration 97, loss = 0.22155603\n",
      "Iteration 98, loss = 0.21802781\n",
      "Iteration 99, loss = 0.21461130\n",
      "Iteration 100, loss = 0.21231362\n",
      "Iteration 101, loss = 0.20853109\n",
      "Iteration 102, loss = 0.20535276\n",
      "Iteration 103, loss = 0.20314445\n",
      "Iteration 104, loss = 0.20022992\n",
      "Iteration 105, loss = 0.19725481\n",
      "Iteration 106, loss = 0.19347190\n",
      "Iteration 107, loss = 0.19132187\n",
      "Iteration 108, loss = 0.18809792\n",
      "Iteration 109, loss = 0.18451333\n",
      "Iteration 110, loss = 0.18209797\n",
      "Iteration 111, loss = 0.17890096\n",
      "Iteration 112, loss = 0.17609844\n",
      "Iteration 113, loss = 0.17322279\n",
      "Iteration 114, loss = 0.16995405\n",
      "Iteration 115, loss = 0.16694413\n",
      "Iteration 116, loss = 0.16421936\n",
      "Iteration 117, loss = 0.16265419\n",
      "Iteration 118, loss = 0.15965836\n",
      "Iteration 119, loss = 0.15747528\n",
      "Iteration 120, loss = 0.15388623\n",
      "Iteration 121, loss = 0.15211781\n",
      "Iteration 122, loss = 0.14881101\n",
      "Iteration 123, loss = 0.14585548\n",
      "Iteration 124, loss = 0.14313066\n",
      "Iteration 125, loss = 0.14051573\n",
      "Iteration 126, loss = 0.13823891\n",
      "Iteration 127, loss = 0.13547081\n",
      "Iteration 128, loss = 0.13305588\n",
      "Iteration 129, loss = 0.13072654\n",
      "Iteration 130, loss = 0.12791596\n",
      "Iteration 131, loss = 0.12546236\n",
      "Iteration 132, loss = 0.12286100\n",
      "Iteration 133, loss = 0.12091937\n",
      "Iteration 134, loss = 0.11819220\n",
      "Iteration 135, loss = 0.11669073\n",
      "Iteration 136, loss = 0.11385640\n",
      "Iteration 137, loss = 0.11222527\n",
      "Iteration 138, loss = 0.10931055\n",
      "Iteration 139, loss = 0.10683154\n",
      "Iteration 140, loss = 0.10582778\n",
      "Iteration 141, loss = 0.10284800\n",
      "Iteration 142, loss = 0.10132055\n",
      "Iteration 143, loss = 0.09811802\n",
      "Iteration 144, loss = 0.09753121\n",
      "Iteration 145, loss = 0.09544523\n",
      "Iteration 146, loss = 0.09329221\n",
      "Iteration 147, loss = 0.09182939\n",
      "Iteration 148, loss = 0.08920270\n",
      "Iteration 149, loss = 0.08801127\n",
      "Iteration 150, loss = 0.08524174\n",
      "Iteration 151, loss = 0.08371731\n",
      "Iteration 152, loss = 0.08216707\n",
      "Iteration 153, loss = 0.07984342\n",
      "Iteration 154, loss = 0.07824109\n",
      "Iteration 155, loss = 0.07668273\n",
      "Iteration 156, loss = 0.07478070\n",
      "Iteration 157, loss = 0.07309762\n",
      "Iteration 158, loss = 0.07154870\n",
      "Iteration 159, loss = 0.07012729\n",
      "Iteration 160, loss = 0.06850345\n",
      "Iteration 161, loss = 0.06711798\n",
      "Iteration 162, loss = 0.06557616\n",
      "Iteration 163, loss = 0.06408593\n",
      "Iteration 164, loss = 0.06262007\n",
      "Iteration 165, loss = 0.06128990\n",
      "Iteration 166, loss = 0.05999482\n",
      "Iteration 167, loss = 0.05899488\n",
      "Iteration 168, loss = 0.05725870\n",
      "Iteration 169, loss = 0.05593788\n",
      "Iteration 170, loss = 0.05472049\n",
      "Iteration 171, loss = 0.05358146\n",
      "Iteration 172, loss = 0.05188073\n",
      "Iteration 173, loss = 0.05142378\n",
      "Iteration 174, loss = 0.04962694\n",
      "Iteration 175, loss = 0.04949824\n",
      "Iteration 176, loss = 0.04758269\n",
      "Iteration 177, loss = 0.04722486\n",
      "Iteration 178, loss = 0.04564145\n",
      "Iteration 179, loss = 0.04475397\n",
      "Iteration 180, loss = 0.04373706\n",
      "Iteration 181, loss = 0.04215510\n",
      "Iteration 182, loss = 0.04149219\n",
      "Iteration 183, loss = 0.04086712\n",
      "Iteration 184, loss = 0.03941394\n",
      "Iteration 185, loss = 0.03832782\n",
      "Iteration 186, loss = 0.03750751\n",
      "Iteration 187, loss = 0.03685254\n",
      "Iteration 188, loss = 0.03638463\n",
      "Iteration 189, loss = 0.03463274\n",
      "Iteration 190, loss = 0.03372213\n",
      "Iteration 191, loss = 0.03295111\n",
      "Iteration 192, loss = 0.03175364\n",
      "Iteration 193, loss = 0.03101095\n",
      "Iteration 194, loss = 0.03019509\n",
      "Iteration 195, loss = 0.02937741\n",
      "Iteration 196, loss = 0.02854855\n",
      "Iteration 197, loss = 0.02792183\n",
      "Iteration 198, loss = 0.02707317\n",
      "Iteration 199, loss = 0.02656539\n",
      "Iteration 200, loss = 0.02589792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cf85bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.39878364132256405\n",
      "MAE: 1.0969206012530108\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99a75538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.40776398\n",
      "Iteration 2, loss = 1.13901524\n",
      "Iteration 3, loss = 0.92975420\n",
      "Iteration 4, loss = 0.77394160\n",
      "Iteration 5, loss = 0.71698750\n",
      "Iteration 6, loss = 0.72701724\n",
      "Iteration 7, loss = 0.73461893\n",
      "Iteration 8, loss = 0.69845081\n",
      "Iteration 9, loss = 0.65349156\n",
      "Iteration 10, loss = 0.63079464\n",
      "Iteration 11, loss = 0.62146109\n",
      "Iteration 12, loss = 0.62001377\n",
      "Iteration 13, loss = 0.61319835\n",
      "Iteration 14, loss = 0.60099570\n",
      "Iteration 15, loss = 0.58278387\n",
      "Iteration 16, loss = 0.57049038\n",
      "Iteration 17, loss = 0.56496424\n",
      "Iteration 18, loss = 0.56039135\n",
      "Iteration 19, loss = 0.55264269\n",
      "Iteration 20, loss = 0.53846767\n",
      "Iteration 21, loss = 0.52653966\n",
      "Iteration 22, loss = 0.51616357\n",
      "Iteration 23, loss = 0.50636012\n",
      "Iteration 24, loss = 0.49268033\n",
      "Iteration 25, loss = 0.48054685\n",
      "Iteration 26, loss = 0.46842131\n",
      "Iteration 27, loss = 0.45543365\n",
      "Iteration 28, loss = 0.44339995\n",
      "Iteration 29, loss = 0.42813456\n",
      "Iteration 30, loss = 0.41338329\n",
      "Iteration 31, loss = 0.40026886\n",
      "Iteration 32, loss = 0.38563216\n",
      "Iteration 33, loss = 0.37181573\n",
      "Iteration 34, loss = 0.36093042\n",
      "Iteration 35, loss = 0.34609339\n",
      "Iteration 36, loss = 0.33448832\n",
      "Iteration 37, loss = 0.31717106\n",
      "Iteration 38, loss = 0.31011562\n",
      "Iteration 39, loss = 0.29512772\n",
      "Iteration 40, loss = 0.28213657\n",
      "Iteration 41, loss = 0.26791734\n",
      "Iteration 42, loss = 0.25302752\n",
      "Iteration 43, loss = 0.23977306\n",
      "Iteration 44, loss = 0.22672892\n",
      "Iteration 45, loss = 0.21194920\n",
      "Iteration 46, loss = 0.19799526\n",
      "Iteration 47, loss = 0.18583728\n",
      "Iteration 48, loss = 0.17018118\n",
      "Iteration 49, loss = 0.15794507\n",
      "Iteration 50, loss = 0.14921386\n",
      "Iteration 51, loss = 0.13286152\n",
      "Iteration 52, loss = 0.12504886\n",
      "Iteration 53, loss = 0.10709999\n",
      "Iteration 54, loss = 0.09762416\n",
      "Iteration 55, loss = 0.08365483\n",
      "Iteration 56, loss = 0.08216009\n",
      "Iteration 57, loss = 0.07055666\n",
      "Iteration 58, loss = 0.05898394\n",
      "Iteration 59, loss = 0.05303817\n",
      "Iteration 60, loss = 0.04814594\n",
      "Iteration 61, loss = 0.04068626\n",
      "Iteration 62, loss = 0.03397231\n",
      "Iteration 63, loss = 0.03036904\n",
      "Iteration 64, loss = 0.02685822\n",
      "Iteration 65, loss = 0.02228270\n",
      "Iteration 66, loss = 0.01924341\n",
      "Iteration 67, loss = 0.01641385\n",
      "Iteration 68, loss = 0.01361882\n",
      "Iteration 69, loss = 0.01267675\n",
      "Iteration 70, loss = 0.01067876\n",
      "Iteration 71, loss = 0.00870656\n",
      "Iteration 72, loss = 0.00744831\n",
      "Iteration 73, loss = 0.00640973\n",
      "Iteration 74, loss = 0.00570597\n",
      "Iteration 75, loss = 0.00526537\n",
      "Iteration 76, loss = 0.00449332\n",
      "Iteration 77, loss = 0.00387413\n",
      "Iteration 78, loss = 0.00323900\n",
      "Iteration 79, loss = 0.00278550\n",
      "Iteration 80, loss = 0.00232868\n",
      "Iteration 81, loss = 0.00228806\n",
      "Iteration 82, loss = 0.00191744\n",
      "Iteration 83, loss = 0.00184775\n",
      "Iteration 84, loss = 0.00157413\n",
      "Iteration 85, loss = 0.00135315\n",
      "Iteration 86, loss = 0.00116784\n",
      "Iteration 87, loss = 0.00097133\n",
      "Iteration 88, loss = 0.00078264\n",
      "Iteration 89, loss = 0.00078024\n",
      "Iteration 90, loss = 0.00071053\n",
      "Iteration 91, loss = 0.00068333\n",
      "Iteration 92, loss = 0.00056796\n",
      "Iteration 93, loss = 0.00049867\n",
      "Iteration 94, loss = 0.00043144\n",
      "Iteration 95, loss = 0.00035078\n",
      "Iteration 96, loss = 0.00034355\n",
      "Iteration 97, loss = 0.00030044\n",
      "Iteration 98, loss = 0.00028348\n",
      "Iteration 99, loss = 0.00026153\n",
      "Iteration 100, loss = 0.00023118\n",
      "Iteration 101, loss = 0.00021466\n",
      "Iteration 102, loss = 0.00020311\n",
      "Iteration 103, loss = 0.00019994\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbd173cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.5638861658433441\n",
      "MAE: 1.1447545342414556\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d137a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 18.86246024\n",
      "Iteration 2, loss = 18.27833928\n",
      "Iteration 3, loss = 17.73724909\n",
      "Iteration 4, loss = 17.21690754\n",
      "Iteration 5, loss = 16.71368655\n",
      "Iteration 6, loss = 16.23033984\n",
      "Iteration 7, loss = 15.75774119\n",
      "Iteration 8, loss = 15.30176273\n",
      "Iteration 9, loss = 14.85859561\n",
      "Iteration 10, loss = 14.42986647\n",
      "Iteration 11, loss = 14.01543688\n",
      "Iteration 12, loss = 13.61212716\n",
      "Iteration 13, loss = 13.22933979\n",
      "Iteration 14, loss = 12.85632735\n",
      "Iteration 15, loss = 12.49621376\n",
      "Iteration 16, loss = 12.14849484\n",
      "Iteration 17, loss = 11.80923079\n",
      "Iteration 18, loss = 11.48071501\n",
      "Iteration 19, loss = 11.16016283\n",
      "Iteration 20, loss = 10.84784084\n",
      "Iteration 21, loss = 10.54357301\n",
      "Iteration 22, loss = 10.24827428\n",
      "Iteration 23, loss = 9.96136257\n",
      "Iteration 24, loss = 9.68282130\n",
      "Iteration 25, loss = 9.41219461\n",
      "Iteration 26, loss = 9.14960030\n",
      "Iteration 27, loss = 8.89467911\n",
      "Iteration 28, loss = 8.64673716\n",
      "Iteration 29, loss = 8.40589909\n",
      "Iteration 30, loss = 8.17208374\n",
      "Iteration 31, loss = 7.94481245\n",
      "Iteration 32, loss = 7.72412353\n",
      "Iteration 33, loss = 7.50979098\n",
      "Iteration 34, loss = 7.30173710\n",
      "Iteration 35, loss = 7.09954818\n",
      "Iteration 36, loss = 6.90302608\n",
      "Iteration 37, loss = 6.71246624\n",
      "Iteration 38, loss = 6.52754730\n",
      "Iteration 39, loss = 6.34769140\n",
      "Iteration 40, loss = 6.17330657\n",
      "Iteration 41, loss = 6.00409497\n",
      "Iteration 42, loss = 5.83994882\n",
      "Iteration 43, loss = 5.68044736\n",
      "Iteration 44, loss = 5.52558315\n",
      "Iteration 45, loss = 5.37540124\n",
      "Iteration 46, loss = 5.22954196\n",
      "Iteration 47, loss = 5.08838063\n",
      "Iteration 48, loss = 4.95098645\n",
      "Iteration 49, loss = 4.81797338\n",
      "Iteration 50, loss = 4.68856363\n",
      "Iteration 51, loss = 4.56333543\n",
      "Iteration 52, loss = 4.44183514\n",
      "Iteration 53, loss = 4.32406061\n",
      "Iteration 54, loss = 4.21004280\n",
      "Iteration 55, loss = 4.09952654\n",
      "Iteration 56, loss = 3.99199365\n",
      "Iteration 57, loss = 3.88790533\n",
      "Iteration 58, loss = 3.78684214\n",
      "Iteration 59, loss = 3.68860578\n",
      "Iteration 60, loss = 3.59360199\n",
      "Iteration 61, loss = 3.50163013\n",
      "Iteration 62, loss = 3.41186248\n",
      "Iteration 63, loss = 3.32529332\n",
      "Iteration 64, loss = 3.24168261\n",
      "Iteration 65, loss = 3.16043380\n",
      "Iteration 66, loss = 3.08174418\n",
      "Iteration 67, loss = 3.00557750\n",
      "Iteration 68, loss = 2.93166193\n",
      "Iteration 69, loss = 2.86009263\n",
      "Iteration 70, loss = 2.79090682\n",
      "Iteration 71, loss = 2.72417806\n",
      "Iteration 72, loss = 2.65929247\n",
      "Iteration 73, loss = 2.59627714\n",
      "Iteration 74, loss = 2.53513860\n",
      "Iteration 75, loss = 2.47593132\n",
      "Iteration 76, loss = 2.41844743\n",
      "Iteration 77, loss = 2.36287101\n",
      "Iteration 78, loss = 2.30946380\n",
      "Iteration 79, loss = 2.25719499\n",
      "Iteration 80, loss = 2.20689283\n",
      "Iteration 81, loss = 2.15838577\n",
      "Iteration 82, loss = 2.11110256\n",
      "Iteration 83, loss = 2.06551744\n",
      "Iteration 84, loss = 2.02127647\n",
      "Iteration 85, loss = 1.97871590\n",
      "Iteration 86, loss = 1.93733748\n",
      "Iteration 87, loss = 1.89725937\n",
      "Iteration 88, loss = 1.85842379\n",
      "Iteration 89, loss = 1.82092331\n",
      "Iteration 90, loss = 1.78454120\n",
      "Iteration 91, loss = 1.74946655\n",
      "Iteration 92, loss = 1.71544316\n",
      "Iteration 93, loss = 1.68265496\n",
      "Iteration 94, loss = 1.65089791\n",
      "Iteration 95, loss = 1.62012465\n",
      "Iteration 96, loss = 1.59028591\n",
      "Iteration 97, loss = 1.56177827\n",
      "Iteration 98, loss = 1.53352295\n",
      "Iteration 99, loss = 1.50686264\n",
      "Iteration 100, loss = 1.48052505\n",
      "Iteration 101, loss = 1.45532018\n",
      "Iteration 102, loss = 1.43105785\n",
      "Iteration 103, loss = 1.40746123\n",
      "Iteration 104, loss = 1.38466544\n",
      "Iteration 105, loss = 1.36262518\n",
      "Iteration 106, loss = 1.34141175\n",
      "Iteration 107, loss = 1.32079360\n",
      "Iteration 108, loss = 1.30088747\n",
      "Iteration 109, loss = 1.28171826\n",
      "Iteration 110, loss = 1.26312844\n",
      "Iteration 111, loss = 1.24521074\n",
      "Iteration 112, loss = 1.22783117\n",
      "Iteration 113, loss = 1.21109785\n",
      "Iteration 114, loss = 1.19470868\n",
      "Iteration 115, loss = 1.17919931\n",
      "Iteration 116, loss = 1.16415821\n",
      "Iteration 117, loss = 1.14950114\n",
      "Iteration 118, loss = 1.13551723\n",
      "Iteration 119, loss = 1.12185278\n",
      "Iteration 120, loss = 1.10855112\n",
      "Iteration 121, loss = 1.09564342\n",
      "Iteration 122, loss = 1.08342069\n",
      "Iteration 123, loss = 1.07131317\n",
      "Iteration 124, loss = 1.05978388\n",
      "Iteration 125, loss = 1.04867171\n",
      "Iteration 126, loss = 1.03776990\n",
      "Iteration 127, loss = 1.02729806\n",
      "Iteration 128, loss = 1.01732725\n",
      "Iteration 129, loss = 1.00755604\n",
      "Iteration 130, loss = 0.99806250\n",
      "Iteration 131, loss = 0.98922778\n",
      "Iteration 132, loss = 0.97997411\n",
      "Iteration 133, loss = 0.97153807\n",
      "Iteration 134, loss = 0.96357430\n",
      "Iteration 135, loss = 0.95588184\n",
      "Iteration 136, loss = 0.94865120\n",
      "Iteration 137, loss = 0.94143071\n",
      "Iteration 138, loss = 0.93438765\n",
      "Iteration 139, loss = 0.92738390\n",
      "Iteration 140, loss = 0.92076568\n",
      "Iteration 141, loss = 0.91398754\n",
      "Iteration 142, loss = 0.90758873\n",
      "Iteration 143, loss = 0.90168229\n",
      "Iteration 144, loss = 0.89560561\n",
      "Iteration 145, loss = 0.88965063\n",
      "Iteration 146, loss = 0.88424764\n",
      "Iteration 147, loss = 0.87905346\n",
      "Iteration 148, loss = 0.87399046\n",
      "Iteration 149, loss = 0.86900987\n",
      "Iteration 150, loss = 0.86432411\n",
      "Iteration 151, loss = 0.85956495\n",
      "Iteration 152, loss = 0.85491460\n",
      "Iteration 153, loss = 0.85055774\n",
      "Iteration 154, loss = 0.84639210\n",
      "Iteration 155, loss = 0.84240555\n",
      "Iteration 156, loss = 0.83841825\n",
      "Iteration 157, loss = 0.83464037\n",
      "Iteration 158, loss = 0.83097731\n",
      "Iteration 159, loss = 0.82745275\n",
      "Iteration 160, loss = 0.82413639\n",
      "Iteration 161, loss = 0.82094739\n",
      "Iteration 162, loss = 0.81768732\n",
      "Iteration 163, loss = 0.81457100\n",
      "Iteration 164, loss = 0.81177693\n",
      "Iteration 165, loss = 0.80871204\n",
      "Iteration 166, loss = 0.80601713\n",
      "Iteration 167, loss = 0.80330311\n",
      "Iteration 168, loss = 0.80086283\n",
      "Iteration 169, loss = 0.79823907\n",
      "Iteration 170, loss = 0.79578338\n",
      "Iteration 171, loss = 0.79340694\n",
      "Iteration 172, loss = 0.79106441\n",
      "Iteration 173, loss = 0.78880485\n",
      "Iteration 174, loss = 0.78668243\n",
      "Iteration 175, loss = 0.78506655\n",
      "Iteration 176, loss = 0.78295926\n",
      "Iteration 177, loss = 0.78091895\n",
      "Iteration 178, loss = 0.77928539\n",
      "Iteration 179, loss = 0.77709956\n",
      "Iteration 180, loss = 0.77532286\n",
      "Iteration 181, loss = 0.77361624\n",
      "Iteration 182, loss = 0.77196723\n",
      "Iteration 183, loss = 0.77040315\n",
      "Iteration 184, loss = 0.76883581\n",
      "Iteration 185, loss = 0.76735100\n",
      "Iteration 186, loss = 0.76588416\n",
      "Iteration 187, loss = 0.76449673\n",
      "Iteration 188, loss = 0.76315434\n",
      "Iteration 189, loss = 0.76182012\n",
      "Iteration 190, loss = 0.76068030\n",
      "Iteration 191, loss = 0.75944716\n",
      "Iteration 192, loss = 0.75838010\n",
      "Iteration 193, loss = 0.75728326\n",
      "Iteration 194, loss = 0.75627793\n",
      "Iteration 195, loss = 0.75515355\n",
      "Iteration 196, loss = 0.75413938\n",
      "Iteration 197, loss = 0.75331241\n",
      "Iteration 198, loss = 0.75213119\n",
      "Iteration 199, loss = 0.75112221\n",
      "Iteration 200, loss = 0.75030059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;B365H&#x27;, &#x27;B365D&#x27;, &#x27;B365A&#x27;, &#x27;BWH&#x27;, &#x27;BWD&#x27;, &#x27;BWA&#x27;, &#x27;IWH&#x27;, &#x27;IWD&#x27;, &#x27;IWA&#x27;, &#x27;PSH&#x27;, &#x27;PSD&#x27;, &#x27;PSA&#x27;, &#x27;WHH&#x27;, &#x27;WHD&#x27;, &#x27;WHA&#x27;, &#x27;VCH&#x27;, &#x27;VCD&#x27;, &#x27;VCA&#x27;, &#x27;MaxH&#x27;, &#x27;MaxD&#x27;, &#x27;MaxA&#x27;, &#x27;AvgH&#x27;, &#x27;AvgD&#x27;, &#x27;AvgA&#x27;, &#x27;B365&gt;2.5&#x27;, &#x27;B365&lt;2.5&#x27;, &#x27;P&gt;2.5&#x27;, &#x27;P&lt;2.5&#x27;, &#x27;Max&gt;2.5&#x27;, &#x27;Max&lt;2.5&#x27;, &#x27;Avg&gt;2.5&#x27;, &#x27;Avg&lt;2.5&#x27;, &#x27;AHh&#x27;, &#x27;B365AHH&#x27;, &#x27;B365AHA&#x27;, &#x27;PAHH&#x27;, &#x27;PAHA&#x27;, &#x27;MaxAHH&#x27;, &#x27;MaxAHA&#x27;, &#x27;AvgAHH&#x27;, &#x27;AvgAHA&#x27;, &#x27;B365CH&#x27;, &#x27;B365CD&#x27;, &#x27;B365CA&#x27;, &#x27;BWCH&#x27;, &#x27;BWCD&#x27;, &#x27;BWCA&#x27;, &#x27;IWCH&#x27;, &#x27;IWCD&#x27;, &#x27;IWCA&#x27;, &#x27;PSCH&#x27;, &#x27;PSCD&#x27;, &#x27;PSCA&#x27;, &#x27;WHCH&#x27;, &#x27;WHCD&#x27;, &#x27;WHCA&#x27;, &#x27;VCCH&#x27;, &#x27;VCCD&#x27;, &#x27;VCCA&#x27;, &#x27;MaxCH&#x27;, &#x27;MaxCD&#x27;, &#x27;MaxCA&#x27;, &#x27;AvgCH&#x27;, &#x27;AvgCD&#x27;, &#x27;AvgCA&#x27;, &#x27;B365C&gt;2.5&#x27;, &#x27;B365C&lt;2.5&#x27;, &#x27;PC&gt;2.5&#x27;, &#x27;PC&lt;2.5&#x27;, &#x27;MaxC&gt;2.5&#x27;, &#x27;MaxC&lt;2.5&#x27;, &#x27;AvgC&gt;2.5&#x27;, &#x27;AvgC&lt;2.5&#x27;, &#x27;AHCh&#x27;, &#x27;B365CAHH&#x27;, &#x27;B365CAHA&#x27;, &#x27;PCAHH&#x27;, &#x27;PCAHA&#x27;, &#x27;MaxCAHH&#x27;, &#x27;MaxCAHA&#x27;, &#x27;AvgCAHH&#x27;, &#x27;AvgCAHA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "122f03e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.02611626564280023\n",
      "MAE: 0.9400140836650767\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c84effd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TeamH</th>\n",
       "      <th>TeamA</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>HStr</th>\n",
       "      <th>HSOH</th>\n",
       "      <th>HSOA</th>\n",
       "      <th>HSAH</th>\n",
       "      <th>HSAA</th>\n",
       "      <th>HSDH</th>\n",
       "      <th>HSDA</th>\n",
       "      <th>HO</th>\n",
       "      <th>HA</th>\n",
       "      <th>HM</th>\n",
       "      <th>HD</th>\n",
       "      <th>HDP</th>\n",
       "      <th>HIP</th>\n",
       "      <th>HSAAg</th>\n",
       "      <th>HATAAg</th>\n",
       "      <th>HGls</th>\n",
       "      <th>HAssts</th>\n",
       "      <th>HGlsPK</th>\n",
       "      <th>HxG</th>\n",
       "      <th>HNpxG</th>\n",
       "      <th>HxAG</th>\n",
       "      <th>HPoss</th>\n",
       "      <th>HPrg</th>\n",
       "      <th>HPrgP</th>\n",
       "      <th>HGKS%</th>\n",
       "      <th>HGKCS%</th>\n",
       "      <th>HSoT</th>\n",
       "      <th>Hg-xG</th>\n",
       "      <th>HCmp</th>\n",
       "      <th>HCmp%</th>\n",
       "      <th>HPrgDist</th>\n",
       "      <th>HXa</th>\n",
       "      <th>HKP</th>\n",
       "      <th>HPPA</th>\n",
       "      <th>HCrsPA</th>\n",
       "      <th>HTB</th>\n",
       "      <th>HCrs</th>\n",
       "      <th>HCK</th>\n",
       "      <th>HSCA</th>\n",
       "      <th>HGCA</th>\n",
       "      <th>HTkIW</th>\n",
       "      <th>HLost</th>\n",
       "      <th>HBlocks</th>\n",
       "      <th>HPass</th>\n",
       "      <th>HInt</th>\n",
       "      <th>HClr</th>\n",
       "      <th>HAttPen</th>\n",
       "      <th>HSucc%</th>\n",
       "      <th>HCPA</th>\n",
       "      <th>HDis</th>\n",
       "      <th>HPrgR</th>\n",
       "      <th>HOnG</th>\n",
       "      <th>HOnGA</th>\n",
       "      <th>HOnxG</th>\n",
       "      <th>HOnxGA</th>\n",
       "      <th>AStr</th>\n",
       "      <th>ASOH</th>\n",
       "      <th>ASOA</th>\n",
       "      <th>ASAH</th>\n",
       "      <th>ASAA</th>\n",
       "      <th>ASDH</th>\n",
       "      <th>ASDA</th>\n",
       "      <th>AO</th>\n",
       "      <th>AA</th>\n",
       "      <th>AM</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADP</th>\n",
       "      <th>AIP</th>\n",
       "      <th>ASAAg</th>\n",
       "      <th>ATAAg</th>\n",
       "      <th>AGls</th>\n",
       "      <th>AAssts</th>\n",
       "      <th>AGlsPK</th>\n",
       "      <th>AxG</th>\n",
       "      <th>ANpxG</th>\n",
       "      <th>AxAG</th>\n",
       "      <th>APoss</th>\n",
       "      <th>APrg</th>\n",
       "      <th>APrgP</th>\n",
       "      <th>AGKS%</th>\n",
       "      <th>AGKCS%</th>\n",
       "      <th>ASoT</th>\n",
       "      <th>Ag-xG</th>\n",
       "      <th>ACmp</th>\n",
       "      <th>ACmp%</th>\n",
       "      <th>APrgDist</th>\n",
       "      <th>AXa</th>\n",
       "      <th>AKP</th>\n",
       "      <th>APPA</th>\n",
       "      <th>ACrsPA</th>\n",
       "      <th>ATB</th>\n",
       "      <th>ACrs</th>\n",
       "      <th>ACK</th>\n",
       "      <th>ASCA</th>\n",
       "      <th>AGCA</th>\n",
       "      <th>ATkIW</th>\n",
       "      <th>ALost</th>\n",
       "      <th>ABlocks</th>\n",
       "      <th>APass</th>\n",
       "      <th>AInt</th>\n",
       "      <th>AClr</th>\n",
       "      <th>AAttPen</th>\n",
       "      <th>ASucc%</th>\n",
       "      <th>ACPA</th>\n",
       "      <th>ADis</th>\n",
       "      <th>APrgR</th>\n",
       "      <th>AOnG</th>\n",
       "      <th>AOnGA</th>\n",
       "      <th>AOnxG</th>\n",
       "      <th>AOnxGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/8/2022</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "      <td>3</td>\n",
       "      <td>1085</td>\n",
       "      <td>1100</td>\n",
       "      <td>1110</td>\n",
       "      <td>1110</td>\n",
       "      <td>1060</td>\n",
       "      <td>1090</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>45.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>71.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>348.8</td>\n",
       "      <td>77.2</td>\n",
       "      <td>2310.4</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.19</td>\n",
       "      <td>6.14</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.95</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.89</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.73</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.65</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>5.41</td>\n",
       "      <td>12.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4</td>\n",
       "      <td>1245</td>\n",
       "      <td>1285</td>\n",
       "      <td>1250</td>\n",
       "      <td>1250</td>\n",
       "      <td>1240</td>\n",
       "      <td>1320</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.39</td>\n",
       "      <td>59.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>54.2</td>\n",
       "      <td>70.6</td>\n",
       "      <td>35.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.27</td>\n",
       "      <td>482.8</td>\n",
       "      <td>83.1</td>\n",
       "      <td>2658.9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.01</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.24</td>\n",
       "      <td>17.8</td>\n",
       "      <td>5.81</td>\n",
       "      <td>27.6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>8.89</td>\n",
       "      <td>6.51</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.22</td>\n",
       "      <td>6.35</td>\n",
       "      <td>15.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.1</td>\n",
       "      <td>53.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Time           TeamH    TeamA  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0  5/8/2022  20:00  Crystal Palace  Arsenal     0     2   A     0     1   A   \n",
       "\n",
       "    Referee  HStr  HSOH  HSOA  HSAH  HSAA  HSDH  HSDA  HO  HA  HM  HD  HDP  \\\n",
       "0  A Taylor     3  1085  1100  1110  1110  1060  1090  76  77  75  76    4   \n",
       "\n",
       "   HIP  HSAAg  HATAAg  HGls  HAssts  HGlsPK   HxG  HNpxG  HxAG  HPoss  HPrg  \\\n",
       "0    2   26.6    25.2   1.0    0.76    0.97  1.02   0.96  0.75   45.8  14.2   \n",
       "\n",
       "   HPrgP  HGKS%  HGKCS%  HSoT  Hg-xG   HCmp  HCmp%  HPrgDist   HXa   HKP  \\\n",
       "0   32.2   71.8    24.3  3.51  -0.02  348.8   77.2    2310.4  0.61  8.19   \n",
       "\n",
       "   HPPA  HCrsPA   HTB  HCrs   HCK  HSCA  HGCA  HTkIW  HLost  HBlocks  HPass  \\\n",
       "0  6.14    1.27  0.95  15.4  4.89  19.4  1.76   11.2   6.73     12.3   9.08   \n",
       "\n",
       "   HInt  HClr  HAttPen  HSucc%  HCPA  HDis  HPrgR  HOnG  HOnGA  HOnxG  HOnxGA  \\\n",
       "0  9.65  21.5     19.9    46.9  5.41  12.1   32.1  1.05    1.3   1.02    1.29   \n",
       "\n",
       "   AStr  ASOH  ASOA  ASAH  ASAA  ASDH  ASDA  AO  AA  AM  AD  ADP  AIP  ASAAg  \\\n",
       "0     4  1245  1285  1250  1250  1240  1320  80  83  81  79    7    7   24.1   \n",
       "\n",
       "   ATAAg  AGls  AAssts  AGlsPK   AxG  ANpxG  AxAG  APoss  APrg  APrgP  AGKS%  \\\n",
       "0   23.0  2.14    1.62    2.05  1.87   1.79  1.39   59.5  21.7   54.2   70.6   \n",
       "\n",
       "   AGKCS%  ASoT  Ag-xG   ACmp  ACmp%  APrgDist   AXa   AKP   APPA  ACrsPA  \\\n",
       "0    35.1  5.03   0.27  482.8   83.1    2658.9  1.21  11.7  12.01    1.65   \n",
       "\n",
       "    ATB  ACrs   ACK  ASCA  AGCA  ATkIW  ALost  ABlocks  APass  AInt  AClr  \\\n",
       "0  2.24  17.8  5.81  27.6  3.81   8.89   6.51     9.49   7.22  6.35  15.8   \n",
       "\n",
       "   AAttPen  ASucc%  ACPA  ADis  APrgR  AOnG  AOnGA  AOnxG  AOnxGA  \n",
       "0     34.0    46.3  7.38  10.1   53.5  2.24   1.16   1.87    1.12  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data2 = pd.read_csv('../data/data_teams.csv')\n",
    "data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a60adb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'HStr', 'HSOH', 'HSOA', 'HSAH', 'HSAA', 'HSDH',\n",
    "          'HSDA', 'HO', 'HA', 'HM', 'HD', 'HDP', 'HIP', 'HSAAg', 'HATAAg', 'HGls', 'HAssts', 'HGlsPK', 'HxG', 'HNpxG', 'HxAG',\n",
    "          'HPoss', 'HPrg', 'HPrgP', 'HGKS%', 'HGKCS%', 'HSoT', 'Hg-xG', 'HCmp', 'HCmp%', 'HPrgDist', 'HXa', 'HKP', 'HPPA', 'HCrsPA',\n",
    "          'HTB', 'HCrs', 'HCK', 'HSCA', 'HGCA', 'HTkIW', 'HLost', 'HBlocks', 'HPass', 'HInt', 'HClr', 'HAttPen', 'HSucc%', 'HCPA',\n",
    "          'HDis', 'HPrgR', 'HOnG', 'HOnGA', 'HOnxG', 'HOnxGA', 'AStr', 'ASOH', 'ASOA', 'ASAH', 'ASAA', 'ASDH', 'ASDA', 'AO', 'AA',\n",
    "          'AM', 'AD', 'ADP', 'AIP', 'ASAAg', 'ATAAg', 'AGls', 'AAssts', 'AGlsPK', 'AxG', 'ANpxG', 'AxAG', 'APoss', 'APrg', 'APrgP',\n",
    "          'AGKS%', 'AGKCS%', 'ASoT', 'Ag-xG', 'ACmp', 'ACmp%', 'APrgDist', 'AXa', 'AKP', 'APPA', 'ACrsPA', 'ATB', 'ACrs', 'ACK',\n",
    "          'ASCA', 'AGCA', 'ATkIW', 'ALost', 'ABlocks', 'APass', 'AInt', 'AClr','AAttPen', 'ASucc%', 'ACPA', 'ADis', 'APrgR', 'AOnG',\n",
    "          'AOnGA', 'AOnxG', 'AOnxGA']].copy()\n",
    "y = data2['FTHG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a9fd504",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8ffcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "91276f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.77896664\n",
      "Iteration 2, loss = 1.75661056\n",
      "Iteration 3, loss = 1.11752522\n",
      "Iteration 4, loss = 0.88308195\n",
      "Iteration 5, loss = 0.90365611\n",
      "Iteration 6, loss = 1.00192243\n",
      "Iteration 7, loss = 1.03500917\n",
      "Iteration 8, loss = 0.98368074\n",
      "Iteration 9, loss = 0.89574300\n",
      "Iteration 10, loss = 0.83208494\n",
      "Iteration 11, loss = 0.79377969\n",
      "Iteration 12, loss = 0.77941299\n",
      "Iteration 13, loss = 0.78385089\n",
      "Iteration 14, loss = 0.78975334\n",
      "Iteration 15, loss = 0.78746033\n",
      "Iteration 16, loss = 0.77816688\n",
      "Iteration 17, loss = 0.76428676\n",
      "Iteration 18, loss = 0.75051630\n",
      "Iteration 19, loss = 0.74185404\n",
      "Iteration 20, loss = 0.73737522\n",
      "Iteration 21, loss = 0.73221790\n",
      "Iteration 22, loss = 0.73050906\n",
      "Iteration 23, loss = 0.72506075\n",
      "Iteration 24, loss = 0.71806445\n",
      "Iteration 25, loss = 0.71036055\n",
      "Iteration 26, loss = 0.70528034\n",
      "Iteration 27, loss = 0.70059044\n",
      "Iteration 28, loss = 0.69697276\n",
      "Iteration 29, loss = 0.69219234\n",
      "Iteration 30, loss = 0.68580209\n",
      "Iteration 31, loss = 0.68117304\n",
      "Iteration 32, loss = 0.67634027\n",
      "Iteration 33, loss = 0.67131381\n",
      "Iteration 34, loss = 0.66696615\n",
      "Iteration 35, loss = 0.66253441\n",
      "Iteration 36, loss = 0.65769037\n",
      "Iteration 37, loss = 0.65446207\n",
      "Iteration 38, loss = 0.65004714\n",
      "Iteration 39, loss = 0.64539860\n",
      "Iteration 40, loss = 0.64118024\n",
      "Iteration 41, loss = 0.63645266\n",
      "Iteration 42, loss = 0.63221099\n",
      "Iteration 43, loss = 0.62863356\n",
      "Iteration 44, loss = 0.62467062\n",
      "Iteration 45, loss = 0.62045913\n",
      "Iteration 46, loss = 0.61657793\n",
      "Iteration 47, loss = 0.61320733\n",
      "Iteration 48, loss = 0.61035060\n",
      "Iteration 49, loss = 0.60653131\n",
      "Iteration 50, loss = 0.60235704\n",
      "Iteration 51, loss = 0.59902454\n",
      "Iteration 52, loss = 0.59506209\n",
      "Iteration 53, loss = 0.59225638\n",
      "Iteration 54, loss = 0.58814946\n",
      "Iteration 55, loss = 0.58509296\n",
      "Iteration 56, loss = 0.58246155\n",
      "Iteration 57, loss = 0.57795020\n",
      "Iteration 58, loss = 0.57545484\n",
      "Iteration 59, loss = 0.57291240\n",
      "Iteration 60, loss = 0.56934959\n",
      "Iteration 61, loss = 0.56494609\n",
      "Iteration 62, loss = 0.56283375\n",
      "Iteration 63, loss = 0.55899403\n",
      "Iteration 64, loss = 0.55557306\n",
      "Iteration 65, loss = 0.55186041\n",
      "Iteration 66, loss = 0.54840095\n",
      "Iteration 67, loss = 0.54523577\n",
      "Iteration 68, loss = 0.54280895\n",
      "Iteration 69, loss = 0.53927413\n",
      "Iteration 70, loss = 0.53582263\n",
      "Iteration 71, loss = 0.53294485\n",
      "Iteration 72, loss = 0.53023687\n",
      "Iteration 73, loss = 0.52733478\n",
      "Iteration 74, loss = 0.52376276\n",
      "Iteration 75, loss = 0.52131324\n",
      "Iteration 76, loss = 0.51791114\n",
      "Iteration 77, loss = 0.51446684\n",
      "Iteration 78, loss = 0.51121831\n",
      "Iteration 79, loss = 0.50864422\n",
      "Iteration 80, loss = 0.50547786\n",
      "Iteration 81, loss = 0.50271889\n",
      "Iteration 82, loss = 0.49973158\n",
      "Iteration 83, loss = 0.49685534\n",
      "Iteration 84, loss = 0.49382727\n",
      "Iteration 85, loss = 0.49070454\n",
      "Iteration 86, loss = 0.48749747\n",
      "Iteration 87, loss = 0.48420599\n",
      "Iteration 88, loss = 0.48164668\n",
      "Iteration 89, loss = 0.47844531\n",
      "Iteration 90, loss = 0.47596905\n",
      "Iteration 91, loss = 0.47243246\n",
      "Iteration 92, loss = 0.46918092\n",
      "Iteration 93, loss = 0.46558263\n",
      "Iteration 94, loss = 0.46278237\n",
      "Iteration 95, loss = 0.45946731\n",
      "Iteration 96, loss = 0.45634838\n",
      "Iteration 97, loss = 0.45336688\n",
      "Iteration 98, loss = 0.45079777\n",
      "Iteration 99, loss = 0.44708522\n",
      "Iteration 100, loss = 0.44354548\n",
      "Iteration 101, loss = 0.44288132\n",
      "Iteration 102, loss = 0.43969282\n",
      "Iteration 103, loss = 0.43532837\n",
      "Iteration 104, loss = 0.43268498\n",
      "Iteration 105, loss = 0.43014019\n",
      "Iteration 106, loss = 0.42650143\n",
      "Iteration 107, loss = 0.42253448\n",
      "Iteration 108, loss = 0.41939130\n",
      "Iteration 109, loss = 0.41621216\n",
      "Iteration 110, loss = 0.41411573\n",
      "Iteration 111, loss = 0.40983570\n",
      "Iteration 112, loss = 0.40748580\n",
      "Iteration 113, loss = 0.40398218\n",
      "Iteration 114, loss = 0.39936425\n",
      "Iteration 115, loss = 0.39781594\n",
      "Iteration 116, loss = 0.39592921\n",
      "Iteration 117, loss = 0.39021684\n",
      "Iteration 118, loss = 0.38796188\n",
      "Iteration 119, loss = 0.38745945\n",
      "Iteration 120, loss = 0.38292110\n",
      "Iteration 121, loss = 0.37834050\n",
      "Iteration 122, loss = 0.37708950\n",
      "Iteration 123, loss = 0.37469809\n",
      "Iteration 124, loss = 0.37096391\n",
      "Iteration 125, loss = 0.36737048\n",
      "Iteration 126, loss = 0.36737040\n",
      "Iteration 127, loss = 0.35945569\n",
      "Iteration 128, loss = 0.35570665\n",
      "Iteration 129, loss = 0.35258904\n",
      "Iteration 130, loss = 0.34900586\n",
      "Iteration 131, loss = 0.34530495\n",
      "Iteration 132, loss = 0.34209102\n",
      "Iteration 133, loss = 0.33928163\n",
      "Iteration 134, loss = 0.33606563\n",
      "Iteration 135, loss = 0.33219320\n",
      "Iteration 136, loss = 0.32971850\n",
      "Iteration 137, loss = 0.32616837\n",
      "Iteration 138, loss = 0.32238048\n",
      "Iteration 139, loss = 0.32385593\n",
      "Iteration 140, loss = 0.31981867\n",
      "Iteration 141, loss = 0.31371599\n",
      "Iteration 142, loss = 0.31090636\n",
      "Iteration 143, loss = 0.30723149\n",
      "Iteration 144, loss = 0.30513261\n",
      "Iteration 145, loss = 0.30034528\n",
      "Iteration 146, loss = 0.29836295\n",
      "Iteration 147, loss = 0.29511415\n",
      "Iteration 148, loss = 0.29129676\n",
      "Iteration 149, loss = 0.28862802\n",
      "Iteration 150, loss = 0.28465243\n",
      "Iteration 151, loss = 0.28151773\n",
      "Iteration 152, loss = 0.27973144\n",
      "Iteration 153, loss = 0.27563762\n",
      "Iteration 154, loss = 0.27237396\n",
      "Iteration 155, loss = 0.26907147\n",
      "Iteration 156, loss = 0.26577209\n",
      "Iteration 157, loss = 0.26268439\n",
      "Iteration 158, loss = 0.25931374\n",
      "Iteration 159, loss = 0.25594114\n",
      "Iteration 160, loss = 0.25357848\n",
      "Iteration 161, loss = 0.24946675\n",
      "Iteration 162, loss = 0.24723766\n",
      "Iteration 163, loss = 0.24455755\n",
      "Iteration 164, loss = 0.24114510\n",
      "Iteration 165, loss = 0.23822389\n",
      "Iteration 166, loss = 0.23520711\n",
      "Iteration 167, loss = 0.23174568\n",
      "Iteration 168, loss = 0.23078721\n",
      "Iteration 169, loss = 0.22782598\n",
      "Iteration 170, loss = 0.22384204\n",
      "Iteration 171, loss = 0.22266125\n",
      "Iteration 172, loss = 0.21788016\n",
      "Iteration 173, loss = 0.21536647\n",
      "Iteration 174, loss = 0.21313581\n",
      "Iteration 175, loss = 0.21027635\n",
      "Iteration 176, loss = 0.20782313\n",
      "Iteration 177, loss = 0.20405526\n",
      "Iteration 178, loss = 0.20084428\n",
      "Iteration 179, loss = 0.19807567\n",
      "Iteration 180, loss = 0.19624187\n",
      "Iteration 181, loss = 0.19357223\n",
      "Iteration 182, loss = 0.19013075\n",
      "Iteration 183, loss = 0.18852193\n",
      "Iteration 184, loss = 0.18549531\n",
      "Iteration 185, loss = 0.18318430\n",
      "Iteration 186, loss = 0.18019107\n",
      "Iteration 187, loss = 0.17928356\n",
      "Iteration 188, loss = 0.17509289\n",
      "Iteration 189, loss = 0.17414570\n",
      "Iteration 190, loss = 0.17207052\n",
      "Iteration 191, loss = 0.16909185\n",
      "Iteration 192, loss = 0.16574999\n",
      "Iteration 193, loss = 0.16402611\n",
      "Iteration 194, loss = 0.16162126\n",
      "Iteration 195, loss = 0.15735311\n",
      "Iteration 196, loss = 0.15912184\n",
      "Iteration 197, loss = 0.15606726\n",
      "Iteration 198, loss = 0.15290304\n",
      "Iteration 199, loss = 0.14960026\n",
      "Iteration 200, loss = 0.14811785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-104\" type=\"checkbox\" ><label for=\"sk-estimator-id-104\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7179312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.1419476883494113\n",
      "MAE: 1.1842239096062004\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7343aaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.72688532\n",
      "Iteration 2, loss = 2.00251561\n",
      "Iteration 3, loss = 1.46837720\n",
      "Iteration 4, loss = 1.10286717\n",
      "Iteration 5, loss = 1.01158726\n",
      "Iteration 6, loss = 1.07827294\n",
      "Iteration 7, loss = 1.05483163\n",
      "Iteration 8, loss = 0.93718809\n",
      "Iteration 9, loss = 0.85988385\n",
      "Iteration 10, loss = 0.84954913\n",
      "Iteration 11, loss = 0.85870639\n",
      "Iteration 12, loss = 0.84486913\n",
      "Iteration 13, loss = 0.81134932\n",
      "Iteration 14, loss = 0.77827137\n",
      "Iteration 15, loss = 0.77908188\n",
      "Iteration 16, loss = 0.78029987\n",
      "Iteration 17, loss = 0.76735178\n",
      "Iteration 18, loss = 0.74794874\n",
      "Iteration 19, loss = 0.73395819\n",
      "Iteration 20, loss = 0.72739196\n",
      "Iteration 21, loss = 0.71882966\n",
      "Iteration 22, loss = 0.70795153\n",
      "Iteration 23, loss = 0.69747412\n",
      "Iteration 24, loss = 0.68713839\n",
      "Iteration 25, loss = 0.67657608\n",
      "Iteration 26, loss = 0.66593626\n",
      "Iteration 27, loss = 0.65682269\n",
      "Iteration 28, loss = 0.64532652\n",
      "Iteration 29, loss = 0.63257804\n",
      "Iteration 30, loss = 0.62285863\n",
      "Iteration 31, loss = 0.61150031\n",
      "Iteration 32, loss = 0.59878939\n",
      "Iteration 33, loss = 0.58812627\n",
      "Iteration 34, loss = 0.58455060\n",
      "Iteration 35, loss = 0.57263098\n",
      "Iteration 36, loss = 0.55616870\n",
      "Iteration 37, loss = 0.54533400\n",
      "Iteration 38, loss = 0.53464266\n",
      "Iteration 39, loss = 0.52139396\n",
      "Iteration 40, loss = 0.51140652\n",
      "Iteration 41, loss = 0.49869395\n",
      "Iteration 42, loss = 0.48591589\n",
      "Iteration 43, loss = 0.47774532\n",
      "Iteration 44, loss = 0.46258456\n",
      "Iteration 45, loss = 0.45667432\n",
      "Iteration 46, loss = 0.43964901\n",
      "Iteration 47, loss = 0.43582627\n",
      "Iteration 48, loss = 0.41360654\n",
      "Iteration 49, loss = 0.41980045\n",
      "Iteration 50, loss = 0.39141626\n",
      "Iteration 51, loss = 0.39017574\n",
      "Iteration 52, loss = 0.37050861\n",
      "Iteration 53, loss = 0.36211135\n",
      "Iteration 54, loss = 0.34896799\n",
      "Iteration 55, loss = 0.34220249\n",
      "Iteration 56, loss = 0.32572450\n",
      "Iteration 57, loss = 0.30733594\n",
      "Iteration 58, loss = 0.30483463\n",
      "Iteration 59, loss = 0.28849663\n",
      "Iteration 60, loss = 0.27091850\n",
      "Iteration 61, loss = 0.26152410\n",
      "Iteration 62, loss = 0.24746096\n",
      "Iteration 63, loss = 0.24179062\n",
      "Iteration 64, loss = 0.22225381\n",
      "Iteration 65, loss = 0.22107546\n",
      "Iteration 66, loss = 0.20979680\n",
      "Iteration 67, loss = 0.19208180\n",
      "Iteration 68, loss = 0.18850286\n",
      "Iteration 69, loss = 0.17724096\n",
      "Iteration 70, loss = 0.15932061\n",
      "Iteration 71, loss = 0.16458364\n",
      "Iteration 72, loss = 0.13910460\n",
      "Iteration 73, loss = 0.13392480\n",
      "Iteration 74, loss = 0.12107724\n",
      "Iteration 75, loss = 0.11222238\n",
      "Iteration 76, loss = 0.10597949\n",
      "Iteration 77, loss = 0.09842160\n",
      "Iteration 78, loss = 0.08945185\n",
      "Iteration 79, loss = 0.08338684\n",
      "Iteration 80, loss = 0.07773113\n",
      "Iteration 81, loss = 0.07198915\n",
      "Iteration 82, loss = 0.06772684\n",
      "Iteration 83, loss = 0.06371600\n",
      "Iteration 84, loss = 0.05631230\n",
      "Iteration 85, loss = 0.05409949\n",
      "Iteration 86, loss = 0.05350845\n",
      "Iteration 87, loss = 0.05141552\n",
      "Iteration 88, loss = 0.04733204\n",
      "Iteration 89, loss = 0.04560642\n",
      "Iteration 90, loss = 0.03968731\n",
      "Iteration 91, loss = 0.03526509\n",
      "Iteration 92, loss = 0.03517991\n",
      "Iteration 93, loss = 0.03356165\n",
      "Iteration 94, loss = 0.03151737\n",
      "Iteration 95, loss = 0.02689243\n",
      "Iteration 96, loss = 0.02601316\n",
      "Iteration 97, loss = 0.02589763\n",
      "Iteration 98, loss = 0.02595723\n",
      "Iteration 99, loss = 0.02411457\n",
      "Iteration 100, loss = 0.02010145\n",
      "Iteration 101, loss = 0.01896617\n",
      "Iteration 102, loss = 0.01795433\n",
      "Iteration 103, loss = 0.01618275\n",
      "Iteration 104, loss = 0.01422879\n",
      "Iteration 105, loss = 0.01269173\n",
      "Iteration 106, loss = 0.01286004\n",
      "Iteration 107, loss = 0.01661041\n",
      "Iteration 108, loss = 0.01111854\n",
      "Iteration 109, loss = 0.01302392\n",
      "Iteration 110, loss = 0.01314922\n",
      "Iteration 111, loss = 0.01272098\n",
      "Iteration 112, loss = 0.01146700\n",
      "Iteration 113, loss = 0.01013002\n",
      "Iteration 114, loss = 0.00969018\n",
      "Iteration 115, loss = 0.00886942\n",
      "Iteration 116, loss = 0.00725815\n",
      "Iteration 117, loss = 0.00573053\n",
      "Iteration 118, loss = 0.00522375\n",
      "Iteration 119, loss = 0.00508037\n",
      "Iteration 120, loss = 0.00458814\n",
      "Iteration 121, loss = 0.00428946\n",
      "Iteration 122, loss = 0.00403818\n",
      "Iteration 123, loss = 0.00340701\n",
      "Iteration 124, loss = 0.00326283\n",
      "Iteration 125, loss = 0.00268317\n",
      "Iteration 126, loss = 0.00273510\n",
      "Iteration 127, loss = 0.00248914\n",
      "Iteration 128, loss = 0.00220941\n",
      "Iteration 129, loss = 0.00206951\n",
      "Iteration 130, loss = 0.00190166\n",
      "Iteration 131, loss = 0.00170088\n",
      "Iteration 132, loss = 0.00161851\n",
      "Iteration 133, loss = 0.00151062\n",
      "Iteration 134, loss = 0.00122624\n",
      "Iteration 135, loss = 0.00115631\n",
      "Iteration 136, loss = 0.00108247\n",
      "Iteration 137, loss = 0.00106585\n",
      "Iteration 138, loss = 0.00114132\n",
      "Iteration 139, loss = 0.00138741\n",
      "Iteration 140, loss = 0.00135765\n",
      "Iteration 141, loss = 0.00102028\n",
      "Iteration 142, loss = 0.00092516\n",
      "Iteration 143, loss = 0.00094609\n",
      "Iteration 144, loss = 0.00075649\n",
      "Iteration 145, loss = 0.00089666\n",
      "Iteration 146, loss = 0.00112068\n",
      "Iteration 147, loss = 0.00108833\n",
      "Iteration 148, loss = 0.00112811\n",
      "Iteration 149, loss = 0.00073988\n",
      "Iteration 150, loss = 0.00068651\n",
      "Iteration 151, loss = 0.00061248\n",
      "Iteration 152, loss = 0.00048466\n",
      "Iteration 153, loss = 0.00043689\n",
      "Iteration 154, loss = 0.00046168\n",
      "Iteration 155, loss = 0.00042255\n",
      "Iteration 156, loss = 0.00033354\n",
      "Iteration 157, loss = 0.00039740\n",
      "Iteration 158, loss = 0.00038563\n",
      "Iteration 159, loss = 0.00028116\n",
      "Iteration 160, loss = 0.00026225\n",
      "Iteration 161, loss = 0.00023975\n",
      "Iteration 162, loss = 0.00023447\n",
      "Iteration 163, loss = 0.00026238\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-105\" type=\"checkbox\" ><label for=\"sk-estimator-id-105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-106\" type=\"checkbox\" ><label for=\"sk-estimator-id-106\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-107\" type=\"checkbox\" ><label for=\"sk-estimator-id-107\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-108\" type=\"checkbox\" ><label for=\"sk-estimator-id-108\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-109\" type=\"checkbox\" ><label for=\"sk-estimator-id-109\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-110\" type=\"checkbox\" ><label for=\"sk-estimator-id-110\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-111\" type=\"checkbox\" ><label for=\"sk-estimator-id-111\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-112\" type=\"checkbox\" ><label for=\"sk-estimator-id-112\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdf681bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.34340433538408877\n",
      "MAE: 1.3580885512224763\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27bd334f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 19.53050690\n",
      "Iteration 2, loss = 18.71299301\n",
      "Iteration 3, loss = 18.06645387\n",
      "Iteration 4, loss = 17.49446115\n",
      "Iteration 5, loss = 17.03310416\n",
      "Iteration 6, loss = 16.63753067\n",
      "Iteration 7, loss = 16.22425552\n",
      "Iteration 8, loss = 15.78767852\n",
      "Iteration 9, loss = 15.34197575\n",
      "Iteration 10, loss = 14.91518239\n",
      "Iteration 11, loss = 14.51665789\n",
      "Iteration 12, loss = 14.13430067\n",
      "Iteration 13, loss = 13.76549342\n",
      "Iteration 14, loss = 13.39883172\n",
      "Iteration 15, loss = 13.03545524\n",
      "Iteration 16, loss = 12.67811406\n",
      "Iteration 17, loss = 12.32866845\n",
      "Iteration 18, loss = 11.99078585\n",
      "Iteration 19, loss = 11.66630980\n",
      "Iteration 20, loss = 11.35062142\n",
      "Iteration 21, loss = 11.04342855\n",
      "Iteration 22, loss = 10.74388788\n",
      "Iteration 23, loss = 10.45073990\n",
      "Iteration 24, loss = 10.16715219\n",
      "Iteration 25, loss = 9.89083757\n",
      "Iteration 26, loss = 9.62477207\n",
      "Iteration 27, loss = 9.36491538\n",
      "Iteration 28, loss = 9.11073071\n",
      "Iteration 29, loss = 8.86521045\n",
      "Iteration 30, loss = 8.62431535\n",
      "Iteration 31, loss = 8.39235868\n",
      "Iteration 32, loss = 8.16550946\n",
      "Iteration 33, loss = 7.94630171\n",
      "Iteration 34, loss = 7.73323333\n",
      "Iteration 35, loss = 7.52686644\n",
      "Iteration 36, loss = 7.32586777\n",
      "Iteration 37, loss = 7.13017176\n",
      "Iteration 38, loss = 6.94085743\n",
      "Iteration 39, loss = 6.75686961\n",
      "Iteration 40, loss = 6.57794678\n",
      "Iteration 41, loss = 6.40429373\n",
      "Iteration 42, loss = 6.23680584\n",
      "Iteration 43, loss = 6.07253048\n",
      "Iteration 44, loss = 5.91334572\n",
      "Iteration 45, loss = 5.76122801\n",
      "Iteration 46, loss = 5.61406613\n",
      "Iteration 47, loss = 5.46971862\n",
      "Iteration 48, loss = 5.32717676\n",
      "Iteration 49, loss = 5.18898513\n",
      "Iteration 50, loss = 5.05732161\n",
      "Iteration 51, loss = 4.93243392\n",
      "Iteration 52, loss = 4.80579844\n",
      "Iteration 53, loss = 4.68339455\n",
      "Iteration 54, loss = 4.56590184\n",
      "Iteration 55, loss = 4.45407136\n",
      "Iteration 56, loss = 4.34613910\n",
      "Iteration 57, loss = 4.23931289\n",
      "Iteration 58, loss = 4.13433795\n",
      "Iteration 59, loss = 4.03226599\n",
      "Iteration 60, loss = 3.93542623\n",
      "Iteration 61, loss = 3.84019964\n",
      "Iteration 62, loss = 3.74840484\n",
      "Iteration 63, loss = 3.66007613\n",
      "Iteration 64, loss = 3.57481037\n",
      "Iteration 65, loss = 3.49184229\n",
      "Iteration 66, loss = 3.41022398\n",
      "Iteration 67, loss = 3.33284023\n",
      "Iteration 68, loss = 3.25531337\n",
      "Iteration 69, loss = 3.18169491\n",
      "Iteration 70, loss = 3.11008414\n",
      "Iteration 71, loss = 3.04207805\n",
      "Iteration 72, loss = 2.97536087\n",
      "Iteration 73, loss = 2.91005630\n",
      "Iteration 74, loss = 2.84789728\n",
      "Iteration 75, loss = 2.78720041\n",
      "Iteration 76, loss = 2.72803580\n",
      "Iteration 77, loss = 2.67105781\n",
      "Iteration 78, loss = 2.61631451\n",
      "Iteration 79, loss = 2.56254028\n",
      "Iteration 80, loss = 2.51046029\n",
      "Iteration 81, loss = 2.46062459\n",
      "Iteration 82, loss = 2.41228665\n",
      "Iteration 83, loss = 2.36471936\n",
      "Iteration 84, loss = 2.32034500\n",
      "Iteration 85, loss = 2.27635261\n",
      "Iteration 86, loss = 2.23422670\n",
      "Iteration 87, loss = 2.19235487\n",
      "Iteration 88, loss = 2.15208327\n",
      "Iteration 89, loss = 2.11323032\n",
      "Iteration 90, loss = 2.07577379\n",
      "Iteration 91, loss = 2.04110187\n",
      "Iteration 92, loss = 2.00514505\n",
      "Iteration 93, loss = 1.97193174\n",
      "Iteration 94, loss = 1.93818461\n",
      "Iteration 95, loss = 1.90682433\n",
      "Iteration 96, loss = 1.87588082\n",
      "Iteration 97, loss = 1.84651418\n",
      "Iteration 98, loss = 1.81805713\n",
      "Iteration 99, loss = 1.79027639\n",
      "Iteration 100, loss = 1.76309041\n",
      "Iteration 101, loss = 1.73703946\n",
      "Iteration 102, loss = 1.71193467\n",
      "Iteration 103, loss = 1.68803437\n",
      "Iteration 104, loss = 1.66481582\n",
      "Iteration 105, loss = 1.64199356\n",
      "Iteration 106, loss = 1.62165595\n",
      "Iteration 107, loss = 1.59854186\n",
      "Iteration 108, loss = 1.57821704\n",
      "Iteration 109, loss = 1.55787804\n",
      "Iteration 110, loss = 1.53924299\n",
      "Iteration 111, loss = 1.52007390\n",
      "Iteration 112, loss = 1.50274532\n",
      "Iteration 113, loss = 1.48531807\n",
      "Iteration 114, loss = 1.46808041\n",
      "Iteration 115, loss = 1.45218049\n",
      "Iteration 116, loss = 1.43604286\n",
      "Iteration 117, loss = 1.42138462\n",
      "Iteration 118, loss = 1.40595965\n",
      "Iteration 119, loss = 1.39227491\n",
      "Iteration 120, loss = 1.37844040\n",
      "Iteration 121, loss = 1.36465785\n",
      "Iteration 122, loss = 1.35176619\n",
      "Iteration 123, loss = 1.33950051\n",
      "Iteration 124, loss = 1.32769367\n",
      "Iteration 125, loss = 1.31641294\n",
      "Iteration 126, loss = 1.30514551\n",
      "Iteration 127, loss = 1.29315707\n",
      "Iteration 128, loss = 1.28431059\n",
      "Iteration 129, loss = 1.27721761\n",
      "Iteration 130, loss = 1.26775306\n",
      "Iteration 131, loss = 1.25546197\n",
      "Iteration 132, loss = 1.24557023\n",
      "Iteration 133, loss = 1.23667995\n",
      "Iteration 134, loss = 1.22923053\n",
      "Iteration 135, loss = 1.22104497\n",
      "Iteration 136, loss = 1.21352357\n",
      "Iteration 137, loss = 1.20420988\n",
      "Iteration 138, loss = 1.19706829\n",
      "Iteration 139, loss = 1.18971349\n",
      "Iteration 140, loss = 1.18355682\n",
      "Iteration 141, loss = 1.17601477\n",
      "Iteration 142, loss = 1.16953590\n",
      "Iteration 143, loss = 1.16428114\n",
      "Iteration 144, loss = 1.15670299\n",
      "Iteration 145, loss = 1.15088172\n",
      "Iteration 146, loss = 1.14600914\n",
      "Iteration 147, loss = 1.13990947\n",
      "Iteration 148, loss = 1.13483336\n",
      "Iteration 149, loss = 1.13033136\n",
      "Iteration 150, loss = 1.12514143\n",
      "Iteration 151, loss = 1.12129830\n",
      "Iteration 152, loss = 1.11692189\n",
      "Iteration 153, loss = 1.11088999\n",
      "Iteration 154, loss = 1.10724528\n",
      "Iteration 155, loss = 1.10545046\n",
      "Iteration 156, loss = 1.10064852\n",
      "Iteration 157, loss = 1.09480845\n",
      "Iteration 158, loss = 1.09075750\n",
      "Iteration 159, loss = 1.08920568\n",
      "Iteration 160, loss = 1.08667334\n",
      "Iteration 161, loss = 1.08240853\n",
      "Iteration 162, loss = 1.07918519\n",
      "Iteration 163, loss = 1.07446689\n",
      "Iteration 164, loss = 1.07270372\n",
      "Iteration 165, loss = 1.06867913\n",
      "Iteration 166, loss = 1.06771425\n",
      "Iteration 167, loss = 1.06204584\n",
      "Iteration 168, loss = 1.06198129\n",
      "Iteration 169, loss = 1.06137432\n",
      "Iteration 170, loss = 1.05851961\n",
      "Iteration 171, loss = 1.05495858\n",
      "Iteration 172, loss = 1.05020033\n",
      "Iteration 173, loss = 1.04853408\n",
      "Iteration 174, loss = 1.04698124\n",
      "Iteration 175, loss = 1.04550823\n",
      "Iteration 176, loss = 1.04377247\n",
      "Iteration 177, loss = 1.04233726\n",
      "Iteration 178, loss = 1.04100629\n",
      "Iteration 179, loss = 1.03725363\n",
      "Iteration 180, loss = 1.03532390\n",
      "Iteration 181, loss = 1.03368147\n",
      "Iteration 182, loss = 1.03181164\n",
      "Iteration 183, loss = 1.03082189\n",
      "Iteration 184, loss = 1.03170187\n",
      "Iteration 185, loss = 1.02918172\n",
      "Iteration 186, loss = 1.02624017\n",
      "Iteration 187, loss = 1.02425142\n",
      "Iteration 188, loss = 1.02347527\n",
      "Iteration 189, loss = 1.02345122\n",
      "Iteration 190, loss = 1.02231011\n",
      "Iteration 191, loss = 1.01997209\n",
      "Iteration 192, loss = 1.01665879\n",
      "Iteration 193, loss = 1.02240169\n",
      "Iteration 194, loss = 1.02317235\n",
      "Iteration 195, loss = 1.02105836\n",
      "Iteration 196, loss = 1.01540995\n",
      "Iteration 197, loss = 1.01517452\n",
      "Iteration 198, loss = 1.01311907\n",
      "Iteration 199, loss = 1.01276484\n",
      "Iteration 200, loss = 1.01088075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-113\" type=\"checkbox\" ><label for=\"sk-estimator-id-113\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-114\" type=\"checkbox\" ><label for=\"sk-estimator-id-114\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-115\" type=\"checkbox\" ><label for=\"sk-estimator-id-115\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-116\" type=\"checkbox\" ><label for=\"sk-estimator-id-116\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-117\" type=\"checkbox\" ><label for=\"sk-estimator-id-117\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-118\" type=\"checkbox\" ><label for=\"sk-estimator-id-118\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-119\" type=\"checkbox\" ><label for=\"sk-estimator-id-119\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-120\" type=\"checkbox\" ><label for=\"sk-estimator-id-120\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4de9e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.16350328616363996\n",
      "MAE: 1.056411983152845\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc32d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'HStr', 'HSOH', 'HSOA', 'HSAH', 'HSAA', 'HSDH',\n",
    "          'HSDA', 'HO', 'HA', 'HM', 'HD', 'HDP', 'HIP', 'HSAAg', 'HATAAg', 'HGls', 'HAssts', 'HGlsPK', 'HxG', 'HNpxG', 'HxAG',\n",
    "          'HPoss', 'HPrg', 'HPrgP', 'HGKS%', 'HGKCS%', 'HSoT', 'Hg-xG', 'HCmp', 'HCmp%', 'HPrgDist', 'HXa', 'HKP', 'HPPA', 'HCrsPA',\n",
    "          'HTB', 'HCrs', 'HCK', 'HSCA', 'HGCA', 'HTkIW', 'HLost', 'HBlocks', 'HPass', 'HInt', 'HClr', 'HAttPen', 'HSucc%', 'HCPA',\n",
    "          'HDis', 'HPrgR', 'HOnG', 'HOnGA', 'HOnxG', 'HOnxGA', 'AStr', 'ASOH', 'ASOA', 'ASAH', 'ASAA', 'ASDH', 'ASDA', 'AO', 'AA',\n",
    "          'AM', 'AD', 'ADP', 'AIP', 'ASAAg', 'ATAAg', 'AGls', 'AAssts', 'AGlsPK', 'AxG', 'ANpxG', 'AxAG', 'APoss', 'APrg', 'APrgP',\n",
    "          'AGKS%', 'AGKCS%', 'ASoT', 'Ag-xG', 'ACmp', 'ACmp%', 'APrgDist', 'AXa', 'AKP', 'APPA', 'ACrsPA', 'ATB', 'ACrs', 'ACK',\n",
    "          'ASCA', 'AGCA', 'ATkIW', 'ALost', 'ABlocks', 'APass', 'AInt', 'AClr','AAttPen', 'ASucc%', 'ACPA', 'ADis', 'APrgR', 'AOnG',\n",
    "          'AOnGA', 'AOnxG', 'AOnxGA']].copy()\n",
    "y = data2['FTAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29b22a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f48288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67ed3382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.86518318\n",
      "Iteration 2, loss = 0.72473490\n",
      "Iteration 3, loss = 0.64718646\n",
      "Iteration 4, loss = 0.59825893\n",
      "Iteration 5, loss = 0.57620814\n",
      "Iteration 6, loss = 0.56724195\n",
      "Iteration 7, loss = 0.56637888\n",
      "Iteration 8, loss = 0.56064457\n",
      "Iteration 9, loss = 0.54871053\n",
      "Iteration 10, loss = 0.53501961\n",
      "Iteration 11, loss = 0.51898657\n",
      "Iteration 12, loss = 0.50811023\n",
      "Iteration 13, loss = 0.50000927\n",
      "Iteration 14, loss = 0.49373788\n",
      "Iteration 15, loss = 0.48871598\n",
      "Iteration 16, loss = 0.48282734\n",
      "Iteration 17, loss = 0.47532898\n",
      "Iteration 18, loss = 0.46902645\n",
      "Iteration 19, loss = 0.46082872\n",
      "Iteration 20, loss = 0.45687578\n",
      "Iteration 21, loss = 0.45287341\n",
      "Iteration 22, loss = 0.44792471\n",
      "Iteration 23, loss = 0.44680737\n",
      "Iteration 24, loss = 0.43957836\n",
      "Iteration 25, loss = 0.43397636\n",
      "Iteration 26, loss = 0.43177911\n",
      "Iteration 27, loss = 0.42720089\n",
      "Iteration 28, loss = 0.42363009\n",
      "Iteration 29, loss = 0.42000359\n",
      "Iteration 30, loss = 0.41583876\n",
      "Iteration 31, loss = 0.41237216\n",
      "Iteration 32, loss = 0.40967333\n",
      "Iteration 33, loss = 0.40505359\n",
      "Iteration 34, loss = 0.40235704\n",
      "Iteration 35, loss = 0.40320638\n",
      "Iteration 36, loss = 0.40220179\n",
      "Iteration 37, loss = 0.39249939\n",
      "Iteration 38, loss = 0.38959716\n",
      "Iteration 39, loss = 0.38727396\n",
      "Iteration 40, loss = 0.38390089\n",
      "Iteration 41, loss = 0.38204960\n",
      "Iteration 42, loss = 0.37669780\n",
      "Iteration 43, loss = 0.37391637\n",
      "Iteration 44, loss = 0.37099208\n",
      "Iteration 45, loss = 0.36769805\n",
      "Iteration 46, loss = 0.36437467\n",
      "Iteration 47, loss = 0.36153713\n",
      "Iteration 48, loss = 0.36063455\n",
      "Iteration 49, loss = 0.35687421\n",
      "Iteration 50, loss = 0.35349206\n",
      "Iteration 51, loss = 0.35002004\n",
      "Iteration 52, loss = 0.34840100\n",
      "Iteration 53, loss = 0.34506296\n",
      "Iteration 54, loss = 0.34316756\n",
      "Iteration 55, loss = 0.33931586\n",
      "Iteration 56, loss = 0.33596986\n",
      "Iteration 57, loss = 0.33442417\n",
      "Iteration 58, loss = 0.33164716\n",
      "Iteration 59, loss = 0.32946150\n",
      "Iteration 60, loss = 0.32474929\n",
      "Iteration 61, loss = 0.32285490\n",
      "Iteration 62, loss = 0.31877472\n",
      "Iteration 63, loss = 0.31397260\n",
      "Iteration 64, loss = 0.31241968\n",
      "Iteration 65, loss = 0.30929998\n",
      "Iteration 66, loss = 0.31005655\n",
      "Iteration 67, loss = 0.30301765\n",
      "Iteration 68, loss = 0.30057680\n",
      "Iteration 69, loss = 0.29508514\n",
      "Iteration 70, loss = 0.29643585\n",
      "Iteration 71, loss = 0.29087519\n",
      "Iteration 72, loss = 0.28819355\n",
      "Iteration 73, loss = 0.28582182\n",
      "Iteration 74, loss = 0.27931636\n",
      "Iteration 75, loss = 0.27981091\n",
      "Iteration 76, loss = 0.27401850\n",
      "Iteration 77, loss = 0.27525831\n",
      "Iteration 78, loss = 0.27065840\n",
      "Iteration 79, loss = 0.26635464\n",
      "Iteration 80, loss = 0.26168377\n",
      "Iteration 81, loss = 0.25945721\n",
      "Iteration 82, loss = 0.25727492\n",
      "Iteration 83, loss = 0.25273893\n",
      "Iteration 84, loss = 0.24947571\n",
      "Iteration 85, loss = 0.24620624\n",
      "Iteration 86, loss = 0.24267683\n",
      "Iteration 87, loss = 0.24029619\n",
      "Iteration 88, loss = 0.23779183\n",
      "Iteration 89, loss = 0.23421524\n",
      "Iteration 90, loss = 0.23047791\n",
      "Iteration 91, loss = 0.22697480\n",
      "Iteration 92, loss = 0.22487356\n",
      "Iteration 93, loss = 0.22258367\n",
      "Iteration 94, loss = 0.21716698\n",
      "Iteration 95, loss = 0.21529419\n",
      "Iteration 96, loss = 0.21140314\n",
      "Iteration 97, loss = 0.20800159\n",
      "Iteration 98, loss = 0.20631974\n",
      "Iteration 99, loss = 0.20349844\n",
      "Iteration 100, loss = 0.20021536\n",
      "Iteration 101, loss = 0.19672842\n",
      "Iteration 102, loss = 0.19430325\n",
      "Iteration 103, loss = 0.19023437\n",
      "Iteration 104, loss = 0.19006564\n",
      "Iteration 105, loss = 0.18461680\n",
      "Iteration 106, loss = 0.18320432\n",
      "Iteration 107, loss = 0.17927812\n",
      "Iteration 108, loss = 0.17651627\n",
      "Iteration 109, loss = 0.17478092\n",
      "Iteration 110, loss = 0.17053721\n",
      "Iteration 111, loss = 0.16966812\n",
      "Iteration 112, loss = 0.16576251\n",
      "Iteration 113, loss = 0.16335379\n",
      "Iteration 114, loss = 0.15958877\n",
      "Iteration 115, loss = 0.16027482\n",
      "Iteration 116, loss = 0.15476751\n",
      "Iteration 117, loss = 0.15427519\n",
      "Iteration 118, loss = 0.14992187\n",
      "Iteration 119, loss = 0.14809743\n",
      "Iteration 120, loss = 0.14385870\n",
      "Iteration 121, loss = 0.14473479\n",
      "Iteration 122, loss = 0.13939733\n",
      "Iteration 123, loss = 0.13577048\n",
      "Iteration 124, loss = 0.13456432\n",
      "Iteration 125, loss = 0.13079668\n",
      "Iteration 126, loss = 0.13037645\n",
      "Iteration 127, loss = 0.12613839\n",
      "Iteration 128, loss = 0.12381402\n",
      "Iteration 129, loss = 0.12114656\n",
      "Iteration 130, loss = 0.11940633\n",
      "Iteration 131, loss = 0.11648954\n",
      "Iteration 132, loss = 0.11567276\n",
      "Iteration 133, loss = 0.11621308\n",
      "Iteration 134, loss = 0.10996000\n",
      "Iteration 135, loss = 0.11507718\n",
      "Iteration 136, loss = 0.10727643\n",
      "Iteration 137, loss = 0.10891307\n",
      "Iteration 138, loss = 0.10432124\n",
      "Iteration 139, loss = 0.10207246\n",
      "Iteration 140, loss = 0.09843961\n",
      "Iteration 141, loss = 0.09685332\n",
      "Iteration 142, loss = 0.09461348\n",
      "Iteration 143, loss = 0.09217751\n",
      "Iteration 144, loss = 0.09069309\n",
      "Iteration 145, loss = 0.08987868\n",
      "Iteration 146, loss = 0.08827451\n",
      "Iteration 147, loss = 0.08538147\n",
      "Iteration 148, loss = 0.08344085\n",
      "Iteration 149, loss = 0.08398478\n",
      "Iteration 150, loss = 0.07969263\n",
      "Iteration 151, loss = 0.08214112\n",
      "Iteration 152, loss = 0.07686027\n",
      "Iteration 153, loss = 0.07719840\n",
      "Iteration 154, loss = 0.07396659\n",
      "Iteration 155, loss = 0.07188771\n",
      "Iteration 156, loss = 0.07155567\n",
      "Iteration 157, loss = 0.06878713\n",
      "Iteration 158, loss = 0.06773624\n",
      "Iteration 159, loss = 0.06610998\n",
      "Iteration 160, loss = 0.06477183\n",
      "Iteration 161, loss = 0.06362395\n",
      "Iteration 162, loss = 0.06264284\n",
      "Iteration 163, loss = 0.06047565\n",
      "Iteration 164, loss = 0.05990391\n",
      "Iteration 165, loss = 0.05796838\n",
      "Iteration 166, loss = 0.05729039\n",
      "Iteration 167, loss = 0.05539652\n",
      "Iteration 168, loss = 0.05480254\n",
      "Iteration 169, loss = 0.05323741\n",
      "Iteration 170, loss = 0.05219614\n",
      "Iteration 171, loss = 0.05056028\n",
      "Iteration 172, loss = 0.05019914\n",
      "Iteration 173, loss = 0.04854321\n",
      "Iteration 174, loss = 0.04780951\n",
      "Iteration 175, loss = 0.04661189\n",
      "Iteration 176, loss = 0.04525985\n",
      "Iteration 177, loss = 0.04547212\n",
      "Iteration 178, loss = 0.04404448\n",
      "Iteration 179, loss = 0.04323772\n",
      "Iteration 180, loss = 0.04348067\n",
      "Iteration 181, loss = 0.04063946\n",
      "Iteration 182, loss = 0.03987900\n",
      "Iteration 183, loss = 0.04001459\n",
      "Iteration 184, loss = 0.03885477\n",
      "Iteration 185, loss = 0.03768242\n",
      "Iteration 186, loss = 0.03875377\n",
      "Iteration 187, loss = 0.03593543\n",
      "Iteration 188, loss = 0.03560863\n",
      "Iteration 189, loss = 0.03413056\n",
      "Iteration 190, loss = 0.03362229\n",
      "Iteration 191, loss = 0.03279972\n",
      "Iteration 192, loss = 0.03222932\n",
      "Iteration 193, loss = 0.03440676\n",
      "Iteration 194, loss = 0.03269065\n",
      "Iteration 195, loss = 0.03069589\n",
      "Iteration 196, loss = 0.03521803\n",
      "Iteration 197, loss = 0.02910444\n",
      "Iteration 198, loss = 0.03122765\n",
      "Iteration 199, loss = 0.02838366\n",
      "Iteration 200, loss = 0.02803853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-121\" type=\"checkbox\" ><label for=\"sk-estimator-id-121\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-122\" type=\"checkbox\" ><label for=\"sk-estimator-id-122\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-123\" type=\"checkbox\" ><label for=\"sk-estimator-id-123\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-124\" type=\"checkbox\" ><label for=\"sk-estimator-id-124\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-125\" type=\"checkbox\" ><label for=\"sk-estimator-id-125\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-126\" type=\"checkbox\" ><label for=\"sk-estimator-id-126\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-127\" type=\"checkbox\" ><label for=\"sk-estimator-id-127\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-128\" type=\"checkbox\" ><label for=\"sk-estimator-id-128\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ab9362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.22465801687163056\n",
      "MAE: 1.037123807635497\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63b33fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.08659745\n",
      "Iteration 2, loss = 0.73585936\n",
      "Iteration 3, loss = 0.70163302\n",
      "Iteration 4, loss = 0.66413877\n",
      "Iteration 5, loss = 0.60513741\n",
      "Iteration 6, loss = 0.57763336\n",
      "Iteration 7, loss = 0.57255338\n",
      "Iteration 8, loss = 0.55521805\n",
      "Iteration 9, loss = 0.54555559\n",
      "Iteration 10, loss = 0.54917777\n",
      "Iteration 11, loss = 0.53973343\n",
      "Iteration 12, loss = 0.52220502\n",
      "Iteration 13, loss = 0.50848324\n",
      "Iteration 14, loss = 0.50140387\n",
      "Iteration 15, loss = 0.49035172\n",
      "Iteration 16, loss = 0.48639165\n",
      "Iteration 17, loss = 0.47372906\n",
      "Iteration 18, loss = 0.46362059\n",
      "Iteration 19, loss = 0.45148225\n",
      "Iteration 20, loss = 0.43959495\n",
      "Iteration 21, loss = 0.43486451\n",
      "Iteration 22, loss = 0.42133946\n",
      "Iteration 23, loss = 0.41410122\n",
      "Iteration 24, loss = 0.41209860\n",
      "Iteration 25, loss = 0.39074960\n",
      "Iteration 26, loss = 0.38332986\n",
      "Iteration 27, loss = 0.36803486\n",
      "Iteration 28, loss = 0.35833469\n",
      "Iteration 29, loss = 0.35038672\n",
      "Iteration 30, loss = 0.33708637\n",
      "Iteration 31, loss = 0.32510968\n",
      "Iteration 32, loss = 0.31447847\n",
      "Iteration 33, loss = 0.30704223\n",
      "Iteration 34, loss = 0.29119018\n",
      "Iteration 35, loss = 0.28267661\n",
      "Iteration 36, loss = 0.27672684\n",
      "Iteration 37, loss = 0.26876662\n",
      "Iteration 38, loss = 0.25099087\n",
      "Iteration 39, loss = 0.25739784\n",
      "Iteration 40, loss = 0.23030845\n",
      "Iteration 41, loss = 0.22640898\n",
      "Iteration 42, loss = 0.21598504\n",
      "Iteration 43, loss = 0.19593705\n",
      "Iteration 44, loss = 0.19505985\n",
      "Iteration 45, loss = 0.19147592\n",
      "Iteration 46, loss = 0.16914692\n",
      "Iteration 47, loss = 0.16296083\n",
      "Iteration 48, loss = 0.16202905\n",
      "Iteration 49, loss = 0.13805254\n",
      "Iteration 50, loss = 0.12784071\n",
      "Iteration 51, loss = 0.12017975\n",
      "Iteration 52, loss = 0.11237908\n",
      "Iteration 53, loss = 0.10009056\n",
      "Iteration 54, loss = 0.09434207\n",
      "Iteration 55, loss = 0.08645338\n",
      "Iteration 56, loss = 0.07777433\n",
      "Iteration 57, loss = 0.07273433\n",
      "Iteration 58, loss = 0.06471945\n",
      "Iteration 59, loss = 0.06150880\n",
      "Iteration 60, loss = 0.05657238\n",
      "Iteration 61, loss = 0.05377698\n",
      "Iteration 62, loss = 0.04441242\n",
      "Iteration 63, loss = 0.04329029\n",
      "Iteration 64, loss = 0.04065449\n",
      "Iteration 65, loss = 0.03455737\n",
      "Iteration 66, loss = 0.03067916\n",
      "Iteration 67, loss = 0.02824657\n",
      "Iteration 68, loss = 0.02395891\n",
      "Iteration 69, loss = 0.02212341\n",
      "Iteration 70, loss = 0.01977151\n",
      "Iteration 71, loss = 0.01890713\n",
      "Iteration 72, loss = 0.01638023\n",
      "Iteration 73, loss = 0.01365250\n",
      "Iteration 74, loss = 0.01193459\n",
      "Iteration 75, loss = 0.01144934\n",
      "Iteration 76, loss = 0.00960524\n",
      "Iteration 77, loss = 0.00883883\n",
      "Iteration 78, loss = 0.00798432\n",
      "Iteration 79, loss = 0.00699750\n",
      "Iteration 80, loss = 0.00696366\n",
      "Iteration 81, loss = 0.00983018\n",
      "Iteration 82, loss = 0.00947526\n",
      "Iteration 83, loss = 0.00589667\n",
      "Iteration 84, loss = 0.00500912\n",
      "Iteration 85, loss = 0.00606540\n",
      "Iteration 86, loss = 0.00597038\n",
      "Iteration 87, loss = 0.00387446\n",
      "Iteration 88, loss = 0.00448054\n",
      "Iteration 89, loss = 0.00404611\n",
      "Iteration 90, loss = 0.00224143\n",
      "Iteration 91, loss = 0.00229572\n",
      "Iteration 92, loss = 0.00207871\n",
      "Iteration 93, loss = 0.00271776\n",
      "Iteration 94, loss = 0.00211330\n",
      "Iteration 95, loss = 0.00157445\n",
      "Iteration 96, loss = 0.00289782\n",
      "Iteration 97, loss = 0.00196784\n",
      "Iteration 98, loss = 0.00217608\n",
      "Iteration 99, loss = 0.00234369\n",
      "Iteration 100, loss = 0.00465953\n",
      "Iteration 101, loss = 0.00223075\n",
      "Iteration 102, loss = 0.00189383\n",
      "Iteration 103, loss = 0.00217550\n",
      "Iteration 104, loss = 0.00167646\n",
      "Iteration 105, loss = 0.00117546\n",
      "Iteration 106, loss = 0.00145175\n",
      "Iteration 107, loss = 0.00100627\n",
      "Iteration 108, loss = 0.00077877\n",
      "Iteration 109, loss = 0.00064831\n",
      "Iteration 110, loss = 0.00088319\n",
      "Iteration 111, loss = 0.00070401\n",
      "Iteration 112, loss = 0.00060545\n",
      "Iteration 113, loss = 0.00065902\n",
      "Iteration 114, loss = 0.00062792\n",
      "Iteration 115, loss = 0.00064914\n",
      "Iteration 116, loss = 0.00056385\n",
      "Iteration 117, loss = 0.00087240\n",
      "Iteration 118, loss = 0.00064231\n",
      "Iteration 119, loss = 0.00073690\n",
      "Iteration 120, loss = 0.00070779\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-129\" type=\"checkbox\" ><label for=\"sk-estimator-id-129\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-130\" type=\"checkbox\" ><label for=\"sk-estimator-id-130\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-131\" type=\"checkbox\" ><label for=\"sk-estimator-id-131\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-132\" type=\"checkbox\" ><label for=\"sk-estimator-id-132\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-133\" type=\"checkbox\" ><label for=\"sk-estimator-id-133\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-134\" type=\"checkbox\" ><label for=\"sk-estimator-id-134\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-135\" type=\"checkbox\" ><label for=\"sk-estimator-id-135\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-136\" type=\"checkbox\" ><label for=\"sk-estimator-id-136\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d53396e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.33187254372557806\n",
      "MAE: 1.084872805633458\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ac216e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 19.14145788\n",
      "Iteration 2, loss = 18.47106996\n",
      "Iteration 3, loss = 17.86506526\n",
      "Iteration 4, loss = 17.30720320\n",
      "Iteration 5, loss = 16.78868345\n",
      "Iteration 6, loss = 16.30083904\n",
      "Iteration 7, loss = 15.84645179\n",
      "Iteration 8, loss = 15.40923473\n",
      "Iteration 9, loss = 14.98957183\n",
      "Iteration 10, loss = 14.57343584\n",
      "Iteration 11, loss = 14.16267425\n",
      "Iteration 12, loss = 13.75759751\n",
      "Iteration 13, loss = 13.36509191\n",
      "Iteration 14, loss = 12.98534799\n",
      "Iteration 15, loss = 12.61720085\n",
      "Iteration 16, loss = 12.26019149\n",
      "Iteration 17, loss = 11.91209351\n",
      "Iteration 18, loss = 11.57253176\n",
      "Iteration 19, loss = 11.24288092\n",
      "Iteration 20, loss = 10.92121434\n",
      "Iteration 21, loss = 10.60886505\n",
      "Iteration 22, loss = 10.30580782\n",
      "Iteration 23, loss = 10.01069544\n",
      "Iteration 24, loss = 9.72445970\n",
      "Iteration 25, loss = 9.44700375\n",
      "Iteration 26, loss = 9.17812459\n",
      "Iteration 27, loss = 8.91601454\n",
      "Iteration 28, loss = 8.66202281\n",
      "Iteration 29, loss = 8.41542521\n",
      "Iteration 30, loss = 8.17576936\n",
      "Iteration 31, loss = 7.94412660\n",
      "Iteration 32, loss = 7.71918301\n",
      "Iteration 33, loss = 7.50141467\n",
      "Iteration 34, loss = 7.28908740\n",
      "Iteration 35, loss = 7.08222541\n",
      "Iteration 36, loss = 6.88177788\n",
      "Iteration 37, loss = 6.68744754\n",
      "Iteration 38, loss = 6.49988987\n",
      "Iteration 39, loss = 6.31810301\n",
      "Iteration 40, loss = 6.14138303\n",
      "Iteration 41, loss = 5.96943718\n",
      "Iteration 42, loss = 5.80220738\n",
      "Iteration 43, loss = 5.64004479\n",
      "Iteration 44, loss = 5.48337710\n",
      "Iteration 45, loss = 5.33194516\n",
      "Iteration 46, loss = 5.18483581\n",
      "Iteration 47, loss = 5.04201594\n",
      "Iteration 48, loss = 4.90386360\n",
      "Iteration 49, loss = 4.76904873\n",
      "Iteration 50, loss = 4.63858857\n",
      "Iteration 51, loss = 4.51272654\n",
      "Iteration 52, loss = 4.38947323\n",
      "Iteration 53, loss = 4.27101464\n",
      "Iteration 54, loss = 4.15620325\n",
      "Iteration 55, loss = 4.04513379\n",
      "Iteration 56, loss = 3.93712990\n",
      "Iteration 57, loss = 3.83267944\n",
      "Iteration 58, loss = 3.73131520\n",
      "Iteration 59, loss = 3.63334181\n",
      "Iteration 60, loss = 3.53799074\n",
      "Iteration 61, loss = 3.44580671\n",
      "Iteration 62, loss = 3.35644048\n",
      "Iteration 63, loss = 3.27021416\n",
      "Iteration 64, loss = 3.18654662\n",
      "Iteration 65, loss = 3.10582170\n",
      "Iteration 66, loss = 3.02753353\n",
      "Iteration 67, loss = 2.95085951\n",
      "Iteration 68, loss = 2.87804602\n",
      "Iteration 69, loss = 2.80686222\n",
      "Iteration 70, loss = 2.73762141\n",
      "Iteration 71, loss = 2.67130091\n",
      "Iteration 72, loss = 2.60664616\n",
      "Iteration 73, loss = 2.54401410\n",
      "Iteration 74, loss = 2.48327086\n",
      "Iteration 75, loss = 2.42530536\n",
      "Iteration 76, loss = 2.36783986\n",
      "Iteration 77, loss = 2.31330874\n",
      "Iteration 78, loss = 2.25970061\n",
      "Iteration 79, loss = 2.20827630\n",
      "Iteration 80, loss = 2.15933400\n",
      "Iteration 81, loss = 2.11176979\n",
      "Iteration 82, loss = 2.06513265\n",
      "Iteration 83, loss = 2.01972437\n",
      "Iteration 84, loss = 1.97615755\n",
      "Iteration 85, loss = 1.93351177\n",
      "Iteration 86, loss = 1.89283626\n",
      "Iteration 87, loss = 1.85338027\n",
      "Iteration 88, loss = 1.81533668\n",
      "Iteration 89, loss = 1.77863571\n",
      "Iteration 90, loss = 1.74357489\n",
      "Iteration 91, loss = 1.70883548\n",
      "Iteration 92, loss = 1.67518005\n",
      "Iteration 93, loss = 1.64292467\n",
      "Iteration 94, loss = 1.61227140\n",
      "Iteration 95, loss = 1.58310346\n",
      "Iteration 96, loss = 1.55558087\n",
      "Iteration 97, loss = 1.52810692\n",
      "Iteration 98, loss = 1.50041145\n",
      "Iteration 99, loss = 1.47300397\n",
      "Iteration 100, loss = 1.44654028\n",
      "Iteration 101, loss = 1.42232143\n",
      "Iteration 102, loss = 1.39909561\n",
      "Iteration 103, loss = 1.37601747\n",
      "Iteration 104, loss = 1.35330689\n",
      "Iteration 105, loss = 1.33157463\n",
      "Iteration 106, loss = 1.31099078\n",
      "Iteration 107, loss = 1.29123843\n",
      "Iteration 108, loss = 1.27230972\n",
      "Iteration 109, loss = 1.25378760\n",
      "Iteration 110, loss = 1.23549481\n",
      "Iteration 111, loss = 1.21794367\n",
      "Iteration 112, loss = 1.20103784\n",
      "Iteration 113, loss = 1.18480135\n",
      "Iteration 114, loss = 1.16920232\n",
      "Iteration 115, loss = 1.15401363\n",
      "Iteration 116, loss = 1.13936804\n",
      "Iteration 117, loss = 1.12527281\n",
      "Iteration 118, loss = 1.11178461\n",
      "Iteration 119, loss = 1.09876501\n",
      "Iteration 120, loss = 1.08664981\n",
      "Iteration 121, loss = 1.07401673\n",
      "Iteration 122, loss = 1.06271831\n",
      "Iteration 123, loss = 1.05183218\n",
      "Iteration 124, loss = 1.04036516\n",
      "Iteration 125, loss = 1.02941151\n",
      "Iteration 126, loss = 1.01911596\n",
      "Iteration 127, loss = 1.00880993\n",
      "Iteration 128, loss = 0.99916877\n",
      "Iteration 129, loss = 0.99020657\n",
      "Iteration 130, loss = 0.98137362\n",
      "Iteration 131, loss = 0.97282262\n",
      "Iteration 132, loss = 0.96437457\n",
      "Iteration 133, loss = 0.95632663\n",
      "Iteration 134, loss = 0.94878020\n",
      "Iteration 135, loss = 0.94127258\n",
      "Iteration 136, loss = 0.93440644\n",
      "Iteration 137, loss = 0.92699734\n",
      "Iteration 138, loss = 0.92114308\n",
      "Iteration 139, loss = 0.91411343\n",
      "Iteration 140, loss = 0.90754653\n",
      "Iteration 141, loss = 0.90160566\n",
      "Iteration 142, loss = 0.89571318\n",
      "Iteration 143, loss = 0.89028408\n",
      "Iteration 144, loss = 0.88519592\n",
      "Iteration 145, loss = 0.88020534\n",
      "Iteration 146, loss = 0.87533885\n",
      "Iteration 147, loss = 0.87016799\n",
      "Iteration 148, loss = 0.86507907\n",
      "Iteration 149, loss = 0.86100740\n",
      "Iteration 150, loss = 0.85680103\n",
      "Iteration 151, loss = 0.85263563\n",
      "Iteration 152, loss = 0.84838189\n",
      "Iteration 153, loss = 0.84441007\n",
      "Iteration 154, loss = 0.84108048\n",
      "Iteration 155, loss = 0.83765188\n",
      "Iteration 156, loss = 0.83381035\n",
      "Iteration 157, loss = 0.83044022\n",
      "Iteration 158, loss = 0.82710279\n",
      "Iteration 159, loss = 0.82457552\n",
      "Iteration 160, loss = 0.82067079\n",
      "Iteration 161, loss = 0.81790867\n",
      "Iteration 162, loss = 0.81502564\n",
      "Iteration 163, loss = 0.81236632\n",
      "Iteration 164, loss = 0.80977327\n",
      "Iteration 165, loss = 0.80744815\n",
      "Iteration 166, loss = 0.80508151\n",
      "Iteration 167, loss = 0.80299615\n",
      "Iteration 168, loss = 0.80093757\n",
      "Iteration 169, loss = 0.79825798\n",
      "Iteration 170, loss = 0.79601260\n",
      "Iteration 171, loss = 0.79488632\n",
      "Iteration 172, loss = 0.79301453\n",
      "Iteration 173, loss = 0.79150097\n",
      "Iteration 174, loss = 0.78851964\n",
      "Iteration 175, loss = 0.78635613\n",
      "Iteration 176, loss = 0.78589560\n",
      "Iteration 177, loss = 0.78543067\n",
      "Iteration 178, loss = 0.78485111\n",
      "Iteration 179, loss = 0.78367734\n",
      "Iteration 180, loss = 0.78143626\n",
      "Iteration 181, loss = 0.77928803\n",
      "Iteration 182, loss = 0.77712906\n",
      "Iteration 183, loss = 0.77568610\n",
      "Iteration 184, loss = 0.77435805\n",
      "Iteration 185, loss = 0.77344910\n",
      "Iteration 186, loss = 0.77241092\n",
      "Iteration 187, loss = 0.77121228\n",
      "Iteration 188, loss = 0.76969839\n",
      "Iteration 189, loss = 0.76943376\n",
      "Iteration 190, loss = 0.76806287\n",
      "Iteration 191, loss = 0.76692715\n",
      "Iteration 192, loss = 0.76596027\n",
      "Iteration 193, loss = 0.76471401\n",
      "Iteration 194, loss = 0.76382436\n",
      "Iteration 195, loss = 0.76306580\n",
      "Iteration 196, loss = 0.76222161\n",
      "Iteration 197, loss = 0.76143355\n",
      "Iteration 198, loss = 0.76070110\n",
      "Iteration 199, loss = 0.75995575\n",
      "Iteration 200, loss = 0.75919960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-137\" type=\"checkbox\" ><label for=\"sk-estimator-id-137\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-138\" type=\"checkbox\" ><label for=\"sk-estimator-id-138\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-139\" type=\"checkbox\" ><label for=\"sk-estimator-id-139\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-140\" type=\"checkbox\" ><label for=\"sk-estimator-id-140\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-141\" type=\"checkbox\" ><label for=\"sk-estimator-id-141\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HDP&#x27;, &#x27;HIP&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;, &#x27;HGls&#x27;, &#x27;HAssts&#x27;, &#x27;HGlsPK&#x27;, &#x27;HxG&#x27;, &#x27;HNpxG&#x27;, &#x27;HxAG&#x27;, &#x27;HPoss&#x27;, &#x27;HPrg&#x27;, &#x27;HPrgP&#x27;, &#x27;HGKS%&#x27;, &#x27;HGKCS%&#x27;, &#x27;HSoT&#x27;, &#x27;Hg-xG&#x27;, &#x27;HCmp&#x27;, &#x27;HCmp%&#x27;, &#x27;HPrgDist&#x27;, &#x27;HXa&#x27;, &#x27;HKP&#x27;, &#x27;HPPA&#x27;, &#x27;HCrsPA&#x27;, &#x27;HTB&#x27;, &#x27;HCrs&#x27;, &#x27;HCK&#x27;, &#x27;HSCA&#x27;, &#x27;HGCA&#x27;, &#x27;HTkIW&#x27;, &#x27;HLost&#x27;, &#x27;HBlocks&#x27;, &#x27;HPass&#x27;, &#x27;HInt&#x27;, &#x27;HClr&#x27;, &#x27;HAttPen&#x27;, &#x27;HSucc%&#x27;, &#x27;HCPA&#x27;, &#x27;HDis&#x27;, &#x27;HPrgR&#x27;, &#x27;HOnG&#x27;, &#x27;HOnGA&#x27;, &#x27;HOnxG&#x27;, &#x27;HOnxGA&#x27;, &#x27;AStr&#x27;, &#x27;ASOH&#x27;, &#x27;ASOA&#x27;, &#x27;ASAH&#x27;, &#x27;ASAA&#x27;, &#x27;ASDH&#x27;, &#x27;ASDA&#x27;, &#x27;AO&#x27;, &#x27;AA&#x27;, &#x27;AM&#x27;, &#x27;AD&#x27;, &#x27;ADP&#x27;, &#x27;AIP&#x27;, &#x27;ASAAg&#x27;, &#x27;ATAAg&#x27;, &#x27;AGls&#x27;, &#x27;AAssts&#x27;, &#x27;AGlsPK&#x27;, &#x27;AxG&#x27;, &#x27;ANpxG&#x27;, &#x27;AxAG&#x27;, &#x27;APoss&#x27;, &#x27;APrg&#x27;, &#x27;APrgP&#x27;, &#x27;AGKS%&#x27;, &#x27;AGKCS%&#x27;, &#x27;ASoT&#x27;, &#x27;Ag-xG&#x27;, &#x27;ACmp&#x27;, &#x27;ACmp%&#x27;, &#x27;APrgDist&#x27;, &#x27;AXa&#x27;, &#x27;AKP&#x27;, &#x27;APPA&#x27;, &#x27;ACrsPA&#x27;, &#x27;ATB&#x27;, &#x27;ACrs&#x27;, &#x27;ACK&#x27;, &#x27;ASCA&#x27;, &#x27;AGCA&#x27;, &#x27;ATkIW&#x27;, &#x27;ALost&#x27;, &#x27;ABlocks&#x27;, &#x27;APass&#x27;, &#x27;AInt&#x27;, &#x27;AClr&#x27;, &#x27;AAttPen&#x27;, &#x27;ASucc%&#x27;, &#x27;ACPA&#x27;, &#x27;ADis&#x27;, &#x27;APrgR&#x27;, &#x27;AOnG&#x27;, &#x27;AOnGA&#x27;, &#x27;AOnxG&#x27;, &#x27;AOnxGA&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-142\" type=\"checkbox\" ><label for=\"sk-estimator-id-142\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-143\" type=\"checkbox\" ><label for=\"sk-estimator-id-143\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-144\" type=\"checkbox\" ><label for=\"sk-estimator-id-144\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba733c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.029089953355725173\n",
      "MAE: 0.935757448549554\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f220c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TeamH</th>\n",
       "      <th>TeamA</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>Referee</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "      <th>BWH</th>\n",
       "      <th>BWD</th>\n",
       "      <th>BWA</th>\n",
       "      <th>IWH</th>\n",
       "      <th>IWD</th>\n",
       "      <th>IWA</th>\n",
       "      <th>PSH</th>\n",
       "      <th>PSD</th>\n",
       "      <th>PSA</th>\n",
       "      <th>WHH</th>\n",
       "      <th>WHD</th>\n",
       "      <th>WHA</th>\n",
       "      <th>VCH</th>\n",
       "      <th>VCD</th>\n",
       "      <th>VCA</th>\n",
       "      <th>MaxH</th>\n",
       "      <th>MaxD</th>\n",
       "      <th>MaxA</th>\n",
       "      <th>AvgH</th>\n",
       "      <th>AvgD</th>\n",
       "      <th>AvgA</th>\n",
       "      <th>B365&gt;2.5</th>\n",
       "      <th>B365&lt;2.5</th>\n",
       "      <th>P&gt;2.5</th>\n",
       "      <th>P&lt;2.5</th>\n",
       "      <th>Max&gt;2.5</th>\n",
       "      <th>Max&lt;2.5</th>\n",
       "      <th>Avg&gt;2.5</th>\n",
       "      <th>Avg&lt;2.5</th>\n",
       "      <th>AHh</th>\n",
       "      <th>B365AHH</th>\n",
       "      <th>B365AHA</th>\n",
       "      <th>PAHH</th>\n",
       "      <th>PAHA</th>\n",
       "      <th>MaxAHH</th>\n",
       "      <th>MaxAHA</th>\n",
       "      <th>AvgAHH</th>\n",
       "      <th>AvgAHA</th>\n",
       "      <th>B365CH</th>\n",
       "      <th>B365CD</th>\n",
       "      <th>B365CA</th>\n",
       "      <th>BWCH</th>\n",
       "      <th>BWCD</th>\n",
       "      <th>BWCA</th>\n",
       "      <th>IWCH</th>\n",
       "      <th>IWCD</th>\n",
       "      <th>IWCA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "      <th>WHCH</th>\n",
       "      <th>WHCD</th>\n",
       "      <th>WHCA</th>\n",
       "      <th>VCCH</th>\n",
       "      <th>VCCD</th>\n",
       "      <th>VCCA</th>\n",
       "      <th>MaxCH</th>\n",
       "      <th>MaxCD</th>\n",
       "      <th>MaxCA</th>\n",
       "      <th>AvgCH</th>\n",
       "      <th>AvgCD</th>\n",
       "      <th>AvgCA</th>\n",
       "      <th>B365C&gt;2.5</th>\n",
       "      <th>B365C&lt;2.5</th>\n",
       "      <th>PC&gt;2.5</th>\n",
       "      <th>PC&lt;2.5</th>\n",
       "      <th>MaxC&gt;2.5</th>\n",
       "      <th>MaxC&lt;2.5</th>\n",
       "      <th>AvgC&gt;2.5</th>\n",
       "      <th>AvgC&lt;2.5</th>\n",
       "      <th>AHCh</th>\n",
       "      <th>B365CAHH</th>\n",
       "      <th>B365CAHA</th>\n",
       "      <th>PCAHH</th>\n",
       "      <th>PCAHA</th>\n",
       "      <th>MaxCAHH</th>\n",
       "      <th>MaxCAHA</th>\n",
       "      <th>AvgCAHH</th>\n",
       "      <th>AvgCAHA</th>\n",
       "      <th>HStr</th>\n",
       "      <th>HSOH</th>\n",
       "      <th>HSOA</th>\n",
       "      <th>HSAH</th>\n",
       "      <th>HSAA</th>\n",
       "      <th>HSDH</th>\n",
       "      <th>HSDA</th>\n",
       "      <th>HO</th>\n",
       "      <th>HA</th>\n",
       "      <th>HM</th>\n",
       "      <th>HD</th>\n",
       "      <th>HDP</th>\n",
       "      <th>HIP</th>\n",
       "      <th>HSAAg</th>\n",
       "      <th>HATAAg</th>\n",
       "      <th>HGls</th>\n",
       "      <th>HAssts</th>\n",
       "      <th>HGlsPK</th>\n",
       "      <th>HxG</th>\n",
       "      <th>HNpxG</th>\n",
       "      <th>HxAG</th>\n",
       "      <th>HPoss</th>\n",
       "      <th>HPrg</th>\n",
       "      <th>HPrgP</th>\n",
       "      <th>HGKS%</th>\n",
       "      <th>HGKCS%</th>\n",
       "      <th>HSoT</th>\n",
       "      <th>Hg-xG</th>\n",
       "      <th>HCmp</th>\n",
       "      <th>HCmp%</th>\n",
       "      <th>HPrgDist</th>\n",
       "      <th>HXa</th>\n",
       "      <th>HKP</th>\n",
       "      <th>HPPA</th>\n",
       "      <th>HCrsPA</th>\n",
       "      <th>HTB</th>\n",
       "      <th>HCrs</th>\n",
       "      <th>HCK</th>\n",
       "      <th>HSCA</th>\n",
       "      <th>HGCA</th>\n",
       "      <th>HTkIW</th>\n",
       "      <th>HLost</th>\n",
       "      <th>HBlocks</th>\n",
       "      <th>HPass</th>\n",
       "      <th>HInt</th>\n",
       "      <th>HClr</th>\n",
       "      <th>HAttPen</th>\n",
       "      <th>HSucc%</th>\n",
       "      <th>HCPA</th>\n",
       "      <th>HDis</th>\n",
       "      <th>HPrgR</th>\n",
       "      <th>HOnG</th>\n",
       "      <th>HOnGA</th>\n",
       "      <th>HOnxG</th>\n",
       "      <th>HOnxGA</th>\n",
       "      <th>AStr</th>\n",
       "      <th>ASOH</th>\n",
       "      <th>ASOA</th>\n",
       "      <th>ASAH</th>\n",
       "      <th>ASAA</th>\n",
       "      <th>ASDH</th>\n",
       "      <th>ASDA</th>\n",
       "      <th>AO</th>\n",
       "      <th>AA</th>\n",
       "      <th>AM</th>\n",
       "      <th>AD</th>\n",
       "      <th>ADP</th>\n",
       "      <th>AIP</th>\n",
       "      <th>ASAAg</th>\n",
       "      <th>ATAAg</th>\n",
       "      <th>AGls</th>\n",
       "      <th>AAssts</th>\n",
       "      <th>AGlsPK</th>\n",
       "      <th>AxG</th>\n",
       "      <th>ANpxG</th>\n",
       "      <th>AxAG</th>\n",
       "      <th>APoss</th>\n",
       "      <th>APrg</th>\n",
       "      <th>APrgP</th>\n",
       "      <th>AGKS%</th>\n",
       "      <th>AGKCS%</th>\n",
       "      <th>ASoT</th>\n",
       "      <th>Ag-xG</th>\n",
       "      <th>ACmp</th>\n",
       "      <th>ACmp%</th>\n",
       "      <th>APrgDist</th>\n",
       "      <th>AXa</th>\n",
       "      <th>AKP</th>\n",
       "      <th>APPA</th>\n",
       "      <th>ACrsPA</th>\n",
       "      <th>ATB</th>\n",
       "      <th>ACrs</th>\n",
       "      <th>ACK</th>\n",
       "      <th>ASCA</th>\n",
       "      <th>AGCA</th>\n",
       "      <th>ATkIW</th>\n",
       "      <th>ALost</th>\n",
       "      <th>ABlocks</th>\n",
       "      <th>APass</th>\n",
       "      <th>AInt</th>\n",
       "      <th>AClr</th>\n",
       "      <th>AAttPen</th>\n",
       "      <th>ASucc%</th>\n",
       "      <th>ACPA</th>\n",
       "      <th>ADis</th>\n",
       "      <th>APrgR</th>\n",
       "      <th>AOnG</th>\n",
       "      <th>AOnGA</th>\n",
       "      <th>AOnxG</th>\n",
       "      <th>AOnxGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/8/2022</td>\n",
       "      <td>20:00</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>A Taylor</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.33</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1.89</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.78</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.39</td>\n",
       "      <td>3.59</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.87</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.83</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.85</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.88</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>5.01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.57</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.84</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.85</td>\n",
       "      <td>3</td>\n",
       "      <td>1085</td>\n",
       "      <td>1100</td>\n",
       "      <td>1110</td>\n",
       "      <td>1110</td>\n",
       "      <td>1060</td>\n",
       "      <td>1090</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>75</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>26.6</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.75</td>\n",
       "      <td>45.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>71.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>3.51</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>348.8</td>\n",
       "      <td>77.2</td>\n",
       "      <td>2310.4</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.19</td>\n",
       "      <td>6.14</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.95</td>\n",
       "      <td>15.4</td>\n",
       "      <td>4.89</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.73</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.08</td>\n",
       "      <td>9.65</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>5.41</td>\n",
       "      <td>12.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.29</td>\n",
       "      <td>4</td>\n",
       "      <td>1245</td>\n",
       "      <td>1285</td>\n",
       "      <td>1250</td>\n",
       "      <td>1250</td>\n",
       "      <td>1240</td>\n",
       "      <td>1320</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.39</td>\n",
       "      <td>59.5</td>\n",
       "      <td>21.7</td>\n",
       "      <td>54.2</td>\n",
       "      <td>70.6</td>\n",
       "      <td>35.1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>0.27</td>\n",
       "      <td>482.8</td>\n",
       "      <td>83.1</td>\n",
       "      <td>2658.9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.01</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.24</td>\n",
       "      <td>17.8</td>\n",
       "      <td>5.81</td>\n",
       "      <td>27.6</td>\n",
       "      <td>3.81</td>\n",
       "      <td>8.89</td>\n",
       "      <td>6.51</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.22</td>\n",
       "      <td>6.35</td>\n",
       "      <td>15.8</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.1</td>\n",
       "      <td>53.5</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Time           TeamH    TeamA  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
       "0  5/8/2022  20:00  Crystal Palace  Arsenal     0     2   A     0     1   A   \n",
       "\n",
       "    Referee  B365H  B365D  B365A   BWH  BWD   BWA  IWH   IWD   IWA  PSH   PSD  \\\n",
       "0  A Taylor    4.2    3.6   1.85  4.33  3.5  1.87  4.3  3.55  1.85  4.5  3.65   \n",
       "\n",
       "    PSA  WHH  WHD   WHA  VCH  VCD   VCA  MaxH  MaxD  MaxA  AvgH  AvgD  AvgA  \\\n",
       "0  1.89  4.4  3.5  1.83  4.6  3.5  1.87   4.6  3.78  1.95  4.39  3.59  1.88   \n",
       "\n",
       "   B365>2.5  B365<2.5  P>2.5  P<2.5  Max>2.5  Max<2.5  Avg>2.5  Avg<2.5  AHh  \\\n",
       "0       2.1      1.72   2.14   1.78     2.19     1.91     2.09     1.76  0.5   \n",
       "\n",
       "   B365AHH  B365AHA  PAHH  PAHA  MaxAHH  MaxAHA  AvgAHH  AvgAHA  B365CH  \\\n",
       "0     2.04     1.89  2.03  1.89    2.06    1.91    2.01    1.87     4.5   \n",
       "\n",
       "   B365CD  B365CA  BWCH  BWCD  BWCA  IWCH  IWCD  IWCA  PSCH  PSCD  PSCA  WHCH  \\\n",
       "0     3.6     1.8   4.5   3.5  1.83   4.4  3.55  1.85  4.58  3.63  1.88   4.8   \n",
       "\n",
       "   WHCD  WHCA  VCCH  VCCD  VCCA  MaxCH  MaxCD  MaxCA  AvgCH  AvgCD  AvgCA  \\\n",
       "0   3.4  1.78  4.75   3.5  1.85   5.01    3.7   1.91   4.56   3.57   1.85   \n",
       "\n",
       "   B365C>2.5  B365C<2.5  PC>2.5  PC<2.5  MaxC>2.5  MaxC<2.5  AvgC>2.5  \\\n",
       "0        2.1       1.72    2.14    1.78      2.19      1.91      2.08   \n",
       "\n",
       "   AvgC<2.5  AHCh  B365CAHH  B365CAHA  PCAHH  PCAHA  MaxCAHH  MaxCAHA  \\\n",
       "0      1.76   0.5      2.09      1.84   2.04   1.88     2.09     1.88   \n",
       "\n",
       "   AvgCAHH  AvgCAHA  HStr  HSOH  HSOA  HSAH  HSAA  HSDH  HSDA  HO  HA  HM  HD  \\\n",
       "0     2.03     1.85     3  1085  1100  1110  1110  1060  1090  76  77  75  76   \n",
       "\n",
       "   HDP  HIP  HSAAg  HATAAg  HGls  HAssts  HGlsPK   HxG  HNpxG  HxAG  HPoss  \\\n",
       "0    4    2   26.6    25.2   1.0    0.76    0.97  1.02   0.96  0.75   45.8   \n",
       "\n",
       "   HPrg  HPrgP  HGKS%  HGKCS%  HSoT  Hg-xG   HCmp  HCmp%  HPrgDist   HXa  \\\n",
       "0  14.2   32.2   71.8    24.3  3.51  -0.02  348.8   77.2    2310.4  0.61   \n",
       "\n",
       "    HKP  HPPA  HCrsPA   HTB  HCrs   HCK  HSCA  HGCA  HTkIW  HLost  HBlocks  \\\n",
       "0  8.19  6.14    1.27  0.95  15.4  4.89  19.4  1.76   11.2   6.73     12.3   \n",
       "\n",
       "   HPass  HInt  HClr  HAttPen  HSucc%  HCPA  HDis  HPrgR  HOnG  HOnGA  HOnxG  \\\n",
       "0   9.08  9.65  21.5     19.9    46.9  5.41  12.1   32.1  1.05    1.3   1.02   \n",
       "\n",
       "   HOnxGA  AStr  ASOH  ASOA  ASAH  ASAA  ASDH  ASDA  AO  AA  AM  AD  ADP  AIP  \\\n",
       "0    1.29     4  1245  1285  1250  1250  1240  1320  80  83  81  79    7    7   \n",
       "\n",
       "   ASAAg  ATAAg  AGls  AAssts  AGlsPK   AxG  ANpxG  AxAG  APoss  APrg  APrgP  \\\n",
       "0   24.1   23.0  2.14    1.62    2.05  1.87   1.79  1.39   59.5  21.7   54.2   \n",
       "\n",
       "   AGKS%  AGKCS%  ASoT  Ag-xG   ACmp  ACmp%  APrgDist   AXa   AKP   APPA  \\\n",
       "0   70.6    35.1  5.03   0.27  482.8   83.1    2658.9  1.21  11.7  12.01   \n",
       "\n",
       "   ACrsPA   ATB  ACrs   ACK  ASCA  AGCA  ATkIW  ALost  ABlocks  APass  AInt  \\\n",
       "0    1.65  2.24  17.8  5.81  27.6  3.81   8.89   6.51     9.49   7.22  6.35   \n",
       "\n",
       "   AClr  AAttPen  ASucc%  ACPA  ADis  APrgR  AOnG  AOnGA  AOnxG  AOnxGA  \n",
       "0  15.8     34.0    46.3  7.38  10.1   53.5  2.24   1.16   1.87    1.12  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data3 = pd.read_csv('../data/final_data_corrected.csv')\n",
    "data3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07947e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basic = data3.drop(['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA',\n",
    "          'PSH', 'PSD', 'PSA', 'WHH','WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'MaxH', 'MaxD', 'MaxA','AvgH', 'AvgD', 'AvgA', 'B365>2.5',\n",
    "          'B365<2.5', 'P>2.5', 'P<2.5', 'Max>2.5', 'Max<2.5', 'Avg>2.5', 'Avg<2.5', 'AHh', 'B365AHH','B365AHA', 'PAHH', 'PAHA', \n",
    "          'MaxAHH', 'MaxAHA', \"AvgAHH\", 'AvgAHA', 'B365CH', 'B365CD', 'B365CA', 'BWCH', 'BWCD', 'BWCA', 'IWCH', 'IWCD', 'IWCA',\n",
    "          'PSCH', 'PSCD', 'PSCA', 'WHCH', 'WHCD', 'WHCA', 'VCCH', 'VCCD', 'VCCA', 'MaxCH', 'MaxCD', 'MaxCA', 'AvgCH', 'AvgCD',\n",
    "          'AvgCA', 'B365C>2.5', 'B365C<2.5', 'PC>2.5', 'PC<2.5', 'MaxC>2.5', 'MaxC<2.5', 'AvgC>2.5', 'AvgC<2.5', 'AHCh', 'B365CAHH',\n",
    "          'B365CAHA', 'PCAHH', 'PCAHA', 'MaxCAHH', 'MaxCAHA', 'AvgCAHH', 'AvgCAHA', 'HGls', 'HAssts', 'HGlsPK', 'HxG', 'HNpxG', 'HxAG',\n",
    "          'HPoss', 'HPrg', 'HPrgP', 'HGKS%', 'HGKCS%', 'HSoT', 'Hg-xG', 'HCmp', 'HCmp%', 'HPrgDist', 'HXa', 'HKP', 'HPPA', 'HCrsPA',\n",
    "          'HTB', 'HCrs', 'HCK', 'HSCA', 'HGCA', 'HTkIW', 'HLost', 'HBlocks', 'HPass', 'HInt', 'HClr', 'HAttPen', 'HSucc%', 'HCPA',\n",
    "          'HDis', 'HPrgR', 'HOnG', 'HOnGA', 'HOnxG', 'HOnxGA', 'AStr', 'ASOH', 'ASOA', 'ASAH', 'ASAA', 'ASDH', 'ASDA', 'AO', 'AA',\n",
    "          'AM', 'AD', 'ADP', 'AIP', 'ASAAg', 'ATAAg', 'AGls', 'AAssts', 'AGlsPK', 'AxG', 'ANpxG', 'AxAG', 'APoss', 'APrg', 'APrgP',\n",
    "          'AGKS%', 'AGKCS%', 'ASoT', 'Ag-xG', 'ACmp', 'ACmp%', 'APrgDist', 'AXa', 'AKP', 'APPA', 'ACrsPA', 'ATB', 'ACrs', 'ACK',\n",
    "          'ASCA', 'AGCA', 'ATkIW', 'ALost', 'ABlocks', 'APass', 'AInt', 'AClr','AAttPen', 'ASucc%', 'ACPA', 'ADis', 'APrgR', 'AOnG',\n",
    "          'AOnGA', 'AOnxG', 'AOnxGA'], axis=1)\n",
    "data_basic.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39f6dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data3[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'HStr', 'HSOH', 'HSOA', 'HSAH', 'HSAA', 'HSDH',\n",
    "          'HSDA', 'HO', 'HA', 'HM', 'HD', 'HSAAg', 'HATAAg']].copy()\n",
    "y = data3['FTHG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d7ce1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "349c1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "887540c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.10481765\n",
      "Iteration 2, loss = 2.82715397\n",
      "Iteration 3, loss = 2.58475998\n",
      "Iteration 4, loss = 2.35654138\n",
      "Iteration 5, loss = 2.14293075\n",
      "Iteration 6, loss = 1.95222389\n",
      "Iteration 7, loss = 1.77784655\n",
      "Iteration 8, loss = 1.61962782\n",
      "Iteration 9, loss = 1.47625944\n",
      "Iteration 10, loss = 1.35022535\n",
      "Iteration 11, loss = 1.24344469\n",
      "Iteration 12, loss = 1.14939790\n",
      "Iteration 13, loss = 1.07560238\n",
      "Iteration 14, loss = 1.01019968\n",
      "Iteration 15, loss = 0.95998682\n",
      "Iteration 16, loss = 0.92634313\n",
      "Iteration 17, loss = 0.90141594\n",
      "Iteration 18, loss = 0.88627731\n",
      "Iteration 19, loss = 0.87890934\n",
      "Iteration 20, loss = 0.87277142\n",
      "Iteration 21, loss = 0.87060085\n",
      "Iteration 22, loss = 0.86631461\n",
      "Iteration 23, loss = 0.85993089\n",
      "Iteration 24, loss = 0.85279853\n",
      "Iteration 25, loss = 0.84357835\n",
      "Iteration 26, loss = 0.83404001\n",
      "Iteration 27, loss = 0.82390657\n",
      "Iteration 28, loss = 0.81318760\n",
      "Iteration 29, loss = 0.80316247\n",
      "Iteration 30, loss = 0.79384269\n",
      "Iteration 31, loss = 0.78469839\n",
      "Iteration 32, loss = 0.77661648\n",
      "Iteration 33, loss = 0.76885011\n",
      "Iteration 34, loss = 0.76189569\n",
      "Iteration 35, loss = 0.75539898\n",
      "Iteration 36, loss = 0.74966185\n",
      "Iteration 37, loss = 0.74419947\n",
      "Iteration 38, loss = 0.73846258\n",
      "Iteration 39, loss = 0.73276685\n",
      "Iteration 40, loss = 0.72659803\n",
      "Iteration 41, loss = 0.72097402\n",
      "Iteration 42, loss = 0.71512897\n",
      "Iteration 43, loss = 0.70931552\n",
      "Iteration 44, loss = 0.70448343\n",
      "Iteration 45, loss = 0.69864616\n",
      "Iteration 46, loss = 0.69369415\n",
      "Iteration 47, loss = 0.68849183\n",
      "Iteration 48, loss = 0.68357127\n",
      "Iteration 49, loss = 0.67880080\n",
      "Iteration 50, loss = 0.67425422\n",
      "Iteration 51, loss = 0.66959666\n",
      "Iteration 52, loss = 0.66483271\n",
      "Iteration 53, loss = 0.66027566\n",
      "Iteration 54, loss = 0.65603905\n",
      "Iteration 55, loss = 0.65151790\n",
      "Iteration 56, loss = 0.64696502\n",
      "Iteration 57, loss = 0.64266245\n",
      "Iteration 58, loss = 0.63862731\n",
      "Iteration 59, loss = 0.63463356\n",
      "Iteration 60, loss = 0.63031290\n",
      "Iteration 61, loss = 0.62661152\n",
      "Iteration 62, loss = 0.62249865\n",
      "Iteration 63, loss = 0.61890708\n",
      "Iteration 64, loss = 0.61475424\n",
      "Iteration 65, loss = 0.61094330\n",
      "Iteration 66, loss = 0.60767813\n",
      "Iteration 67, loss = 0.60372876\n",
      "Iteration 68, loss = 0.60026514\n",
      "Iteration 69, loss = 0.59678226\n",
      "Iteration 70, loss = 0.59320231\n",
      "Iteration 71, loss = 0.58972201\n",
      "Iteration 72, loss = 0.58671003\n",
      "Iteration 73, loss = 0.58294043\n",
      "Iteration 74, loss = 0.57974965\n",
      "Iteration 75, loss = 0.57615775\n",
      "Iteration 76, loss = 0.57297350\n",
      "Iteration 77, loss = 0.56962582\n",
      "Iteration 78, loss = 0.56654179\n",
      "Iteration 79, loss = 0.56338492\n",
      "Iteration 80, loss = 0.56007938\n",
      "Iteration 81, loss = 0.55682608\n",
      "Iteration 82, loss = 0.55387334\n",
      "Iteration 83, loss = 0.55083205\n",
      "Iteration 84, loss = 0.54784559\n",
      "Iteration 85, loss = 0.54452812\n",
      "Iteration 86, loss = 0.54133300\n",
      "Iteration 87, loss = 0.53860147\n",
      "Iteration 88, loss = 0.53538298\n",
      "Iteration 89, loss = 0.53201609\n",
      "Iteration 90, loss = 0.52893826\n",
      "Iteration 91, loss = 0.52576864\n",
      "Iteration 92, loss = 0.52266893\n",
      "Iteration 93, loss = 0.51915938\n",
      "Iteration 94, loss = 0.51621514\n",
      "Iteration 95, loss = 0.51306958\n",
      "Iteration 96, loss = 0.50978961\n",
      "Iteration 97, loss = 0.50673802\n",
      "Iteration 98, loss = 0.50340583\n",
      "Iteration 99, loss = 0.50034703\n",
      "Iteration 100, loss = 0.49699413\n",
      "Iteration 101, loss = 0.49387308\n",
      "Iteration 102, loss = 0.49083012\n",
      "Iteration 103, loss = 0.48768329\n",
      "Iteration 104, loss = 0.48459292\n",
      "Iteration 105, loss = 0.48123138\n",
      "Iteration 106, loss = 0.47785764\n",
      "Iteration 107, loss = 0.47468319\n",
      "Iteration 108, loss = 0.47154874\n",
      "Iteration 109, loss = 0.46815156\n",
      "Iteration 110, loss = 0.46467760\n",
      "Iteration 111, loss = 0.46152762\n",
      "Iteration 112, loss = 0.45820749\n",
      "Iteration 113, loss = 0.45526876\n",
      "Iteration 114, loss = 0.45183077\n",
      "Iteration 115, loss = 0.44868802\n",
      "Iteration 116, loss = 0.44582207\n",
      "Iteration 117, loss = 0.44275207\n",
      "Iteration 118, loss = 0.43882020\n",
      "Iteration 119, loss = 0.43567633\n",
      "Iteration 120, loss = 0.43212660\n",
      "Iteration 121, loss = 0.42879564\n",
      "Iteration 122, loss = 0.42510282\n",
      "Iteration 123, loss = 0.42155219\n",
      "Iteration 124, loss = 0.41834241\n",
      "Iteration 125, loss = 0.41541671\n",
      "Iteration 126, loss = 0.41176254\n",
      "Iteration 127, loss = 0.40839926\n",
      "Iteration 128, loss = 0.40510528\n",
      "Iteration 129, loss = 0.40187051\n",
      "Iteration 130, loss = 0.39833693\n",
      "Iteration 131, loss = 0.39497927\n",
      "Iteration 132, loss = 0.39164124\n",
      "Iteration 133, loss = 0.38841890\n",
      "Iteration 134, loss = 0.38503398\n",
      "Iteration 135, loss = 0.38154183\n",
      "Iteration 136, loss = 0.37809577\n",
      "Iteration 137, loss = 0.37437589\n",
      "Iteration 138, loss = 0.37122295\n",
      "Iteration 139, loss = 0.36766615\n",
      "Iteration 140, loss = 0.36414559\n",
      "Iteration 141, loss = 0.36093807\n",
      "Iteration 142, loss = 0.35744150\n",
      "Iteration 143, loss = 0.35457587\n",
      "Iteration 144, loss = 0.35113442\n",
      "Iteration 145, loss = 0.34799400\n",
      "Iteration 146, loss = 0.34378378\n",
      "Iteration 147, loss = 0.34082561\n",
      "Iteration 148, loss = 0.33764553\n",
      "Iteration 149, loss = 0.33444806\n",
      "Iteration 150, loss = 0.33130641\n",
      "Iteration 151, loss = 0.32780613\n",
      "Iteration 152, loss = 0.32438046\n",
      "Iteration 153, loss = 0.32088343\n",
      "Iteration 154, loss = 0.31743348\n",
      "Iteration 155, loss = 0.31455188\n",
      "Iteration 156, loss = 0.31078466\n",
      "Iteration 157, loss = 0.30740084\n",
      "Iteration 158, loss = 0.30418298\n",
      "Iteration 159, loss = 0.30089048\n",
      "Iteration 160, loss = 0.29740878\n",
      "Iteration 161, loss = 0.29411876\n",
      "Iteration 162, loss = 0.29070023\n",
      "Iteration 163, loss = 0.28751437\n",
      "Iteration 164, loss = 0.28405417\n",
      "Iteration 165, loss = 0.28082757\n",
      "Iteration 166, loss = 0.27758746\n",
      "Iteration 167, loss = 0.27435041\n",
      "Iteration 168, loss = 0.27117587\n",
      "Iteration 169, loss = 0.26813242\n",
      "Iteration 170, loss = 0.26488727\n",
      "Iteration 171, loss = 0.26172207\n",
      "Iteration 172, loss = 0.25837834\n",
      "Iteration 173, loss = 0.25560850\n",
      "Iteration 174, loss = 0.25236781\n",
      "Iteration 175, loss = 0.24901105\n",
      "Iteration 176, loss = 0.24618262\n",
      "Iteration 177, loss = 0.24316535\n",
      "Iteration 178, loss = 0.23988600\n",
      "Iteration 179, loss = 0.23671751\n",
      "Iteration 180, loss = 0.23360239\n",
      "Iteration 181, loss = 0.23061380\n",
      "Iteration 182, loss = 0.22743693\n",
      "Iteration 183, loss = 0.22435206\n",
      "Iteration 184, loss = 0.22151284\n",
      "Iteration 185, loss = 0.21829123\n",
      "Iteration 186, loss = 0.21512545\n",
      "Iteration 187, loss = 0.21210649\n",
      "Iteration 188, loss = 0.20949517\n",
      "Iteration 189, loss = 0.20640817\n",
      "Iteration 190, loss = 0.20341387\n",
      "Iteration 191, loss = 0.20049690\n",
      "Iteration 192, loss = 0.19748924\n",
      "Iteration 193, loss = 0.19421328\n",
      "Iteration 194, loss = 0.19148213\n",
      "Iteration 195, loss = 0.18869686\n",
      "Iteration 196, loss = 0.18575576\n",
      "Iteration 197, loss = 0.18284912\n",
      "Iteration 198, loss = 0.18030343\n",
      "Iteration 199, loss = 0.17730310\n",
      "Iteration 200, loss = 0.17460722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-145\" type=\"checkbox\" ><label for=\"sk-estimator-id-145\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-146\" type=\"checkbox\" ><label for=\"sk-estimator-id-146\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-147\" type=\"checkbox\" ><label for=\"sk-estimator-id-147\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-148\" type=\"checkbox\" ><label for=\"sk-estimator-id-148\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-149\" type=\"checkbox\" ><label for=\"sk-estimator-id-149\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-150\" type=\"checkbox\" ><label for=\"sk-estimator-id-150\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-151\" type=\"checkbox\" ><label for=\"sk-estimator-id-151\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-152\" type=\"checkbox\" ><label for=\"sk-estimator-id-152\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d22ef03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.11138053118139601\n",
      "MAE: 1.1665392817190168\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "815c0067",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.17574149\n",
      "Iteration 2, loss = 1.77089816\n",
      "Iteration 3, loss = 1.41055715\n",
      "Iteration 4, loss = 1.11662019\n",
      "Iteration 5, loss = 0.94429331\n",
      "Iteration 6, loss = 0.92405857\n",
      "Iteration 7, loss = 0.97607745\n",
      "Iteration 8, loss = 0.97323760\n",
      "Iteration 9, loss = 0.90905867\n",
      "Iteration 10, loss = 0.84771494\n",
      "Iteration 11, loss = 0.82264042\n",
      "Iteration 12, loss = 0.82134117\n",
      "Iteration 13, loss = 0.81997563\n",
      "Iteration 14, loss = 0.81061730\n",
      "Iteration 15, loss = 0.79080623\n",
      "Iteration 16, loss = 0.76334066\n",
      "Iteration 17, loss = 0.74127138\n",
      "Iteration 18, loss = 0.72678734\n",
      "Iteration 19, loss = 0.72237644\n",
      "Iteration 20, loss = 0.71332971\n",
      "Iteration 21, loss = 0.69435823\n",
      "Iteration 22, loss = 0.67241306\n",
      "Iteration 23, loss = 0.65494180\n",
      "Iteration 24, loss = 0.64141341\n",
      "Iteration 25, loss = 0.63031458\n",
      "Iteration 26, loss = 0.61319574\n",
      "Iteration 27, loss = 0.59148235\n",
      "Iteration 28, loss = 0.57186653\n",
      "Iteration 29, loss = 0.55606558\n",
      "Iteration 30, loss = 0.53743623\n",
      "Iteration 31, loss = 0.52151991\n",
      "Iteration 32, loss = 0.50172712\n",
      "Iteration 33, loss = 0.48359421\n",
      "Iteration 34, loss = 0.46559005\n",
      "Iteration 35, loss = 0.44644931\n",
      "Iteration 36, loss = 0.42824325\n",
      "Iteration 37, loss = 0.41111985\n",
      "Iteration 38, loss = 0.39389866\n",
      "Iteration 39, loss = 0.37954321\n",
      "Iteration 40, loss = 0.35745149\n",
      "Iteration 41, loss = 0.34373895\n",
      "Iteration 42, loss = 0.32754271\n",
      "Iteration 43, loss = 0.30660859\n",
      "Iteration 44, loss = 0.28835427\n",
      "Iteration 45, loss = 0.27127350\n",
      "Iteration 46, loss = 0.25259905\n",
      "Iteration 47, loss = 0.23781738\n",
      "Iteration 48, loss = 0.21767027\n",
      "Iteration 49, loss = 0.20432925\n",
      "Iteration 50, loss = 0.19117152\n",
      "Iteration 51, loss = 0.17168998\n",
      "Iteration 52, loss = 0.15894906\n",
      "Iteration 53, loss = 0.14394849\n",
      "Iteration 54, loss = 0.13075031\n",
      "Iteration 55, loss = 0.11733304\n",
      "Iteration 56, loss = 0.10435820\n",
      "Iteration 57, loss = 0.09315616\n",
      "Iteration 58, loss = 0.08214448\n",
      "Iteration 59, loss = 0.07272058\n",
      "Iteration 60, loss = 0.06396081\n",
      "Iteration 61, loss = 0.05661850\n",
      "Iteration 62, loss = 0.04897175\n",
      "Iteration 63, loss = 0.04310743\n",
      "Iteration 64, loss = 0.03772262\n",
      "Iteration 65, loss = 0.03269735\n",
      "Iteration 66, loss = 0.02870696\n",
      "Iteration 67, loss = 0.02491804\n",
      "Iteration 68, loss = 0.02195698\n",
      "Iteration 69, loss = 0.01968876\n",
      "Iteration 70, loss = 0.01672577\n",
      "Iteration 71, loss = 0.01567420\n",
      "Iteration 72, loss = 0.01324435\n",
      "Iteration 73, loss = 0.01116018\n",
      "Iteration 74, loss = 0.01117901\n",
      "Iteration 75, loss = 0.00893085\n",
      "Iteration 76, loss = 0.00787019\n",
      "Iteration 77, loss = 0.00686758\n",
      "Iteration 78, loss = 0.00609010\n",
      "Iteration 79, loss = 0.00534902\n",
      "Iteration 80, loss = 0.00495032\n",
      "Iteration 81, loss = 0.00422837\n",
      "Iteration 82, loss = 0.00370878\n",
      "Iteration 83, loss = 0.00333591\n",
      "Iteration 84, loss = 0.00301136\n",
      "Iteration 85, loss = 0.00256109\n",
      "Iteration 86, loss = 0.00233557\n",
      "Iteration 87, loss = 0.00207621\n",
      "Iteration 88, loss = 0.00181494\n",
      "Iteration 89, loss = 0.00162403\n",
      "Iteration 90, loss = 0.00142188\n",
      "Iteration 91, loss = 0.00127445\n",
      "Iteration 92, loss = 0.00112851\n",
      "Iteration 93, loss = 0.00101805\n",
      "Iteration 94, loss = 0.00091381\n",
      "Iteration 95, loss = 0.00082419\n",
      "Iteration 96, loss = 0.00074413\n",
      "Iteration 97, loss = 0.00067985\n",
      "Iteration 98, loss = 0.00061339\n",
      "Iteration 99, loss = 0.00055026\n",
      "Iteration 100, loss = 0.00051330\n",
      "Iteration 101, loss = 0.00047588\n",
      "Iteration 102, loss = 0.00042832\n",
      "Iteration 103, loss = 0.00038724\n",
      "Iteration 104, loss = 0.00036223\n",
      "Iteration 105, loss = 0.00033944\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-153\" type=\"checkbox\" ><label for=\"sk-estimator-id-153\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-154\" type=\"checkbox\" ><label for=\"sk-estimator-id-154\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-155\" type=\"checkbox\" ><label for=\"sk-estimator-id-155\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-156\" type=\"checkbox\" ><label for=\"sk-estimator-id-156\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-157\" type=\"checkbox\" ><label for=\"sk-estimator-id-157\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-158\" type=\"checkbox\" ><label for=\"sk-estimator-id-158\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-159\" type=\"checkbox\" ><label for=\"sk-estimator-id-159\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-160\" type=\"checkbox\" ><label for=\"sk-estimator-id-160\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e81da6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.4727349819670956\n",
      "MAE: 1.3395191728460158\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d42b0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 18.13307176\n",
      "Iteration 2, loss = 17.52603750\n",
      "Iteration 3, loss = 16.95130594\n",
      "Iteration 4, loss = 16.43782117\n",
      "Iteration 5, loss = 15.95748829\n",
      "Iteration 6, loss = 15.51094567\n",
      "Iteration 7, loss = 15.10646493\n",
      "Iteration 8, loss = 14.73615202\n",
      "Iteration 9, loss = 14.39831015\n",
      "Iteration 10, loss = 14.06945499\n",
      "Iteration 11, loss = 13.74786975\n",
      "Iteration 12, loss = 13.42572374\n",
      "Iteration 13, loss = 13.10541361\n",
      "Iteration 14, loss = 12.79006757\n",
      "Iteration 15, loss = 12.47912843\n",
      "Iteration 16, loss = 12.18010169\n",
      "Iteration 17, loss = 11.88815356\n",
      "Iteration 18, loss = 11.60585390\n",
      "Iteration 19, loss = 11.32870283\n",
      "Iteration 20, loss = 11.05976308\n",
      "Iteration 21, loss = 10.79596285\n",
      "Iteration 22, loss = 10.53810841\n",
      "Iteration 23, loss = 10.28561942\n",
      "Iteration 24, loss = 10.03938826\n",
      "Iteration 25, loss = 9.79864270\n",
      "Iteration 26, loss = 9.56399627\n",
      "Iteration 27, loss = 9.33582004\n",
      "Iteration 28, loss = 9.11313122\n",
      "Iteration 29, loss = 8.89542033\n",
      "Iteration 30, loss = 8.68327095\n",
      "Iteration 31, loss = 8.47614236\n",
      "Iteration 32, loss = 8.27433139\n",
      "Iteration 33, loss = 8.07745520\n",
      "Iteration 34, loss = 7.88533891\n",
      "Iteration 35, loss = 7.69834773\n",
      "Iteration 36, loss = 7.51681936\n",
      "Iteration 37, loss = 7.33942083\n",
      "Iteration 38, loss = 7.16635730\n",
      "Iteration 39, loss = 6.99781348\n",
      "Iteration 40, loss = 6.83290014\n",
      "Iteration 41, loss = 6.67169587\n",
      "Iteration 42, loss = 6.51541206\n",
      "Iteration 43, loss = 6.36196315\n",
      "Iteration 44, loss = 6.21434557\n",
      "Iteration 45, loss = 6.06844054\n",
      "Iteration 46, loss = 5.92872175\n",
      "Iteration 47, loss = 5.79126237\n",
      "Iteration 48, loss = 5.65704336\n",
      "Iteration 49, loss = 5.52657063\n",
      "Iteration 50, loss = 5.39970150\n",
      "Iteration 51, loss = 5.27553039\n",
      "Iteration 52, loss = 5.15495187\n",
      "Iteration 53, loss = 5.03779342\n",
      "Iteration 54, loss = 4.92312770\n",
      "Iteration 55, loss = 4.81185232\n",
      "Iteration 56, loss = 4.70329983\n",
      "Iteration 57, loss = 4.59781193\n",
      "Iteration 58, loss = 4.49600303\n",
      "Iteration 59, loss = 4.39610825\n",
      "Iteration 60, loss = 4.29881759\n",
      "Iteration 61, loss = 4.20431612\n",
      "Iteration 62, loss = 4.11168545\n",
      "Iteration 63, loss = 4.02163444\n",
      "Iteration 64, loss = 3.93374885\n",
      "Iteration 65, loss = 3.84906622\n",
      "Iteration 66, loss = 3.76617938\n",
      "Iteration 67, loss = 3.68579435\n",
      "Iteration 68, loss = 3.60755217\n",
      "Iteration 69, loss = 3.53122823\n",
      "Iteration 70, loss = 3.45741134\n",
      "Iteration 71, loss = 3.38498968\n",
      "Iteration 72, loss = 3.31499058\n",
      "Iteration 73, loss = 3.24685300\n",
      "Iteration 74, loss = 3.18070097\n",
      "Iteration 75, loss = 3.11633259\n",
      "Iteration 76, loss = 3.05401052\n",
      "Iteration 77, loss = 2.99398302\n",
      "Iteration 78, loss = 2.93468999\n",
      "Iteration 79, loss = 2.87742075\n",
      "Iteration 80, loss = 2.82153820\n",
      "Iteration 81, loss = 2.76683030\n",
      "Iteration 82, loss = 2.71434075\n",
      "Iteration 83, loss = 2.66317471\n",
      "Iteration 84, loss = 2.61357882\n",
      "Iteration 85, loss = 2.56519591\n",
      "Iteration 86, loss = 2.51829804\n",
      "Iteration 87, loss = 2.47257991\n",
      "Iteration 88, loss = 2.42889121\n",
      "Iteration 89, loss = 2.38551036\n",
      "Iteration 90, loss = 2.34382594\n",
      "Iteration 91, loss = 2.30337718\n",
      "Iteration 92, loss = 2.26449237\n",
      "Iteration 93, loss = 2.22614279\n",
      "Iteration 94, loss = 2.18909082\n",
      "Iteration 95, loss = 2.15319025\n",
      "Iteration 96, loss = 2.11846372\n",
      "Iteration 97, loss = 2.08485748\n",
      "Iteration 98, loss = 2.05270382\n",
      "Iteration 99, loss = 2.02154642\n",
      "Iteration 100, loss = 1.99163249\n",
      "Iteration 101, loss = 1.96224469\n",
      "Iteration 102, loss = 1.93294314\n",
      "Iteration 103, loss = 1.90472281\n",
      "Iteration 104, loss = 1.87711745\n",
      "Iteration 105, loss = 1.85047488\n",
      "Iteration 106, loss = 1.82466139\n",
      "Iteration 107, loss = 1.79911388\n",
      "Iteration 108, loss = 1.77562625\n",
      "Iteration 109, loss = 1.75155186\n",
      "Iteration 110, loss = 1.72898474\n",
      "Iteration 111, loss = 1.70707676\n",
      "Iteration 112, loss = 1.68573119\n",
      "Iteration 113, loss = 1.66570279\n",
      "Iteration 114, loss = 1.64531944\n",
      "Iteration 115, loss = 1.62618230\n",
      "Iteration 116, loss = 1.60743622\n",
      "Iteration 117, loss = 1.58924361\n",
      "Iteration 118, loss = 1.57170628\n",
      "Iteration 119, loss = 1.55465814\n",
      "Iteration 120, loss = 1.53810287\n",
      "Iteration 121, loss = 1.52227736\n",
      "Iteration 122, loss = 1.50676682\n",
      "Iteration 123, loss = 1.49195267\n",
      "Iteration 124, loss = 1.47757301\n",
      "Iteration 125, loss = 1.46370356\n",
      "Iteration 126, loss = 1.45033794\n",
      "Iteration 127, loss = 1.43731488\n",
      "Iteration 128, loss = 1.42453358\n",
      "Iteration 129, loss = 1.41228978\n",
      "Iteration 130, loss = 1.40082605\n",
      "Iteration 131, loss = 1.38950675\n",
      "Iteration 132, loss = 1.37785541\n",
      "Iteration 133, loss = 1.36702877\n",
      "Iteration 134, loss = 1.35663853\n",
      "Iteration 135, loss = 1.34729811\n",
      "Iteration 136, loss = 1.33697130\n",
      "Iteration 137, loss = 1.32743440\n",
      "Iteration 138, loss = 1.31829355\n",
      "Iteration 139, loss = 1.30955499\n",
      "Iteration 140, loss = 1.30163044\n",
      "Iteration 141, loss = 1.29384210\n",
      "Iteration 142, loss = 1.28684018\n",
      "Iteration 143, loss = 1.27874266\n",
      "Iteration 144, loss = 1.27149779\n",
      "Iteration 145, loss = 1.26321477\n",
      "Iteration 146, loss = 1.25584384\n",
      "Iteration 147, loss = 1.24908309\n",
      "Iteration 148, loss = 1.24296645\n",
      "Iteration 149, loss = 1.23694347\n",
      "Iteration 150, loss = 1.23110118\n",
      "Iteration 151, loss = 1.22525967\n",
      "Iteration 152, loss = 1.21924693\n",
      "Iteration 153, loss = 1.21368477\n",
      "Iteration 154, loss = 1.20858479\n",
      "Iteration 155, loss = 1.20483077\n",
      "Iteration 156, loss = 1.19915366\n",
      "Iteration 157, loss = 1.19430544\n",
      "Iteration 158, loss = 1.18928053\n",
      "Iteration 159, loss = 1.18478100\n",
      "Iteration 160, loss = 1.18040391\n",
      "Iteration 161, loss = 1.17632907\n",
      "Iteration 162, loss = 1.17231819\n",
      "Iteration 163, loss = 1.16853466\n",
      "Iteration 164, loss = 1.16484377\n",
      "Iteration 165, loss = 1.16137218\n",
      "Iteration 166, loss = 1.15821466\n",
      "Iteration 167, loss = 1.15445281\n",
      "Iteration 168, loss = 1.15130259\n",
      "Iteration 169, loss = 1.14817341\n",
      "Iteration 170, loss = 1.14516586\n",
      "Iteration 171, loss = 1.14215951\n",
      "Iteration 172, loss = 1.13949221\n",
      "Iteration 173, loss = 1.13704363\n",
      "Iteration 174, loss = 1.13439508\n",
      "Iteration 175, loss = 1.13205971\n",
      "Iteration 176, loss = 1.12949593\n",
      "Iteration 177, loss = 1.12720887\n",
      "Iteration 178, loss = 1.12469482\n",
      "Iteration 179, loss = 1.12266199\n",
      "Iteration 180, loss = 1.12031166\n",
      "Iteration 181, loss = 1.11872676\n",
      "Iteration 182, loss = 1.11669998\n",
      "Iteration 183, loss = 1.11480193\n",
      "Iteration 184, loss = 1.11273885\n",
      "Iteration 185, loss = 1.11097465\n",
      "Iteration 186, loss = 1.10928165\n",
      "Iteration 187, loss = 1.10783256\n",
      "Iteration 188, loss = 1.10601568\n",
      "Iteration 189, loss = 1.10453144\n",
      "Iteration 190, loss = 1.10310365\n",
      "Iteration 191, loss = 1.10178166\n",
      "Iteration 192, loss = 1.10079483\n",
      "Iteration 193, loss = 1.09925364\n",
      "Iteration 194, loss = 1.09842921\n",
      "Iteration 195, loss = 1.09653071\n",
      "Iteration 196, loss = 1.09529951\n",
      "Iteration 197, loss = 1.09410046\n",
      "Iteration 198, loss = 1.09381658\n",
      "Iteration 199, loss = 1.09234925\n",
      "Iteration 200, loss = 1.09128979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-161\" type=\"checkbox\" ><label for=\"sk-estimator-id-161\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-162\" type=\"checkbox\" ><label for=\"sk-estimator-id-162\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-163\" type=\"checkbox\" ><label for=\"sk-estimator-id-163\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-164\" type=\"checkbox\" ><label for=\"sk-estimator-id-164\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-165\" type=\"checkbox\" ><label for=\"sk-estimator-id-165\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-166\" type=\"checkbox\" ><label for=\"sk-estimator-id-166\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-167\" type=\"checkbox\" ><label for=\"sk-estimator-id-167\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-168\" type=\"checkbox\" ><label for=\"sk-estimator-id-168\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "455f66da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.06984203797915756\n",
      "MAE: 1.141088275832193\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "836336fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data3[['Date', 'Time', 'TeamH', 'TeamA', 'FTR', 'HTR', 'Referee', 'HStr', 'HSOH', 'HSOA', 'HSAH', 'HSAA', 'HSDH',\n",
    "          'HSDA', 'HO', 'HA', 'HM', 'HD', 'HSAAg', 'HATAAg']].copy()\n",
    "y = data3['FTAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fc89d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns = ['Date', 'Time', 'FTR', 'HTR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "243a9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bb76785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.65667037\n",
      "Iteration 2, loss = 1.50007621\n",
      "Iteration 3, loss = 1.36108155\n",
      "Iteration 4, loss = 1.24385824\n",
      "Iteration 5, loss = 1.14706807\n",
      "Iteration 6, loss = 1.07679488\n",
      "Iteration 7, loss = 1.01361665\n",
      "Iteration 8, loss = 0.96652794\n",
      "Iteration 9, loss = 0.93613401\n",
      "Iteration 10, loss = 0.91246832\n",
      "Iteration 11, loss = 0.89380937\n",
      "Iteration 12, loss = 0.87789876\n",
      "Iteration 13, loss = 0.86068468\n",
      "Iteration 14, loss = 0.84417858\n",
      "Iteration 15, loss = 0.82516700\n",
      "Iteration 16, loss = 0.80628721\n",
      "Iteration 17, loss = 0.78569781\n",
      "Iteration 18, loss = 0.76630454\n",
      "Iteration 19, loss = 0.74943469\n",
      "Iteration 20, loss = 0.73085345\n",
      "Iteration 21, loss = 0.71499490\n",
      "Iteration 22, loss = 0.69975311\n",
      "Iteration 23, loss = 0.68507664\n",
      "Iteration 24, loss = 0.67112588\n",
      "Iteration 25, loss = 0.65813966\n",
      "Iteration 26, loss = 0.64512292\n",
      "Iteration 27, loss = 0.63225539\n",
      "Iteration 28, loss = 0.61894533\n",
      "Iteration 29, loss = 0.60821158\n",
      "Iteration 30, loss = 0.59540061\n",
      "Iteration 31, loss = 0.58451116\n",
      "Iteration 32, loss = 0.57369243\n",
      "Iteration 33, loss = 0.56339998\n",
      "Iteration 34, loss = 0.55412194\n",
      "Iteration 35, loss = 0.54366914\n",
      "Iteration 36, loss = 0.53475676\n",
      "Iteration 37, loss = 0.52663257\n",
      "Iteration 38, loss = 0.51790004\n",
      "Iteration 39, loss = 0.50970486\n",
      "Iteration 40, loss = 0.50268347\n",
      "Iteration 41, loss = 0.49474340\n",
      "Iteration 42, loss = 0.48763627\n",
      "Iteration 43, loss = 0.48093397\n",
      "Iteration 44, loss = 0.47440631\n",
      "Iteration 45, loss = 0.46769757\n",
      "Iteration 46, loss = 0.46144582\n",
      "Iteration 47, loss = 0.45592026\n",
      "Iteration 48, loss = 0.45031875\n",
      "Iteration 49, loss = 0.44480245\n",
      "Iteration 50, loss = 0.43972141\n",
      "Iteration 51, loss = 0.43448998\n",
      "Iteration 52, loss = 0.42982891\n",
      "Iteration 53, loss = 0.42554094\n",
      "Iteration 54, loss = 0.42054725\n",
      "Iteration 55, loss = 0.41628968\n",
      "Iteration 56, loss = 0.41234090\n",
      "Iteration 57, loss = 0.40818916\n",
      "Iteration 58, loss = 0.40425196\n",
      "Iteration 59, loss = 0.40065598\n",
      "Iteration 60, loss = 0.39717637\n",
      "Iteration 61, loss = 0.39349890\n",
      "Iteration 62, loss = 0.39009570\n",
      "Iteration 63, loss = 0.38655030\n",
      "Iteration 64, loss = 0.38335480\n",
      "Iteration 65, loss = 0.38015734\n",
      "Iteration 66, loss = 0.37693644\n",
      "Iteration 67, loss = 0.37366681\n",
      "Iteration 68, loss = 0.37062402\n",
      "Iteration 69, loss = 0.36770472\n",
      "Iteration 70, loss = 0.36464985\n",
      "Iteration 71, loss = 0.36165769\n",
      "Iteration 72, loss = 0.35856528\n",
      "Iteration 73, loss = 0.35593978\n",
      "Iteration 74, loss = 0.35304417\n",
      "Iteration 75, loss = 0.35041511\n",
      "Iteration 76, loss = 0.34743993\n",
      "Iteration 77, loss = 0.34476997\n",
      "Iteration 78, loss = 0.34215483\n",
      "Iteration 79, loss = 0.33925988\n",
      "Iteration 80, loss = 0.33656636\n",
      "Iteration 81, loss = 0.33381633\n",
      "Iteration 82, loss = 0.33101601\n",
      "Iteration 83, loss = 0.32881649\n",
      "Iteration 84, loss = 0.32611018\n",
      "Iteration 85, loss = 0.32356010\n",
      "Iteration 86, loss = 0.32055398\n",
      "Iteration 87, loss = 0.31793107\n",
      "Iteration 88, loss = 0.31512649\n",
      "Iteration 89, loss = 0.31243880\n",
      "Iteration 90, loss = 0.30964536\n",
      "Iteration 91, loss = 0.30736372\n",
      "Iteration 92, loss = 0.30470344\n",
      "Iteration 93, loss = 0.30199562\n",
      "Iteration 94, loss = 0.29919514\n",
      "Iteration 95, loss = 0.29649496\n",
      "Iteration 96, loss = 0.29390617\n",
      "Iteration 97, loss = 0.29149594\n",
      "Iteration 98, loss = 0.28918316\n",
      "Iteration 99, loss = 0.28647131\n",
      "Iteration 100, loss = 0.28355258\n",
      "Iteration 101, loss = 0.28060544\n",
      "Iteration 102, loss = 0.27841128\n",
      "Iteration 103, loss = 0.27598427\n",
      "Iteration 104, loss = 0.27349910\n",
      "Iteration 105, loss = 0.27081581\n",
      "Iteration 106, loss = 0.26796504\n",
      "Iteration 107, loss = 0.26509156\n",
      "Iteration 108, loss = 0.26235939\n",
      "Iteration 109, loss = 0.25984495\n",
      "Iteration 110, loss = 0.25701460\n",
      "Iteration 111, loss = 0.25449770\n",
      "Iteration 112, loss = 0.25185339\n",
      "Iteration 113, loss = 0.24897193\n",
      "Iteration 114, loss = 0.24627724\n",
      "Iteration 115, loss = 0.24350995\n",
      "Iteration 116, loss = 0.24088173\n",
      "Iteration 117, loss = 0.23842442\n",
      "Iteration 118, loss = 0.23596759\n",
      "Iteration 119, loss = 0.23321380\n",
      "Iteration 120, loss = 0.23026556\n",
      "Iteration 121, loss = 0.22739562\n",
      "Iteration 122, loss = 0.22458976\n",
      "Iteration 123, loss = 0.22203354\n",
      "Iteration 124, loss = 0.21928903\n",
      "Iteration 125, loss = 0.21650028\n",
      "Iteration 126, loss = 0.21381243\n",
      "Iteration 127, loss = 0.21120844\n",
      "Iteration 128, loss = 0.20852623\n",
      "Iteration 129, loss = 0.20592362\n",
      "Iteration 130, loss = 0.20309763\n",
      "Iteration 131, loss = 0.20030937\n",
      "Iteration 132, loss = 0.19774933\n",
      "Iteration 133, loss = 0.19506497\n",
      "Iteration 134, loss = 0.19231153\n",
      "Iteration 135, loss = 0.18964609\n",
      "Iteration 136, loss = 0.18689300\n",
      "Iteration 137, loss = 0.18418166\n",
      "Iteration 138, loss = 0.18141077\n",
      "Iteration 139, loss = 0.17875993\n",
      "Iteration 140, loss = 0.17607653\n",
      "Iteration 141, loss = 0.17349254\n",
      "Iteration 142, loss = 0.17079057\n",
      "Iteration 143, loss = 0.16833834\n",
      "Iteration 144, loss = 0.16584618\n",
      "Iteration 145, loss = 0.16302148\n",
      "Iteration 146, loss = 0.16055499\n",
      "Iteration 147, loss = 0.15804174\n",
      "Iteration 148, loss = 0.15555040\n",
      "Iteration 149, loss = 0.15297665\n",
      "Iteration 150, loss = 0.15034634\n",
      "Iteration 151, loss = 0.14797857\n",
      "Iteration 152, loss = 0.14559500\n",
      "Iteration 153, loss = 0.14319803\n",
      "Iteration 154, loss = 0.14066803\n",
      "Iteration 155, loss = 0.13815186\n",
      "Iteration 156, loss = 0.13584700\n",
      "Iteration 157, loss = 0.13356173\n",
      "Iteration 158, loss = 0.13101367\n",
      "Iteration 159, loss = 0.12865443\n",
      "Iteration 160, loss = 0.12630878\n",
      "Iteration 161, loss = 0.12398680\n",
      "Iteration 162, loss = 0.12171544\n",
      "Iteration 163, loss = 0.11963393\n",
      "Iteration 164, loss = 0.11708673\n",
      "Iteration 165, loss = 0.11531690\n",
      "Iteration 166, loss = 0.11325417\n",
      "Iteration 167, loss = 0.11096064\n",
      "Iteration 168, loss = 0.10880073\n",
      "Iteration 169, loss = 0.10676708\n",
      "Iteration 170, loss = 0.10508166\n",
      "Iteration 171, loss = 0.10307716\n",
      "Iteration 172, loss = 0.10096872\n",
      "Iteration 173, loss = 0.09904333\n",
      "Iteration 174, loss = 0.09710632\n",
      "Iteration 175, loss = 0.09527244\n",
      "Iteration 176, loss = 0.09351612\n",
      "Iteration 177, loss = 0.09160404\n",
      "Iteration 178, loss = 0.08970289\n",
      "Iteration 179, loss = 0.08794830\n",
      "Iteration 180, loss = 0.08625253\n",
      "Iteration 181, loss = 0.08455193\n",
      "Iteration 182, loss = 0.08270041\n",
      "Iteration 183, loss = 0.08107870\n",
      "Iteration 184, loss = 0.07947454\n",
      "Iteration 185, loss = 0.07771043\n",
      "Iteration 186, loss = 0.07619900\n",
      "Iteration 187, loss = 0.07459326\n",
      "Iteration 188, loss = 0.07295366\n",
      "Iteration 189, loss = 0.07147589\n",
      "Iteration 190, loss = 0.06993796\n",
      "Iteration 191, loss = 0.06834070\n",
      "Iteration 192, loss = 0.06699875\n",
      "Iteration 193, loss = 0.06555208\n",
      "Iteration 194, loss = 0.06409464\n",
      "Iteration 195, loss = 0.06257843\n",
      "Iteration 196, loss = 0.06111876\n",
      "Iteration 197, loss = 0.05980511\n",
      "Iteration 198, loss = 0.05852363\n",
      "Iteration 199, loss = 0.05712901\n",
      "Iteration 200, loss = 0.05584432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-169\" type=\"checkbox\" ><label for=\"sk-estimator-id-169\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;, MLPRegressor(verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-170\" type=\"checkbox\" ><label for=\"sk-estimator-id-170\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse_output=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-171\" type=\"checkbox\" ><label for=\"sk-estimator-id-171\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-172\" type=\"checkbox\" ><label for=\"sk-estimator-id-172\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-173\" type=\"checkbox\" ><label for=\"sk-estimator-id-173\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-174\" type=\"checkbox\" ><label for=\"sk-estimator-id-174\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-175\" type=\"checkbox\" ><label for=\"sk-estimator-id-175\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-176\" type=\"checkbox\" ><label for=\"sk-estimator-id-176\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse_output=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr', MLPRegressor(verbose=True))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse_output = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4221ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.3014912539919947\n",
      "MAE: 1.0251487466885199\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 Score: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3883b070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.21957361\n",
      "Iteration 2, loss = 0.99405852\n",
      "Iteration 3, loss = 0.83173028\n",
      "Iteration 4, loss = 0.75705291\n",
      "Iteration 5, loss = 0.76056307\n",
      "Iteration 6, loss = 0.76959531\n",
      "Iteration 7, loss = 0.74013842\n",
      "Iteration 8, loss = 0.69414045\n",
      "Iteration 9, loss = 0.66300709\n",
      "Iteration 10, loss = 0.64132766\n",
      "Iteration 11, loss = 0.63063753\n",
      "Iteration 12, loss = 0.61791946\n",
      "Iteration 13, loss = 0.60087490\n",
      "Iteration 14, loss = 0.57948374\n",
      "Iteration 15, loss = 0.55706378\n",
      "Iteration 16, loss = 0.53666208\n",
      "Iteration 17, loss = 0.52618222\n",
      "Iteration 18, loss = 0.50966915\n",
      "Iteration 19, loss = 0.48970657\n",
      "Iteration 20, loss = 0.46773923\n",
      "Iteration 21, loss = 0.45252233\n",
      "Iteration 22, loss = 0.43810871\n",
      "Iteration 23, loss = 0.41751410\n",
      "Iteration 24, loss = 0.39808920\n",
      "Iteration 25, loss = 0.38234535\n",
      "Iteration 26, loss = 0.36749915\n",
      "Iteration 27, loss = 0.34682863\n",
      "Iteration 28, loss = 0.33069850\n",
      "Iteration 29, loss = 0.31661955\n",
      "Iteration 30, loss = 0.29706211\n",
      "Iteration 31, loss = 0.28367991\n",
      "Iteration 32, loss = 0.26974222\n",
      "Iteration 33, loss = 0.25276001\n",
      "Iteration 34, loss = 0.23991849\n",
      "Iteration 35, loss = 0.22692096\n",
      "Iteration 36, loss = 0.21224636\n",
      "Iteration 37, loss = 0.19910856\n",
      "Iteration 38, loss = 0.18601470\n",
      "Iteration 39, loss = 0.17222556\n",
      "Iteration 40, loss = 0.16016014\n",
      "Iteration 41, loss = 0.14731492\n",
      "Iteration 42, loss = 0.13714587\n",
      "Iteration 43, loss = 0.12474906\n",
      "Iteration 44, loss = 0.11313080\n",
      "Iteration 45, loss = 0.10166591\n",
      "Iteration 46, loss = 0.09283716\n",
      "Iteration 47, loss = 0.08253022\n",
      "Iteration 48, loss = 0.07554096\n",
      "Iteration 49, loss = 0.06638113\n",
      "Iteration 50, loss = 0.05952573\n",
      "Iteration 51, loss = 0.05124336\n",
      "Iteration 52, loss = 0.04561712\n",
      "Iteration 53, loss = 0.04042024\n",
      "Iteration 54, loss = 0.03543079\n",
      "Iteration 55, loss = 0.03140415\n",
      "Iteration 56, loss = 0.02729772\n",
      "Iteration 57, loss = 0.02346815\n",
      "Iteration 58, loss = 0.02139511\n",
      "Iteration 59, loss = 0.01824477\n",
      "Iteration 60, loss = 0.01589968\n",
      "Iteration 61, loss = 0.01403391\n",
      "Iteration 62, loss = 0.01199138\n",
      "Iteration 63, loss = 0.01056349\n",
      "Iteration 64, loss = 0.00898436\n",
      "Iteration 65, loss = 0.00765289\n",
      "Iteration 66, loss = 0.00686410\n",
      "Iteration 67, loss = 0.00582437\n",
      "Iteration 68, loss = 0.00505847\n",
      "Iteration 69, loss = 0.00431762\n",
      "Iteration 70, loss = 0.00379311\n",
      "Iteration 71, loss = 0.00332772\n",
      "Iteration 72, loss = 0.00285983\n",
      "Iteration 73, loss = 0.00242981\n",
      "Iteration 74, loss = 0.00213470\n",
      "Iteration 75, loss = 0.00180942\n",
      "Iteration 76, loss = 0.00158577\n",
      "Iteration 77, loss = 0.00139146\n",
      "Iteration 78, loss = 0.00119365\n",
      "Iteration 79, loss = 0.00102116\n",
      "Iteration 80, loss = 0.00089702\n",
      "Iteration 81, loss = 0.00076915\n",
      "Iteration 82, loss = 0.00066980\n",
      "Iteration 83, loss = 0.00062845\n",
      "Iteration 84, loss = 0.00051983\n",
      "Iteration 85, loss = 0.00044039\n",
      "Iteration 86, loss = 0.00039251\n",
      "Iteration 87, loss = 0.00033844\n",
      "Iteration 88, loss = 0.00032117\n",
      "Iteration 89, loss = 0.00026890\n",
      "Iteration 90, loss = 0.00023711\n",
      "Iteration 91, loss = 0.00022347\n",
      "Iteration 92, loss = 0.00020589\n",
      "Iteration 93, loss = 0.00018362\n",
      "Iteration 94, loss = 0.00017697\n",
      "Iteration 95, loss = 0.00016040\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-177\" type=\"checkbox\" ><label for=\"sk-estimator-id-177\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-178\" type=\"checkbox\" ><label for=\"sk-estimator-id-178\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-179\" type=\"checkbox\" ><label for=\"sk-estimator-id-179\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-180\" type=\"checkbox\" ><label for=\"sk-estimator-id-180\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-181\" type=\"checkbox\" ><label for=\"sk-estimator-id-181\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-182\" type=\"checkbox\" ><label for=\"sk-estimator-id-182\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-183\" type=\"checkbox\" ><label for=\"sk-estimator-id-183\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-184\" type=\"checkbox\" ><label for=\"sk-estimator-id-184\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000,\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (100, 100, 100),\n",
    "                            max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b1c0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.1427948015473175\n",
      "MAE: 0.9630138297809253\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "767a3703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 16.76213140\n",
      "Iteration 2, loss = 16.31397586\n",
      "Iteration 3, loss = 15.88825966\n",
      "Iteration 4, loss = 15.47444118\n",
      "Iteration 5, loss = 15.07233718\n",
      "Iteration 6, loss = 14.68223908\n",
      "Iteration 7, loss = 14.30235051\n",
      "Iteration 8, loss = 13.93335986\n",
      "Iteration 9, loss = 13.57519325\n",
      "Iteration 10, loss = 13.22487367\n",
      "Iteration 11, loss = 12.88461693\n",
      "Iteration 12, loss = 12.55215298\n",
      "Iteration 13, loss = 12.23048407\n",
      "Iteration 14, loss = 11.91529032\n",
      "Iteration 15, loss = 11.60856727\n",
      "Iteration 16, loss = 11.30934305\n",
      "Iteration 17, loss = 11.01799057\n",
      "Iteration 18, loss = 10.73377899\n",
      "Iteration 19, loss = 10.45655502\n",
      "Iteration 20, loss = 10.18708940\n",
      "Iteration 21, loss = 9.92372486\n",
      "Iteration 22, loss = 9.66738648\n",
      "Iteration 23, loss = 9.41746338\n",
      "Iteration 24, loss = 9.17412390\n",
      "Iteration 25, loss = 8.93730771\n",
      "Iteration 26, loss = 8.70615791\n",
      "Iteration 27, loss = 8.48119433\n",
      "Iteration 28, loss = 8.26194103\n",
      "Iteration 29, loss = 8.04867728\n",
      "Iteration 30, loss = 7.84092701\n",
      "Iteration 31, loss = 7.63832933\n",
      "Iteration 32, loss = 7.44125851\n",
      "Iteration 33, loss = 7.24928660\n",
      "Iteration 34, loss = 7.06239590\n",
      "Iteration 35, loss = 6.88044242\n",
      "Iteration 36, loss = 6.70328640\n",
      "Iteration 37, loss = 6.53078934\n",
      "Iteration 38, loss = 6.36299181\n",
      "Iteration 39, loss = 6.19977180\n",
      "Iteration 40, loss = 6.04065140\n",
      "Iteration 41, loss = 5.88575778\n",
      "Iteration 42, loss = 5.73536002\n",
      "Iteration 43, loss = 5.58859927\n",
      "Iteration 44, loss = 5.44594851\n",
      "Iteration 45, loss = 5.30760643\n",
      "Iteration 46, loss = 5.17217536\n",
      "Iteration 47, loss = 5.04098811\n",
      "Iteration 48, loss = 4.91327638\n",
      "Iteration 49, loss = 4.78913157\n",
      "Iteration 50, loss = 4.66838941\n",
      "Iteration 51, loss = 4.55085598\n",
      "Iteration 52, loss = 4.43662319\n",
      "Iteration 53, loss = 4.32538201\n",
      "Iteration 54, loss = 4.21717752\n",
      "Iteration 55, loss = 4.11206027\n",
      "Iteration 56, loss = 4.00976612\n",
      "Iteration 57, loss = 3.91029957\n",
      "Iteration 58, loss = 3.81377539\n",
      "Iteration 59, loss = 3.71978716\n",
      "Iteration 60, loss = 3.62842656\n",
      "Iteration 61, loss = 3.53968625\n",
      "Iteration 62, loss = 3.45340099\n",
      "Iteration 63, loss = 3.36962948\n",
      "Iteration 64, loss = 3.28818925\n",
      "Iteration 65, loss = 3.20897246\n",
      "Iteration 66, loss = 3.13226705\n",
      "Iteration 67, loss = 3.05775309\n",
      "Iteration 68, loss = 2.98558582\n",
      "Iteration 69, loss = 2.91541310\n",
      "Iteration 70, loss = 2.84704738\n",
      "Iteration 71, loss = 2.78053726\n",
      "Iteration 72, loss = 2.71587561\n",
      "Iteration 73, loss = 2.65310101\n",
      "Iteration 74, loss = 2.59188477\n",
      "Iteration 75, loss = 2.53268676\n",
      "Iteration 76, loss = 2.47516629\n",
      "Iteration 77, loss = 2.41959814\n",
      "Iteration 78, loss = 2.36528582\n",
      "Iteration 79, loss = 2.31275356\n",
      "Iteration 80, loss = 2.26186463\n",
      "Iteration 81, loss = 2.21244566\n",
      "Iteration 82, loss = 2.16448345\n",
      "Iteration 83, loss = 2.11797973\n",
      "Iteration 84, loss = 2.07284512\n",
      "Iteration 85, loss = 2.02916149\n",
      "Iteration 86, loss = 1.98679062\n",
      "Iteration 87, loss = 1.94571470\n",
      "Iteration 88, loss = 1.90591186\n",
      "Iteration 89, loss = 1.86728451\n",
      "Iteration 90, loss = 1.82980467\n",
      "Iteration 91, loss = 1.79345000\n",
      "Iteration 92, loss = 1.75828976\n",
      "Iteration 93, loss = 1.72407166\n",
      "Iteration 94, loss = 1.69086551\n",
      "Iteration 95, loss = 1.65855561\n",
      "Iteration 96, loss = 1.62740222\n",
      "Iteration 97, loss = 1.59704713\n",
      "Iteration 98, loss = 1.56769169\n",
      "Iteration 99, loss = 1.53931659\n",
      "Iteration 100, loss = 1.51188696\n",
      "Iteration 101, loss = 1.48521794\n",
      "Iteration 102, loss = 1.45945343\n",
      "Iteration 103, loss = 1.43453104\n",
      "Iteration 104, loss = 1.41043985\n",
      "Iteration 105, loss = 1.38697447\n",
      "Iteration 106, loss = 1.36438114\n",
      "Iteration 107, loss = 1.34250172\n",
      "Iteration 108, loss = 1.32112050\n",
      "Iteration 109, loss = 1.30058089\n",
      "Iteration 110, loss = 1.28070199\n",
      "Iteration 111, loss = 1.26150042\n",
      "Iteration 112, loss = 1.24303074\n",
      "Iteration 113, loss = 1.22502025\n",
      "Iteration 114, loss = 1.20786020\n",
      "Iteration 115, loss = 1.19069146\n",
      "Iteration 116, loss = 1.17448257\n",
      "Iteration 117, loss = 1.15881675\n",
      "Iteration 118, loss = 1.14358417\n",
      "Iteration 119, loss = 1.12877507\n",
      "Iteration 120, loss = 1.11437791\n",
      "Iteration 121, loss = 1.10048350\n",
      "Iteration 122, loss = 1.08694777\n",
      "Iteration 123, loss = 1.07393465\n",
      "Iteration 124, loss = 1.06162576\n",
      "Iteration 125, loss = 1.04930445\n",
      "Iteration 126, loss = 1.03765274\n",
      "Iteration 127, loss = 1.02639425\n",
      "Iteration 128, loss = 1.01547409\n",
      "Iteration 129, loss = 1.00495098\n",
      "Iteration 130, loss = 0.99478890\n",
      "Iteration 131, loss = 0.98493302\n",
      "Iteration 132, loss = 0.97544412\n",
      "Iteration 133, loss = 0.96624071\n",
      "Iteration 134, loss = 0.95737465\n",
      "Iteration 135, loss = 0.94896474\n",
      "Iteration 136, loss = 0.94063527\n",
      "Iteration 137, loss = 0.93270544\n",
      "Iteration 138, loss = 0.92496907\n",
      "Iteration 139, loss = 0.91751048\n",
      "Iteration 140, loss = 0.91027742\n",
      "Iteration 141, loss = 0.90334471\n",
      "Iteration 142, loss = 0.89656408\n",
      "Iteration 143, loss = 0.89002578\n",
      "Iteration 144, loss = 0.88377197\n",
      "Iteration 145, loss = 0.87773253\n",
      "Iteration 146, loss = 0.87197891\n",
      "Iteration 147, loss = 0.86629448\n",
      "Iteration 148, loss = 0.86099022\n",
      "Iteration 149, loss = 0.85567252\n",
      "Iteration 150, loss = 0.85066969\n",
      "Iteration 151, loss = 0.84574645\n",
      "Iteration 152, loss = 0.84106427\n",
      "Iteration 153, loss = 0.83653378\n",
      "Iteration 154, loss = 0.83217669\n",
      "Iteration 155, loss = 0.82800101\n",
      "Iteration 156, loss = 0.82390029\n",
      "Iteration 157, loss = 0.82002143\n",
      "Iteration 158, loss = 0.81630384\n",
      "Iteration 159, loss = 0.81266640\n",
      "Iteration 160, loss = 0.80921064\n",
      "Iteration 161, loss = 0.80584076\n",
      "Iteration 162, loss = 0.80260088\n",
      "Iteration 163, loss = 0.79945535\n",
      "Iteration 164, loss = 0.79648504\n",
      "Iteration 165, loss = 0.79328132\n",
      "Iteration 166, loss = 0.79104771\n",
      "Iteration 167, loss = 0.78782794\n",
      "Iteration 168, loss = 0.78523905\n",
      "Iteration 169, loss = 0.78263608\n",
      "Iteration 170, loss = 0.78018277\n",
      "Iteration 171, loss = 0.77786598\n",
      "Iteration 172, loss = 0.77565194\n",
      "Iteration 173, loss = 0.77372648\n",
      "Iteration 174, loss = 0.77146392\n",
      "Iteration 175, loss = 0.76946615\n",
      "Iteration 176, loss = 0.76752881\n",
      "Iteration 177, loss = 0.76565055\n",
      "Iteration 178, loss = 0.76376847\n",
      "Iteration 179, loss = 0.76194072\n",
      "Iteration 180, loss = 0.76034878\n",
      "Iteration 181, loss = 0.75880018\n",
      "Iteration 182, loss = 0.75712079\n",
      "Iteration 183, loss = 0.75554189\n",
      "Iteration 184, loss = 0.75411571\n",
      "Iteration 185, loss = 0.75280903\n",
      "Iteration 186, loss = 0.75141216\n",
      "Iteration 187, loss = 0.75022376\n",
      "Iteration 188, loss = 0.74923953\n",
      "Iteration 189, loss = 0.74813856\n",
      "Iteration 190, loss = 0.74705760\n",
      "Iteration 191, loss = 0.74596268\n",
      "Iteration 192, loss = 0.74484715\n",
      "Iteration 193, loss = 0.74368679\n",
      "Iteration 194, loss = 0.74269460\n",
      "Iteration 195, loss = 0.74149355\n",
      "Iteration 196, loss = 0.74042801\n",
      "Iteration 197, loss = 0.73946774\n",
      "Iteration 198, loss = 0.73853338\n",
      "Iteration 199, loss = 0.73778990\n",
      "Iteration 200, loss = 0.73686347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17202\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-185\" type=\"checkbox\" ><label for=\"sk-estimator-id-185\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;ct&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;,\n",
       "                                                   &#x27;Referee&#x27;])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;mlr&#x27;,\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-186\" type=\"checkbox\" ><label for=\"sk-estimator-id-186\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ct: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;ohe&#x27;, OneHotEncoder(sparse=False),\n",
       "                                 [&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-187\" type=\"checkbox\" ><label for=\"sk-estimator-id-187\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ohe</label><div class=\"sk-toggleable__content\"><pre>[&#x27;TeamH&#x27;, &#x27;TeamA&#x27;, &#x27;Referee&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-188\" type=\"checkbox\" ><label for=\"sk-estimator-id-188\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-189\" type=\"checkbox\" ><label for=\"sk-estimator-id-189\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HStr&#x27;, &#x27;HSOH&#x27;, &#x27;HSOA&#x27;, &#x27;HSAH&#x27;, &#x27;HSAA&#x27;, &#x27;HSDH&#x27;, &#x27;HSDA&#x27;, &#x27;HO&#x27;, &#x27;HA&#x27;, &#x27;HM&#x27;, &#x27;HD&#x27;, &#x27;HSAAg&#x27;, &#x27;HATAAg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-190\" type=\"checkbox\" ><label for=\"sk-estimator-id-190\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-191\" type=\"checkbox\" ><label for=\"sk-estimator-id-191\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-192\" type=\"checkbox\" ><label for=\"sk-estimator-id-192\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60), verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('ct',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(sparse=False),\n",
       "                                                  ['TeamH', 'TeamA',\n",
       "                                                   'Referee'])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('mlr',\n",
       "                 MLPRegressor(alpha=24, hidden_layer_sizes=(60, 60, 60),\n",
       "                              verbose=True))])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('ct', ColumnTransformer(\n",
    "            transformers = [\n",
    "                ('ohe', OneHotEncoder(sparse = False), ['TeamH', 'TeamA', 'Referee'])\n",
    "            ],\n",
    "            remainder = 'passthrough'\n",
    "        )),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('mlr', MLPRegressor(verbose = True,\n",
    "                            hidden_layer_sizes = (60, 60, 60),\n",
    "                            alpha = 24))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "08045edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.01608328430147421\n",
      "MAE: 0.9497084008139123\n"
     ]
    }
   ],
   "source": [
    "print(f'R2: {r2_score(y_test, pipe.predict(X_test))}')\n",
    "\n",
    "print(f'MAE: {mean_absolute_error(y_test, pipe.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee1548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
